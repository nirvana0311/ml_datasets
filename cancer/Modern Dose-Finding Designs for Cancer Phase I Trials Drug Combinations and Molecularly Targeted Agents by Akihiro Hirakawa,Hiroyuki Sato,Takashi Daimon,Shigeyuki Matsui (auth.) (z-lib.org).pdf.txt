SPRINGER BRIEFS IN STATISTICS

J S S R E S E A R C H S E R I E S I N S TAT I S T I C S

Akihiro Hirakawa · Hiroyuki Sato

Takashi Daimon · Shigeyuki Matsui

Modern Dose-

Finding Designs for

Cancer Phase I Trials:

Drug Combinations

and Molecularly

Targeted Agents

123

SpringerBriefs in Statistics

JSS Research Series in Statistics

Editors-in-Chief

Naoto Kunitomo

Akimichi Takemura

Series editors

Genshiro Kitagawa

Tomoyuki Higuchi

Yutaka Kano

Toshimitsu Hamasaki

Shigeyuki Matsui

Manabu Iwasaki

Yasuhiro Omori

Yoshihiro Yajima

The current research of statistics in Japan has expanded in several directions in line with recent trends in academic activities in the area of statistics and statistical sciences over the globe. The core of these research activities in statistics in Japan has been the Japan Statistical Society (JSS). This society, the oldest and largest academic organization for statistics in Japan, was founded in 1931 by a handful of pioneer statisticians and economists and now has a history of about 80 years. Many distinguished scholars have been members, including the influential statistician Hirotugu Akaike, who was a past president of JSS, and the notable mathematician Kiyosi Itô, who was an earlier member of the Institute of Statistical Mathematics (ISM), which has been a closely related organization since the establishment of ISM. The society has two academic journals: the Journal of the Japan Statistical Society (English Series) and the Journal of the Japan Statistical Society (Japanese Series). The membership of JSS consists of researchers, teachers, and professional statisticians in many different fields including mathematics, statistics, engineering, medical sciences, government statistics, economics, business, psychology, education, and many other natural, biological, and social sciences.

The JSS Series of Statistics aims to publish recent results of current research activities in the areas of statistics and statistical sciences in Japan that otherwise would not be available in English; they are complementary to the two JSS

academic journals, both English and Japanese. Because the scope of a research paper in academic journals inevitably has become narrowly focused and condensed in recent years, this series is intended to fill the gap between academic research activities and the form of a single academic paper.

The series will be of great interest to a wide audience of researchers, teachers, professional statisticians, and graduate students in many countries who are interested in statistics and statistical sciences, in statistical theory, and in various areas of statistical applications.

More information about this series at http://www.springer.com/series/13497

Akihiro Hirakawa • Hiroyuki Sato

Takashi Daimon • Shigeyuki Matsui

Modern Dose-Finding

Designs for Cancer Phase I

Trials: Drug Combinations

and Molecularly Targeted

Agents

123

Akihiro Hirakawa

Takashi Daimon

Department of Biostatistics

Division of Biostatistics

and Bioinformatics, Graduate

Hyogo College of Medicine

School of Medicine

Nishinomiya, Hyogo

The University of Tokyo

Japan

Tokyo

Japan

Shigeyuki Matsui

Department of Biostatistics, Graduate

Hiroyuki Sato

School of Medicine

Pharmaceuticals and Medical

Nagoya University

Devices Agency

Nagoya, Aichi

Tokyo

Japan

Japan

ISSN 2191-544X

ISSN 2191-5458

(electronic)

SpringerBriefs in Statistics

ISSN 2364-0057

ISSN 2364-0065

(electronic)

JSS Research Series in Statistics

ISBN 978-4-431-55572-8

ISBN 978-4-431-55573-5

(eBook)

https://doi.org/10.1007/978-4-431-55573-5

Library of Congress Control Number: 2018930526

© The Author(s), under exclusive licence to Springer Japan KK, part of Springer Nature 2018

This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.

The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.

The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

Printed on acid-free paper

This Springer imprint is published by the registered company Springer Japan KK part of Springer Nature The registered company address is: Shiroyama Trust Tower, 4-3-1 Toranomon, Minato-ku, Tokyo 105-6005, Japan

To our beloved families and

ex-colleagues/colleagues at the University of

Tokyo, Pharmaceuticals and Medical Devices

Agency, Hyogo College of Medicine, and

Nagoya University.





Preface

Novel treatments of cancers have emerged over the past decade. Along with this growing trend, innovative phase I trial designs for determining a maximum tolerated dose (MTD) or recommended phase 2 dose (RP2D) have also been devised. In contrast to the emergence of such statistical dose-finding approaches, most phase I trials have a classic dose escalation design such as the 3 + 3 scheme in practice because of its ease of use. Because the utility of the innovative dose-finding designs has been examined in a large number of studies, we need to get away from the comfort zone of application of the classic dose escalation designs to increase the success rate of anticancer drug development. The aim of this book is to contribute to the modernization of dose-finding methods in phase I trials by describing statistical methodologies of recent innovative dose-finding methods as well as their user-friendly software implementations.

This book deals with advanced methods for phase I dose-finding clinical trials with multiple drugs and/or outcomes in oncology. In addition to the methodological aspects of the dose-finding methods, the text also provides software implementations and practical considerations for applying these complex methods to real cancer clinical trials. Thus, in this book, we aim to provide researchers working in biostatistics and other statistical sciences a good summary of recent developments in complex dose-finding methods as well as to offer practitioners in biostatistics and clinical investigators advanced information for designing, conducting, monitoring, and analyzing complex dose-finding trials. The topics in the book are mainly related to cancer clinical trials, but many are potentially applicable or extendable to trials dealing with other diseases.

The book mainly focuses on model-based dose-finding methods for two kinds of phase I trials. One is clinical trials of a combination of two agents. When developing dose-finding methods for two-agent combination trials, we need reasonable models that can adequately capture joint toxicity probabilities for two agents, taking into consideration possible interactions of the two agents on toxicity probability (e.g., synergistic or antagonistic effects). The other is clinical trials evaluating both efficacy and toxicity outcomes in single- and two-agent combination trials. These methods are often applied to the phase I trials of molecularly targeted agents vii

viii

Preface

(MTAs) because the toxicity and efficacy for an MTA do not monotonically increase with the dose, but the efficacy often increases initially with the dose and then plateaus. Successful software implementations for several dose-finding methods we introduced in this book are shown and their practical operating characteristics are discussed. Recent topics on dose-finding methods for MTAs are also elaborated.

Chapter 1 provides key points of phase I cancer trials. We also overview the 3 + 3 design as a rule-based dose-finding method and then a continual reassessment method (CRM) as a model-based dose-finding method for monotherapy (i.e., the use of a single agent). Chapter 2 is devoted to the dose-finding methods for two-agent combination trials. In two-agent combination phase I trials, we need to capture the dose–toxicity relationship for combination of two agents and to identify MTD combinations of the two agents. We compared several rival methods and summarized the operating characteristics of each method. Chapter 3 introduces dose-finding designs that determine the optimal dose based on the joint assessment of toxicity and efficacy of an agent. Various types of incorporation of toxicity and efficacy outcomes into dose-finding methods have been developed. We discuss four Bayesian designs in this chapter. Chapter 4 describes dose-finding methods for MTAs to determine the optimal dose in singe-agent trials. Finally, we introduce some recent advanced topics on dose-finding designs including seamless phase I/II trials, designs that account for late-onset toxicity and efficacy outcomes, dose finding based on relative dose intensity, cancer immunotherapy, and dose individualization for precision medicine in Chap. 5.

Finally,

we

are

grateful

for

a

Grant-in-Aid

for

Scientific Research

(Nos. 16H06299, 15K15948, 15K00058, and 17K00045) from the Ministry of Education, Culture, Sports, Science and Technology of Japan for supporting this book project. The views expressed here are the result of an independent study and do not represent the viewpoints or findings of the Pharmaceuticals and Medical Devices Agency.

Tokyo, Japan

Akihiro Hirakawa

November 2017

Hiroyuki Sato

Takashi Daimon

Shigeyuki Matsui





Contents

1

Dose Finding in Phase I Cancer Trials . . . . . . . . . . . . . . . . . . . . . . .

1

1.1

Cytotoxic Agents and MTAs . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1.2

Classification of Phase I Cancer Trials . . . . . . . . . . . . . . . . . . . .

2

1.3

Rule-Based Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

1.3.1

3 þ 3 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

1.3.2

Other Relevant Methods . . . . . . . . . . . . . . . . . . . . . . . . .

3

1.4

Model-Based Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

1.4.1

Bayesian CRM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

1.4.2

Other Relevant Designs . . . . . . . . . . . . . . . . . . . . . . . . .

6

References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

2

Dose Finding for a Combination of Two Agents . . . . . . . . . . . . . . . .

9

2.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

9

2.1.1

Two-Agent Combination Trials . . . . . . . . . . . . . . . . . . . .

9

2.1.2

An Overview of Model-Based Dose-Finding Methods . . .

10

2.1.3

Methodological Characteristics . . . . . . . . . . . . . . . . . . . .

11

2.2

The Bayesian Approach Based on Copula Regression . . . . . . . . .

13

2.2.1

Copula-Type Models . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

2.2.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

14

2.2.3

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

14

2.3

Hierarchical Bayesian Design . . . . . . . . . . . . . . . . . . . . . . . . . .

15

2.3.1

Hierarchical Models . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

2.3.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

17

2.3.3

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

17

2.4

An Approach Using a Shrinkage Logistic Model . . . . . . . . . . . .

20

2.4.1

The Shrinkage Logistic Model . . . . . . . . . . . . . . . . . . . .

20

2.4.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

20

2.4.3

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

21

2.5

An Approach Using a Logistic Model . . . . . . . . . . . . . . . . . . . .

22

2.5.1

The Logistic Model Involving Standardized Doses . . . . .

22

ix

x

Contents

2.5.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

23

2.5.3

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

23

2.6

The Design Based on Order-Restricted Inference . . . . . . . . . . . .

25

2.6.1

Order-Restricted Inference . . . . . . . . . . . . . . . . . . . . . . .

25

2.6.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

26

2.7

The Partial-Ordering Continual Reassessment Method . . . . . . . .

27

2.7.1

The Model for Possible Orderings of Toxicity

Probability for a Dose Combination . . . . . . . . . . . . . . . .

27

2.7.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

28

2.7.3

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

29

2.8

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

30

2.9

Effects of Design Properties . . . . . . . . . . . . . . . . . . . . . . . . . . .

34

2.9.1

Size of Patient Cohorts . . . . . . . . . . . . . . . . . . . . . . . . . .

35

2.9.2

The Choice of a Dose–Toxicity Model . . . . . . . . . . . . . .

35

2.9.3

The Start-Up Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

37

2.9.4

Restrictions on Skipping Dose Levels . . . . . . . . . . . . . . .

37

References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

38

3

Dose Finding for Joint Assessment of Both Efficacy

and Toxicity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

41

3.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

41

3.2

The Bivariate Continual Reassessment Method . . . . . . . . . . . . . .

43

3.2.1

Modeling Toxicity and Efficacy Outcomes . . . . . . . . . . .

43

3.2.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

44

3.2.3

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . .

45

3.2.4

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

45

3.3

Dose Finding Based on Efficacy–Toxicity Trade-Offs . . . . . . . . .

46

3.3.1

Modeling Toxicity and Efficacy Outcomes . . . . . . . . . . .

46

3.3.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

47

3.3.3

Constructing a Trade-Off Contour . . . . . . . . . . . . . . . . . .

48

3.3.4

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . .

49

3.3.5

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

50

3.4

A Bayesian Approach to Modeling Binary Toxicity

and Continuous Efficacy Outcomes . . . . . . . . . . . . . . . . . . . . . .

50

3.4.1

Modeling Toxicity and Efficacy Outcomes . . . . . . . . . . .

51

3.4.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

52

3.4.3

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . .

53

3.5

The BMA Bivariate CRM . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

54

3.5.1

Modeling Toxicity and Efficacy Outcomes . . . . . . . . . . .

54

3.5.2

BMA Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

55

3.5.3

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

56

3.5.4

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . .

57

3.5.5

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

57

References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

58

Contents

xi

4

Dose Finding for Molecularly Targeted Agents (MTAs) . . . . . . . . . .

59

4.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

59

4.2

The Model-Selecting Dose-Finding Method . . . . . . . . . . . . . . . .

60

4.2.1

Modeling Toxicity and Efficacy Outcomes . . . . . . . . . . .

61

4.2.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

62

4.2.3

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . .

63

4.2.4

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

64

4.3

The Dose-Finding Method Using the Change Point Model . . . . .

65

4.3.1

Modeling Toxicity and Efficacy Outcomes . . . . . . . . . . .

65

4.3.2

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

68

4.3.3

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . .

70

4.3.4

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

72

4.4

The Dose-Finding Method with Late-Onset Efficacy . . . . . . . . . .

73

4.4.1

Modeling Toxicity and Efficacy Outcomes . . . . . . . . . . .

73

4.4.2

Plateau Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

75

4.4.3

The Dose-Finding Algorithm . . . . . . . . . . . . . . . . . . . . .

76

4.4.4

Operating Characteristics . . . . . . . . . . . . . . . . . . . . . . . .

77

4.4.5

Software Implementation . . . . . . . . . . . . . . . . . . . . . . . .

78

References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

79

5

Advanced Topics on Dose-Finding Designs . . . . . . . . . . . . . . . . . . . .

81

5.1

Leveraging Phase I/II Trials . . . . . . . . . . . . . . . . . . . . . . . . . . .

81

5.2

Late-Onset Toxicity and Efficacy Outcomes . . . . . . . . . . . . . . . .

82

5.3

Accounting for Relative Dose Intensity for MTAs . . . . . . . . . . .

85

5.4

Cancer Immunotherapy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

86

5.5

Dose Individualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

86

References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

87





Acronyms

BMA

Bayesian model averaging

CRM

Continual reassessment method

MTA

Molecularly targeted agent

MTD

Maximum tolerated dose

RP2D

Recommended phase 2 dose

xiii





Chapter 1

Dose Finding in Phase I Cancer Trials

Abstract The objective of phase I cancer trials is to determine the optimal dose of an agent or a combination of agents that can serve as a recommended phase 2 dose (RP2D). The conventionally defined RP2D of a cytotoxic agent corresponds to the maximum tolerated dose (MTD), defined as the highest dose with acceptable toxicity.

MTD is generally calculated from dose-limiting toxicity data obtained during the first, and rarely, the second cycle of treatment. The dose-finding methods for determining the MTD are roughly categorized into two groups: (1) those based on prespecified dose escalation or de-escalation rules; and (2) those based on a statistical dose–

response model. In contrast to cytotoxic agents, the RP2D of molecularly targeted agents (MTAs) may not be necessarily identical to their MTD owing to the mechanism of action. Therefore, the reasonable dose-finding methods for determining the RP2D

of cytotoxic agents and of MTAs are considered different. This introductory chapter provides key points on phase I cancer trials and an overview the rule-and model-based dose-finding methods for monotherapy (i.e., the use of a single agent) that are the prototype of all the innovative dose-finding methods developed recently.

Keywords Dose finding · Maximum tolerated dose · Phase I · Recommended phase 2 dose

1.1

Cytotoxic Agents and MTAs

Cytotoxic agents are those aimed at directly killing cancer cells. Nonetheless, they also kill other cells likewise, such as normal cells, as a systemic action, and therefore they may have serious adverse effects. Thus, it is thought that the efficacy and toxicity of cytotoxic agents stem from the same biological mechanism, closely linked to each other. In addition, for cytotoxic agents, it is natural to consider an assumption of monotonicity, where higher doses may yield greater efficacy but lesser safety. In general, the fatal nature of the disease may allow for the use of an MTD, in hopes of killing all cancer cells. This approach is behind the strategy of traditional early-phase clinical trials for cytotoxic agents. The aim is to determine the MTD based

© The Author(s), under exclusive licence to Springer Japan KK, part of Springer Nature 2018

1

A. Hirakawa et al., Modern Dose-Finding Designs for Cancer Phase I Trials: Drug Combinations and Molecularly Targeted Agents, JSS Research Series in Statistics, https://doi.org/10.1007/978-4-431-55573-5_1





2

1

Dose Finding in Phase I Cancer Trials

on toxicity data in a phase I trial, followed by evaluation of efficacy at MTD in a subsequent phase II trial.

MTAs differ from standard chemotherapy in several ways. MTAs block the growth and spread of a tumor by interfering with specific molecules (“molecular targets”) that are involved in the growth, progression, and spread of the tumor, whereas most of cytotoxic agents act on all rapidly dividing normal and cancerous cells. MTAs are also deliberately chosen or designed to interact with their target, whereas many cytotoxic agents have been identified because they kill cells. MTAs are often cytostatic (that is, they block tumor cell proliferation); therefore, the dose–efficacy curves of MTAs do not always monotonically increase with the dose escalation. Jain et al. (2010)

concluded that targeted agents may have different dose–response relationships as compared with cytotoxic chemotherapies. Le Tourneau et al. (2010) suggested that some MTAs do not necessarily need to be administered at their MTD to obtain maximal efficacy. In the determination of an optimal dose for MTAs, dose-finding methods that take into account the bivariate-correlating outcomes of both efficacy and toxicity are required.

1.2

Classification of Phase I Cancer Trials

The objective of phase I cancer trials is to determine the optimal dose of an agent or a combination of agents that can serve as the RP2D. The secondary objectives are to evaluate the toxicity including dose-limiting toxicity, pharmacokinetics, and the antitumor effect in the schedule under evaluation. The conventionally defined RP2D of a cytotoxic agent corresponds to the MTD, defined as the highest dose with acceptable toxicity. MTD is generally determined from dose-limiting toxicity data obtained during the first, and rarely, the second cycle of treatment. In two-agent combination phase I trials, investigators need to capture the dose–toxicity relationship for combination of two agents and identify MTD combinations of the two agents.

The dose-finding methods for determining the MTD (or MTD combination) are roughly categorized into two groups: (1) those based on prespecified dose escalation or de-escalation rules; and (2) those based on a statistical dose–response model.

In contrast to cytotoxic agents, the RP2D of MTAs may not necessarily be identical to their MTD owing to the mechanism of action. Therefore, dose-finding methods that take account the efficacy outcome in addition to the toxicity outcome are warranted for the clinical development of MTAs. The dose–efficacy model for MTAs is necessary to capture the specific relation between efficacy and a dose level. The efficacy may increase initially with the dose level but then reaches a plateau; however, this may not always be the case. Several powerful methods were developed recently.

Thus, the reasonable dose-finding methods for determining the RP2D of cytotoxic agents and MTAs are considered to be different.

Before introducing the statistical methodologies for recent innovative dose-finding methods for a combination therapy of two agents and MTAs, we first overview the rule- and model-based dose-finding methods for monotherapy (i.e., the use of





1.2 Classification of Phase I Cancer Trials

3

a single agent) that are the prototype of all the innovative dose-finding methods developed recently. Eisenhauer et al. (2015) described the basics of dose-finding designs including the 3 + 3 designs as well as information on the process, pitfalls, and logistics of phase I trials. Cheung (2011) focused on the theory and application of the continual reassessment method (CRM). Statistical properties and operating characteristics of rule- and model-based dose-finding methods have been examined in several studies (e.g., O’Quigley and Chevret 1991, Chevret 1993, Lin and Shih

2001, Iasonos et al. 2008).

1.3

Rule-Based Methods

1.3.1

3 + 3 Design

The most well-known and widely used rule-based method is the 3 + 3 design (Carter

1973; Storer 1989). This design enrolls a group of three patients and treats them with the starting (usually, the lowest) dose level. Based on the observed prespecified toxicity (usually, dose-limiting toxicity), we determine the dose level allocated to the next cohort of patients and the MTD as follows:

Step 1: Treat three patients at the starting dose level and observe the toxicities.

(a) If none of the three patients develops toxicity, then allocate the next higher dose to the next cohort of patients, and repeat Step 1.

(b) If one out of three patients experiences toxicity, then go to Step 2.

(c) If at least two out of three patients experience toxicity, then go to Step 3.

Step 2: Treat three more patients at the same dose level and observe the toxicities.

(a) If one out of the six patients experiences toxicity, then allocate the next higher dose to the next cohort of patients and go to Step 1.

(b) If at least two out of the six patients experience toxicity, then go to Step 3.

Step 3: Stop dose escalation, and the next lower dose level is generally selected as the MTD.

Figure 1.1 shows an example of dose assignment for the 3 + 3 design.

1.3.2

Other Relevant Methods

Accelerated-titration designs proposed by Simon et al. (1997) are also a widely used rule-based method. The main features of this design are (i) to include a rapid





4

1

Dose Finding in Phase I Cancer Trials

Fig. 1.1 Dose assignment

for the 3 + 3 design

initial escalation stage, called an accelerated stage, where one patient per dose level is treated, (ii) to account for moderate toxicity in addition to the dose-limiting toxicity, (iii) to have options to use intrapatient dose modification, and (iv) to analyze trial results by means of the model that incorporates parameters for intra- and inter-patient variation in toxicity and cumulative toxicity. They compared the operating characteristics of the 3 + 3 design with those of the three different designs with an accelerated phase. In addition, the best-of-5 design (Storer 2001) and the rolling six design (Skolnik et al. 2008) may be useful in practice.

1.4

Model-Based Methods

1.4.1

Bayesian CRM

The most well-known model-based method is the CRM developed by the O’Quigley et al. (1990). The CRM is the well-established prototype of the various recent model-based methods. The CRM involves a dose–toxicity model and estimates the model parameters based on the Bayesian theorem. For patient i , if a predefined toxicity is observed, primarily the dose-limiting toxicity, we denote Yi = 1; otherwise, Yi = 0.

We let Pr{ Yi = 1} be the probability that Yi = 1, often modeling this probability using a one-parameter logistic regression model with a fixed intercept β 0: Pr{ Yi = 1} = ψ(xi | β 1 ) =

exp (β 0 + β 1 xi ) ,

(1.1)

1 + exp (β 0 + β 1 xi )

where xi is the dose level of an agent for patient i, and β 1 is the regression coefficient. O’Quigley et al. (1990) also introduced alternate models, including power and hyperbolic tangent models. It should be noted that the numerical dose label xi s in the CRM is not necessarily the actual dose administered, but rather is defined on a conceptual scale that represents an ordering of the risks of toxicity based on initial guesses about toxicity probabilities, for example, skeleton.

In the original CRM, the first patient is allocated to the dose level initially believed to have toxicity closest to the target toxicity probability φ. After obtaining the data

1.4 Model-Based Methods

5

on the toxicity outcomes from the first j patients, D j = { y 1 , · · · , y j }, the CRM

updates the posterior estimates of toxicity probabilities for the dose levels through the estimation of the posterior probability distribution p j+1 (β 1| D j ) to determine the dose level allocated to the ( j + 1 ) th patient as follows: p j+1 (β 1| D j ) =

L j (β 1| D j ) p(β 1 )

∞

,

(1.2)

−∞ L j (β 1| D j ) p(β 1 )dβ 1

where L j (β 1| D j ) is the likelihood function of Eq. (1.1) for j patients; that is, j



L j (β 1| D j ) =

{ ψ(xi | β 1 )yi }{1 − ψ(xi | β 1 )( 1− yi)} , (1.3)

i =1

and p(β 1 ) is the prior probability distribution for β 1. In this simple one-parameter setting, the posterior estimate of β 1 may be most easily computed by a standard numerical quadrature method (e.g., trapezoidal rule), but computer-intensive simulation-based methods, such as the Markov chain Monte Carlo method, have been widely applied. Using the posterior mean of β 1, the posterior estimates of toxicity probabilities for the dose levels were obtained. The dose level (at which posterior toxicity probability is the closest to the target value φ) was then determined, and the ( j + 1 ) th patient was allocated to that dose level. Thus, dose allocation based on the posterior toxicity probability was performed until the maximum sample size N max was reached. Eventually, the dose level with a posterior toxicity probability closest to the target value φ at the end of the trial was selected as MTD. Figure 1.2 shows the trace plot of dose assignment for the Bayesian CRM.

Practical performance of the CRM can be improved by introducing a safety stopping rule, by limiting each dose escalation to one level, and by treating patients in cohorts (Goodman et al. 1995). When treating in cohorts of three using the same dose level within the cohort, the first three patients are allocated to the lowest dose level in practice owing to ethical considerations. Cheung (2011) provided comprehensive reviews and extensive discussions of the CRM.

Fig. 1.2 Dose assignment

for the Bayesian CRM





6

1

Dose Finding in Phase I Cancer Trials

1.4.2

Other Relevant Designs

Babb et al. (1998) developed a dose-finding method that includes the escalation with overdose control on the basis of the Bayesian CRM. In this design, the expected proportion of patients treated at doses higher than the MTD is equal to a fixed level, α.

Ji et al. (2007) proposed a simple dose-finding method that uses a beta/binomial model and a dose assignment rule based on posterior toxicity probabilities. Ji et al.

(2010) devised the modified toxicity probability interval method by introducing the unit of probability mass that, given an interval and a probability distribution, is defined as the ratio of the probability mass of the interval to the length of the interval. Liu and Yuan (2015) additionally proposed an optimal Bayesian interval design that determines the dose escalation or de-escalation for the next cohorts of patients on the basis of the observed toxicity rate while minimizing the decision error of dose assignment.

References

Babb, J., Rogatko, A., Zacks, S.: Cancer phase I clinical trials: efficient dose escalation with overdose control. Stat. Med. 17, 1103–1120 (1998)

Carter, S.K.: Study design principles for the clinical evaluation of new drugs as developed by the chemotherapy program of the National Cancer Institute. In: Staquet, M.J. (ed.) The Design of Clinical Trials in Cancer Therapy, pp. 242–289. Editions Scientifiques Europrennes, Brussels (1973)

Cheung, Y.K.: Dose Finding by the Continual Reassessment Method. Chapman and Hall, London (2011)

Chevret, S.: The continual reassessment method in cancer phase I clinical trials: A simulation study.

Stat. Med. 12, 1093–1108 (1993)

Eisenhauer, E.A., Twelves, C., Buyse, M.: Phase I Cancer Clinical Trials: A Practical Guide. Oxford University Press, New York (2015)

Goodman, S.N., Zahurak, M.L., Piantadosi, S.: Some practical improvements in the continual reassessment method for phase I studies. Stat. Med. 14, 1149–1161 (1995) Iasonos, A., Wilton, A.S., Riedel, E.R., Seshan, V.E., Spriggs, D.R.: A comprehensive comparison of the continual reassessment method to the standard 3 + 3 dose escalation scheme in phase I dose-finding studies. Clin. Trials 5, 465–477 (2008)

Jain, R.K., Lee, J.J., Hong, D., Markman, M., Gong, J., Naing, A., Wheler, J., Kurzrock, R.: Phase I oncology studies: evidence that in the era of targeted therapies patients on lower doses do not fare worse. Clin. Cancer Res. 16, 1289–97 (2010)

Ji, Y., Li, Y., Bekele, B.N.: Dose-finding in oncology clinical trials based on toxicity probability intervals. Clin. Trials 4, 235–244 (2007)

Ji, Y., Liu, P., Li, Y., Bekele, B.N.: A modified toxicity probability interval method for dose-finding trials. Clin. Trials 7, 653–663 (2010)

Le Tourneau, C., Dieras, V., Tresca, P., Cacheux, W., Paoletti, X.: Current challenges for the early clinical development of anticancer drugs in the era of molecularly targeted agents. Target Oncol.

5, 65–72 (2010)

Lin, Y., Shih, W.J.: Statistical properties of the traditional algorithm-based designs for phase I cancer clinical trials. Biostatistics 2, 203–215 (2001)

References

7

Liu, S., Yuan, Y.: Bayesian optimal interval designs for phase I clinical trials. Appl. Stat. 64, 507–523

(2015)

O’Quigley, J., Chevret, S.: Methods for dose finding studies in cancer clinical trials: a review. Stat.

Med. 10, 1647–1664 (1991)

O’Quigley, J., Pepe, M., Fisher, L.: Continual reassessment method: a practical design for phase I clinical trials in cancer. Biometrics 46, 33–48 (1990)

Simon, R.M., Freidlin, B., Rubinstein, L., Arbuck, S.G., Collins, J., Chiristian, M.C.: Accelerated titration designs for phase I clinical trials in oncology. J. Natl. Cancer Inst. 89, 1138–1147 (1997) Skolnik, J.M., Barrett, J.S., Jayaraman, B., Patel, D., Adamson, P.C.: Shortening the timeline of pediatric phase I trials: the rolling six design. J. Clin. Oncol. 26, 190–195 (2008) Storer, B.E.: Design and analysis of phase I clinical trials. Biometrics 45, 925–937 (1989) Storer, B.E.: An evaluation of phase I clinical trial designs in the continuous dose-response setting.

Stat. Med. 20, 2399–2408 (2001)





Chapter 2

Dose Finding for a Combination

of Two Agents

Abstract Two-agent combination trials—involving a dose combination of two already marketed drugs or a single new investigational drug to be used in combination with an approved drug—have rapidly increased in number. The concurrent development of two new agents intended for use in combination to treat a disease has attracted significant attention. Many authors have attempted to capture a dose–toxicity relationship for combination of two agents and to identify MTD combinations for two agents. This chapter reviews the dose-finding methods for two-agent combination trials along with the comparative analysis of these methods.

Keywords Combination of two agents · Comparative study · MTD combination Synergistic effect

2.1

Introduction

2.1.1

Two-Agent Combination Trials

The testing of drug combinations based on a strong biological rationale is increasingly seen in phase I trials. Effective treatment of cancer frequently requires the use of combinations of drugs because even if a cancer seems sensitive to one drug initially, cellular heterogeneity can lead to the emergence of drug-resistant disease (Marusyk et al. 2012). A combination of drugs can target cancer cells that have differing drug sensitivity levels, achieve a higher intensity of dose if the drugs have nonoverlapping toxicities, and can reduce the risk of drug resistance (Dancey and Chen 2006). Drug combinations have been repeatedly shown to improve survival among patients with either early-stage or advanced-stage cancer. Recently, cancer immunotherapies, such as monoclonal antibodies blocking the inhibitory programed cell death 1 pathway (PD-1–PD-L1), have made a great impact on cancer treatments. Despite the remark-able clinical efficacy of these agents against various malignant tumors, it was found that they are not sufficiently active for many patients. For example, to address this

© The Author(s), under exclusive licence to Springer Japan KK, part of Springer Nature 2018

9

A. Hirakawa et al., Modern Dose-Finding Designs for Cancer Phase I Trials: Drug Combinations and Molecularly Targeted Agents, JSS Research Series in Statistics, https://doi.org/10.1007/978-4-431-55573-5_2





10

2

Dose Finding for a Combination of Two Agents

issue, the combined inhibition of PD-1 and CTLA-4 in melanoma and non small cell lung cancer has highlighted the potential to further enhance the clinical benefits of monotherapies by combining agents with synergistic mechanisms of action (Kim and Alrwas 2014).

In the two-agent combination trials, estimation of the MTD combinations becomes more complex than for single-agent trials. When combining two agents, we need to consider a surface of probability of dose combinations where the dose of one or both agents can be altered. That is, multiple potential MTD combinations can be defined on the dose surface. The dose levels of two agents form various curves on the dose surface, called the MTD contour. We, therefore, need to precisely capture the dose–

toxicity relationship for the combinations and to identify the MTD combination.

Ideally, one or more MTD combinations should be identified while minimizing the total number of enrolled patients in phase I trials. Many authors have developed combination dose-finding methods, an overview of which is provided by Harrington et al. (2013). These methods can be generally classified as rule- or algorithm-based designs.

2.1.2

An Overview of Model-Based Dose-Finding Methods

In this chapter, we focus on model-based dose-finding methods for combinations, in which the primary aim is to find only one MTD combination. Conaway et al.

(2004) estimated the MTD combination by determining the complete and partial orders of the toxicity probabilities by defining nodal and non-nodal parameters. A nodal parameter is one whose ordering is known with respect to all other parameters.

Although the method of Conaway et al. (2004) does not rely on a parametric dose–

toxicity model, it is not an algorithmic- or rule-based design; therefore, we chose to discuss it in the set of model-based approaches. This method was implemented in a phase I trial investigating induction therapy with bortezomib and vorinostat in patients with surgically resectable non small cell lung cancer (Jones et al. 2012).

Yin and Yuan (2009a, b) developed Bayesian adaptive designs based on latent 2 ×

2 tables and a copula-type model for two agents. Braun and Wang (2010) proposed a hierarchical Bayesian model for the probability of toxicity of two agents. Wages et al. (2011a, b) developed both Bayesian and likelihood-based designs that laid out possible complete orderings associated with the partial order and applied model selection techniques and the CRM to estimate the MTD combination. Hirakawa et al.

(2013) proposed a dose-finding method based on the shrunken predictive probability of toxicity for combinations. Riviere et al. (2014) devised a Bayesian dose-finding design based on the logistic model, whereas Mander and Sweeting (2015) published a curve-free method that relies on the mathematical product of independent beta probabilities.

These methods can be roughly categorized into two groups: (1) those using a flexible model, with or without an interaction term, to jointly model the toxicity probability at each dose pair of the two agents; and (2) those that involve a more





2.1 Introduction

11

underparametrized approach, relying upon single-parameter “CRM-type” models and/or order-restricted inference (Barlow et al. 1972). For those in group (1), we focus on the method based on a copula-type (Yin and Yuan 2009b) model, termed the YYC method. We also introduce the method involving a hierarchical Bayesian model (Braun and Wang 2010), termed the BW method. Besides, we describe the methods using a shrinkage logistic model (Hirakawa et al. 2013), termed the HHM

method, and the ordinary logistic model (Riviere et al. 2014), termed the RYDZ

method. For the methods in group (2), we chose likelihood-based CRM for partial ordering (POCRM) (Wages et al. 2011b), termed the WCO method, as well as the order-restricted inference method of Conaway et al. (2004), termed the CDP

method.

2.1.3

Methodological Characteristics

Here, we overview the six above-mentioned dose-finding methods. The methodological characteristics of each design are summarized in Table 2.1. The YYC, BW, and RYDZ methods have been developed based on Bayesian inference, whereas the HHM and WCO methods have been developed based on likelihood inference.

The principle of CDP is the estimation procedure of Hwang and Peddada (1994).

The YYC, HHM, and RYDZ methods model the interactive effect of two agents on the toxicity probability, but the BW method does not. The WCO method is based on the CRM and uses a class of underparametrized working models based on a set of possible orderings for the true toxicity probabilities. In terms of the restriction on skipping dose levels, the BW method allows for simultaneous escalation or de-escalation of both agents, whereas methods YYC, CDP, HHM, and RYDZ

do not. Notably, the RYDZ method enables simultaneous escalation of both agents in the start-up dose escalation rule that is generally incorporated to gather enough information for Bayesian estimation at an early stage of trials. On the other hand, the WCO method allows for a flexible movement of dose levels throughout the trial and does not restrict movement to “neighbors” in the two-agent combination matrix.

In the following section, we introduce both the statistical model for capturing the dose–toxicity relationship and the dose-finding algorithm for exploring the MTD

combinations because almost all the dose-finding methods for two-agent combination trials have often been developed by improving or devising these components of the method. The other detailed design characteristics are not shown in this book. We considered a two-agent combination trial using agents A j ( j = 1 , . . . , J ) and Bk ( k = 1 , . . . , K ), respectively, throughout. We denote the probability of toxicity as π, and the targeting toxicity probability specified by physicians as φ. The other symbols are independently defined by the dose-finding methods we compared.

12

2

Dose Finding for a Combination of Two Agents

BW); Dubois,

YYC

(2004

uan,

the

Y

as

eddada

iere,

s

s

P

iv

YDZ

R

R

Bayesian

Logistic

Ye

Ye

3

Same

method

and

=

,

YDZR

YYC

Dunbar

);

the

ay,w

as

(2013

elihood

s

Cona

HHM

Lik

Shrinkage

No

Ye

3

Same

method

=

Matsui

CDP

and

);

(2009b

Hamada,

a,

elihood

skipping

uan

w

wer

s

Y

WCO

Lik

Po

Ye

No

1

No

restriction

and

irakaH

in

=

both

Y

of

ut

fo

=

el

b

ro

HHM

lev

YYC

);

only

dose

s

wing

(2011b

BW

Bayesian

Hierarchical

Ye

No

1

One

change

allo

simultaneous

escalation

de-escalation

agents

y

methods.

O’Quigle

Peddada

YYC

and

the

dose-finding

and

)

as

ay,

six

ang

w

the

CDP

Hw

(1994

None

No

No

1

Same

method

fo Cona

not

of

both

ages,

fo

W

el

and

r

=

lev

o

only

characteristics

dose

WCO

s

s

wing

);

YYC

Bayesian

Copula

Ye

Ye

3

One

change

allo

simultaneous

escalation

de-escalation

agents

(2010

in

in

)

ang

model

sed

aper

W

the

u

p

Methodological

f

skipping

els

(2014

effect

o

ev

lev

.1

and

size

2

ohar

toxicity

odel

riginal

Z

m

o

dose

ble

raun

a

B

arametric

T

=

and

Method

Estimation

P

dose–toxicity

Prior

probability

specification

Inclusion

interacti

the

Cohort

the

Restriction

on





2.2 The Bayesian Approach Based on Copula Regression 13

2.2

The Bayesian Approach Based on Copula Regression

2.2.1

Copula-Type Models

Let p j and qk be the prespecified toxicity probability corresponding to A j and Bk, β

respectively, and subsequently pα and q will be the true probabilities of toxicity for j

k

agents A and B, respectively, where α > 0 and β > 0 are unknown parameters. Let the true probability of toxicity at combination (A j , Bk) be denoted as π jk. Yin and Yuan (2009b) proposed to use a copula-type regression model in the form of



−1 /γ

π

β

j k = 1 −

( 1 − pα)− γ + ( 1 − q )− γ − 1

,

(2.1)

j

k

where γ > 0 characterizes the interaction of two agents. They also introduced the use of the Gumbel–Hougaard copula model. The joint probability is modeled by γ

π

1 /γ

β

1 /γ

j k = 1 − exp

− −log ( 1 − pα)

+ −log ( 1 − q )

.

(2.2)

j

k

It should be noted that Gasparini et al. (2010) objected to the use of copulas for modeling the joint probability of toxicity because the above model has limitations in the modeling of drug–drug interactions. Further discussions are given in Gasparini et al. (2010).

For the method based on the copula model, using the data obtained at that time point, the posterior distribution is obtained by

f (α, β, γ |Data ) ∝ L(α, β, γ |Data ) f (α) f (β) f (γ ), (2.3)

where L(α, β, γ |Data ) is the likelihood function of the model and f (α), f (β), and f (γ ) are prior distributions, respectively. The Gibbs sampling algorithm is used to sample from the posterior distributions of the unknown parameters. When performing this procedure, we need to elicit the prior toxicity probabilities p j and qk from investigators. In two-agent combination phase I trials, the highest dose level of each agent may often be the MTD that has been identified in each monotherapy phase I trial; therefore, it is reasonable to set the prior toxicity probability of pJ (or qK ) equal to target φ (i.e., 0.30). The remaining toxicity probabilities ( p 1 , . . . , pJ−1

and q 1 , . . . , pK−1) could be based on the investigator elicitations, but it recommends selecting an even distribution from 0 to φ. We also need to specify hyperparameters α, β, and γ . Although we cannot change them in the software released by Yin and Yuan

(2009b), those authors have examined the sensitivity of operating characteristics for α and β and reported that this method is robust at different hyperparameter values.

The Gamma(2, 2) priors for α and β as well as the Gamma(0.1, 0.1) prior for γ are further recommended for the Clayton-type copula.





14

2

Dose Finding for a Combination of Two Agents

2.2.2

The Dose-Finding Algorithm

Suppose ce and cd are the fixed probability cutoffs for dose escalation and de-escalation, respectively. Dose escalation or de-escalation are restricted to one dose level of change only, while not allowing translation along the diagonal direction (corresponding to simultaneous escalation or de-escalation of both agents). As Yin and Yuan (2009b) pointed out in their paper, their dose-finding algorithm may be difficult to implement early in the trial owing to limited available data. Therefore, the following start-up rule is enforced to collect a certain amount of data for stabilizing parameter estimation before beginning the model-based dose finding.

1. Treat patients along the vertical dose escalation in the order { (A 1 , B 1 ), . . . , (A 1 , BK )} until the first toxicity is observed.

2. Treat patients along the horizontal dose escalation in the order { (A 2 , B 1 ), . . . , (AJ , B 1 )} until the first toxicity is observed.

After the start-up rule for stabilizing parameter estimation, the dose-finding algorithm functions as follows:

1. If, at the current dose combination ( j , k), Pr (π jk < φ) > ce, then the dose is escalated to an adjacent dose combination with the probability of toxicity higher than the current value and closest to φ. If the current dose combination is ( AJ , BK ), then the doses remain at the same levels.

2. If, at the current dose combination ( j , k), Pr (π jk > φ) > cd, then the dose is de-escalated to an adjacent dose combination with the probability of toxicity lower than the current value and closest to φ. In the case the current dose combination is ( A 1, B 1), the trial is terminated.

3. Otherwise, the next cohort of patients continues to be treated with the current dose combination (doses staying at the same levels).

4. Once the maximum sample size N max is achieved, the dose combination that has the probability of toxicity that is the closest to φ is selected as the MTD

combination.

2.2.3

Software Implementation

In this section, we use the software released by Yin and Yuan (2009b) to implement their method. Readers can download the .exe file from

http://odin.mdacc.tmc.edu/~yyuan/index_code.html.

In this program, we input the following configurations: the number of dose levels for two agents, their true joint toxicity probabilities for dose combinations, the target toxicity probability, prior estimates of toxicity probabilities for dose levels for each agent, the total number of cohorts, the cohort size, and the number of simulated trials.

For example, we obtain the following simulation results when two dose levels for each agent are tested:





2.2 The Bayesian Approach Based on Copula Regression 15

--------------------------------------------------

CPU time (hour)= 0.00208444

# of trials = 10

The number of cohorts = 10; cohort size = 3

Escalate if Pr(toxicity<0.3) > 0.8

De-escalate if Pr(toxicity<0.3) < 0.45

True toxicity probabilities:

0.15

0.20

0.40

0.10

0.15

0.35

0.05

0.10

0.30

Selection probabilities (%):

10.0

20.0

20.0

0.0

20.0

10.0

0.0

0.0

20.0

Number of patients treated at each dose:

2.4

3.3

1.8

3.3

1.2

2.4

6.9

4.2

4.5

Number of toxicities observed at each dose:

0.2

0.7

0.9

0.5

0.5

0.9

0.3

0.4

1.3

Total number of observed toxicities: 5.7

Percentage of inconclusive trials: 0.0%

--------------------------------------------------

At the default settings, ce and cd are set to 0.8 and 0.45, respectively. By means of the C++ program (copula.cpp), we can change the values for ce and cd . We can next select a copula model (i.e., Clayton or Gumbel copula model) and the prior distributions for their model parameters.

2.3

Hierarchical Bayesian Design

2.3.1

Hierarchical Models

Braun and Wang (2010) developed a novel hierarchical Bayesian design for combination trials. Let a j and bk be the dose levels corresponding to A j and Bk, respectively, whose values are not the actual clinical values of the doses, but are the “effective”

dose values that will lend stability to their dose–toxicity model. It is assumed that

16

2

Dose Finding for a Combination of Two Agents

each π jk has a beta distribution with parameters α jk and β jk. Notably, α jk(β jk) can be interpreted as the prior number of patients assigned to combination ( j , k) expected to manifest (or not manifest) toxicity. Braun and Wang (2010) proposed model α jk and β jk using the parametric functions of a j and bk, log α jk(θ) = θ 0 + θ 1 a j + θ 2 bk and log β jk(λ) = λ 0 − λ 1 a j − λ 2 bk, (2.4) respectively, where θ = { θ 0 , θ 1 , θ 2} obeys a multivariate normal distribution with mean μ = { μ 0 , μ 1 , μ 2}, λ = { λ 0 , λ 1 , λ 2} follows a multivariate normal distribution with mean ω = { ω 0 , ω 1 , ω 2}, and both θ and λ have variance σ 2 I 3, in which I 3 is a 3

× 3 identity matrix. The samples from the posterior distribution for ( θ, λ) are easily obtained by Markov chain Monte Carlo methods. These samples lead to posterior distributions for each element of θ and λ, which in turn lead to a posterior distribution for each π jk. The corresponding posterior means ¯ π jk are calculated.

The BW method necessitates careful elicitation of priors and effective dose values.

Development of priors begins with the specification of p j 1 and q 1 k, which are a priori values for E (π j 1 ) and E (π 1 k). Braun and Wang (2010) set the lowest dose of each agent to zero, i.e., a 1 = b 1 = 0. Consequently, log (α 11 ) = θ 0 and log (β 11 ) = λ 0, and therefore θ 0 and λ 0 describe the expected number of toxicities for combination (A 1 , B 1 ), and the remaining parameters in θ and λ will describe how the expected toxicities for other combinations are related to (A 1 , B 1 ). They also used the fact that Sp 11

α

= 11 = exp{ θ 0} = exp{ μ 0} .

(2.5)

S( 1 − p 11 )

β 11

exp{ φ 0}

exp{ ω 0}

Then, the prior values for μ 0 and ω 0 are obtained via μ 0 = log (Sp 11 )

and

ω 0 = log (S [1 − p 11] ),

(2.6)

where S = 1,000 was chosen as a scaling factor to keep both hyperparameters

√

sufficiently above 0. Furthermore, they select μ 1 = μ 2 = ω 1 = ω 2 = 2 σ 2 so that 97.5% of the prior distributions for θ 1 , θ 2 , λ 1, and λ 2 will lie above 0, depending upon the value of σ 2. Those authors point out that a value in the interval [5 , 10] is often sufficient in their settings for adequate operating characteristics, but each trial setting will require fine-tuning of σ 2. They next define elicited odds ratios that can be approximated by

˜ ξj· ≈ exp{ (μ 1 + ω 1 )aj} and ˜ ξ· k ≈ exp{ (μ 2 + ω 2 )bk} , (2.7)

in which effective doses are obtained by solving for a j and bk. All doses are rescaled to be proportional to log-odds ratios relative to combination (A 1 , B 1 ). The derivation of priors and effective dose values in the BW method is somewhat complex, and it is recommended to read the original paper about the BW method for further detail.





2.3 Hierarchical Bayesian Design

17

We need to elicit the toxicity probability parameters p j 1 and q 1 k from investigators.

As we described in the previous section, the values of pJ 1 and q 1 K are generally set to 0.3, and the toxicity probabilities of all dose combinations are set arithmetically.

We assessed operating characteristics of the BW method for three values of σ 2, i.e., σ 2 = {3 , 5 , 10}. The best overall performance was obtained with σ 2 = 3, while the BW method for σ 2 = 5 (or 10) performed worse in our simulations. This finding indicates that we need to fine-tune the value of σ 2 in practice, as Braun and Wang

(2010) suggested.

2.3.2

The Dose-Finding Algorithm

The BW method accrues all patients in a single stage, rather than in two stages. The dose-finding algorithm is similar to that of the YYC method after the YYC start-up rule.

1. The first subject is assigned to combination ( A 1, B 1).

2. Compute a 95% confidence interval for the overall toxicity rate among all combinations using the cumulative number of observed toxicities for subjects 1 , 2 , . . . , (i − 1 ). If the lower bound of the confidence interval is greater than the target toxicity rate, φ, terminate the trial.

3. Otherwise, use the outcomes and assignments of subjects 1 , 2 , . . . , (i − 1 ) to determine the posterior distribution of each π jk, with posterior means ¯ π jk.

4. Extract the set of dose combinations, that is,

S = { ( j, k) | ji−1 − 1 ≤ j ≤ ji−1 + 1 , ki−1 − 1 ≤ k ≤ ki−1 + 1} , that contains combinations that are within one dose level of the corresponding doses in the combination assigned to the most recently enrolled patient (1, 2, · · · , ( i − 1)), and subsequently allocate the dose combination ( j∗, k∗) in S as the one with the smallest | ¯ π jk − φ| to the next patient i.

5. Repeat these steps until maximum sample size N max is reached. Upon completion of enrollment and follow-up of Nmax patients, identify the MTD combination based on steps 3 and 4.

2.3.3

Software Implementation

To employ the BW method, readers can use the R code released at

http://www-personal.umich.edu/~tombraun/BraunWang/.

Brawn and Wang (2010) provided the following five pieces of code.

get.mtc.r

R code that will identify the optimal combination for the next patient to be enrolled based on the data collected on enrolled patients

18

2

Dose Finding for a Combination of Two Agents

run.onesim.r

R code that will run one simulated trial

jags model.txt

text file containing hierarchical model description in WinBUGS

syntax

Actual Trial.r

R code to find a dose combination to assign to the fourth subject in a hypothetical trial

Simulation Study.r

Sample R code to run a simulation study composed of 1,000

simulations

The simulation study of the BW method can be easily executed by means of the run.onesim.r and jagsmodel.txt. We specify prior toxicity probabilities for each combination, true toxicity probabilities, the target rate of toxicity, maximum sample size, the prior variance parameter, starting doses, and the number of simulations. It should be noted that based on the results of our simulation studies, we recommend that the variance parameter σ 2 be set to 3 to stabilize the implementation of the R package rjags.

For example, the following simulation results are obtained if we execute the pieces of code below:

--------------------------------------------------

#Prior toxicity probabilities for each combination

p.prior <-

matrix(c(0.15,0.20,0.25,0.30,0.30,0.35,0.40,0.45),

nrow=2, ncol=4, byrow=TRUE)

#True toxicity probabilities

p.true <-

matrix(c(0.05,0.10,0.20,0.30,0.10,0.20,0.30,0.40),

nrow=2, ncol=4, byrow=TRUE)

#Targeted rate of DLTs

p.star <- 0.3

#Maximum sample size

m <- 30

#Prior variance parameter

s2 <- 3

#Starting doses

j.start <- 1

k.start <- 1

Run simulations

mysims <- NULL

Nsim <- 10

for (i in 1:Nsim)

{

set.seed(i)

temp <-

run.onesim(m, p.true, p.prior, p.star, s2, j.start, k.start,

dir) mysims <- rbind(mysims, temp)

2.3 Hierarchical Bayesian Design

19

}

#Tabulate number of times each combo chosen as MTC

ndose.a <- ncol(p.prior)

ndose.b <- nrow(p.prior)

a <- mysims[,1]

b <- mysims[,2]

mtc.table <- table(c(b, paste(rep(0:ndose.b, ndose.a+1))),

c(a, rep(0:ndose.a, rep(ndose.b+1,ndose.a+1))))-1

rm(a,b)

colnames(mtc.table) <- paste(rep("A",ndose.a+1), 0:ndose.a, sep="")

rownames(mtc.table) <- paste(rep("B",ndose.b+1), 0:ndose.b, sep="")

> mtc.table

A0 A1 A2 A3 A4

B0

0

0

0

0

0

B1

0

1

2

3

1

B2

0

1

0

2

0

#Tabulate average number of patients assigned to each combo

a <- mysims[,m:(2*m-1)+4]

b <- t(matrix(as.numeric(paste(rep(1:ndose.a,ndose.b),

rep(1:ndose.b, rep(ndose.a,ndose.b)), sep="")),

nrow=ndose.a*ndose.b, ncol=nrow(a)))

a <- cbind(a,b)

b <- t(apply(a, 1, table)-1)

nsubj.table <-

matrix(apply(b, 2, mean), ncol=ndose.a, nrow=ndose.b, byrow=F)

rm(a,b)

colnames(nsubj.table) <- paste(rep("A",ndose.a), 1:ndose.a, sep="")

rownames(nsubj.table) <- paste(rep("B",ndose.b), 1:ndose.b, sep="")

> nsubj.table

A1

A2

A3

A4

B1 4.0 5.4 6.3 2.9

B2 2.9 4.4 2.4 1.7

--------------------------------------------------





20

2

Dose Finding for a Combination of Two Agents

2.4

An Approach Using a Shrinkage Logistic Model

2.4.1

The Shrinkage Logistic Model

Hirakawa et al. (2013) developed a dose-finding method based on the shrinkage logistic model. They first model the joint toxicity probability πi for patient i using an ordinary logistic regression model with fixed intercept β 0 as follows: πi = exp (β 0 + β 1 xi 1 + β 2 xi 2 + β 3 xi 3 ) , (2.8)

1 + exp (β 0 + β 1 xi 1 + β 2 xi 2 + β 3 xi 3 ) where xi 1 and xi 2 are the actual (or standardized) dose levels of agents A and B, respectively, and xi 3 represents a variable of their interaction such that xi 3 = xi 1 × xi 2

for patient i .

Using the maximum likelihood estimates for parameters ˆ

βj ( j = 1, 2, 3), Hirakawa

et al. (2013) proposed the shrunken predictive probability:

˜ πi = exp (β 0 + ( 1 − δ 1 ) ˆ β 1 xi 1 + ( 1 − δ 2 ) ˆ β 2 xi 2 + ( 1 − δ 3 ) ˆ β 3 xi 3 ) , (2.9)

1 + exp (β 0 + ( 1 − δ 1 ) ˆ

β 1 xi 1 + ( 1 − δ 2 ) ˆ β 2 xi 2 + ( 1 − δ 3 ) ˆ β 3 xi 3 ) where shrinkage multiplier 1 − δ j ( j = 1 , 2 , and 3) is a number between 0 and 1.

Hirakawa et al. (2013) also developed the method for estimation of the shrinkage multipliers.

2.4.2

The Dose-Finding Algorithm

Hirakawa et al. (2013) invoke the following start-up rule-based dose allocation algorithm with the cohort size of three until the maximum likelihood estimate for each parameter is obtained.

1. The matrix of combinations is zoned according to its diagonals from the upper left entry to the lower right entry, as described in the WCO method.

2. The first cohort is allocated to the zone that includes the lowest dose combinations (A 1 , B 1 ). If a prespecified stopping rule is fulfilled, then we terminate the trial for safety. Otherwise, we will escalate to the next zone. If more than one dose combination is contained within a particular zone, we can sample without replacement from the dose combinations available, allocating the sampled dose combination to the next cohort. This sampling and allocation step is continued until all available dose combinations in that zone are tested.

3. During the above-mentioned step, the existence of maximum likelihood estimates for the regression coefficients is verified for every cohort of three patients, although we do not show this procedure in detail in this book. If we obtain the





2.4 An Approach Using a Shrinkage Logistic Model

21

maximum likelihood estimates, then the shrunken predictive probability of toxicity for each dose combination is calculated, and subsequently the following dose-finding algorithm is applied.

After obtaining the maximum likelihood estimates for the regression parameters, we calculate the shrunken predictive probability of toxicity for the current dose combination dc and then start the following dose-finding algorithm. We adopt the same restriction on the skipping dose level proposed in the YYC method. Let c 1 and c 2 be the allowable bands from target toxicity limit φ as MTD combinations.

1. If, at the current dose combination dc, φ − c 1 ≤ ˜ p(dc) ≤ φ + c 2, then the next cohort of patients continues to be allocated to the current dose combination.

2. Otherwise, the next cohort of patients is allocated to the dose combination with the shrunken predictive probability closest to φ among the adjacent or current dose combinations.

3. Once the maximum sample size N max is reached, the dose combination that should be assigned to the next cohort is selected as the MTD combination. In addition, if we encounter the situation where dc = d 1 and ˜ p(dc) > φ + c 2, then we terminate the trial for safety.

2.4.3

Software Implementation

The estimation of shrinkage multipliers is carried out using the SAS/IML software (SAS Institute Inc., Cart, NC). Given the data on dose levels of agents A and B, fixed intercept ( β 0), a maximum likelihood estimate for each coefficient ( ˆ

β 1, ˆ β 2, and ˆ β 3),

and first-order linear approximation of πi obtained by means of Eqs. (7) and (8) in Hirakawa et al. (2013), we estimate the shrinkage parameters ( δ 1, δ 2, and δ 3,) using the following function module and the NLPNRR subroutine for the Newton–Raphson ridge method in SAS/IML.

--------------------------------------------------

/************************************************/

d: shrinkage multipliers

dA: dose level of agent A

dB: dose level of agent B

Int: Fixed intercept

b1, b2, b3: Maximum likelihood estimate for each coefficient

pt: first-order linear approximation of true toxicity

probability obtained using Equations (7) and (8)

in ref. (Hirakawa et al., 20113)

/************************************************/

start l(d) global(dA,dB,Int, b1,b2,b3,pt);





22

2

Dose Finding for a Combination of Two Agents

ptilde=exp(Int+(1-d[1])#b1#dA+(1-d[2])#b2#dB

+(1-d[3])#b3#dA#dB)/(1+exp(Int+(1-d[1])#b1#dA

+(1-d[2])#b2#dB+(1-d[3])#b3#dA#dB));

logl=sum(pt#log(ptilde)+(1-pt)#log(1-ptilde));

return(logl);

finish l;

x0={0 0 0};

con={0 0 0,1 1 1};

optn={1 0};

call nlpnrr(rc,xr,"l",x0,optn,con);

if rc>0 then

d=xr[,1]||xr[,2]||xr[,3];

else

d=0||0||0;

--------------------------------------------------

2.5

An Approach Using a Logistic Model

2.5.1

The Logistic Model Involving Standardized Doses

Riviere et al. (2014) modeled the true probability of toxicity at combination (A j , Bk) πjk via an ordinary four-parameter logistic model as follows: logit (π jk) = β 0 + β 1 u j + β 2 vk + β 3 u j vk, (2.10)

where u j and vk are the standardized doses for the j th level of agent A and the k th level of agent B; β 0 , β 1 , β 2, and β 3 are unknown parameters that represent the intercept, the toxicity effects of agents A and B, and the interaction between the two agents, respectively. The standardized dose of two agents is defined as p j

qk

u j = log

, vk = log

,

(2.11)

1 − p j

1 − qk

where p j and qk are the prior probabilities of toxicity for agents A and B, respectively. Riviere et al. (2014) assumed a normal prior with mean 0 and variance 10 for the parameters of intercept ( β 0) and interaction term ( β 3), and presumed an exponential prior with a mean of 1 for β 1 and β 2. Thus, the joint posterior distribution of parameters β 0, β 1, β 2, and β 3 is given by f (β 0 , β 1 , β 2 , β 3 | Data ) ∝ L(β 0 , β 1 , β 2 , β 3 | Data ) f (β 0 ) f (β 1 ) f (β 2 ) f (β 3 ), (2.12)

where L(· ) is the likelihood function of model parameters. The posterior samples for each parameter are obtained by the Gibbs sampler.





2.5 An Approach Using a Logistic Model

23

2.5.2

The Dose-Finding Algorithm

Riviere et al. (2014) applied the dose-finding algorithm proposed by Yin and Yuan

(2009a). That is, they restricted dose escalation and de-escalation to one level at a time (i.e., we do not allow a dose to escalate or de-escalate along the diagonal). On the other hand, Sweeting and Mander (2012) showed that the diagonal escalation strategy may be more effective in reaching the target toxicity level with a limited sample size and can provide a higher percentage of correct selection of an MTD

combination. They, therefore, adopted this strategy in their start-up rule of the RYDZ

method. Notably, they also proposed a different criterion for the selection of an MTD

combination at the end of the trial. Once trial reaches the maximum sample size, the RYDZ method selects the dose combination with the highest posterior probability, Pr (π jk ∈ [ φ − δ, φ + δ] ),

(2.13)

which has been used to treat at least one cohort of patients, as the MTD combination.

Riviere et al. (2014) used δ of 0.1 in their simulation studies.

2.5.3

Software Implementation

We can avail ourselves of the RYDZ method using the R package dfcomb. Given the number and prior toxicity probabilities of agents A and B; values of φ, φ − δ, and φ + δ; the number of cohorts and cohort sizes; the probability threshold for dose escalation; dose de-escalation; and early trial termination with the minimum number of patients for early trial termination, the function CombIncrease_sim provides the operating characteristics of the RYDZ method as follows:

--------------------------------------------------

p_tox_sc1 = matrix(c(

0.10,0.20,0.30,

0.20,0.30,0.40,

0.30,0.40,0.50),nrow=3,ncol=3)

prior_a1 = c(0.1, 0.2, 0.3)

prior_a2 = c(0.1, 0.2, 0.3)

ndose_a1 = 3

ndose_a2 = 3

CombIncrease_sim(ndose_a1=ndose_a1, ndose_a2=ndose_a2,

p_tox=p_tox_sc1, target=0.30, target_min=0.20, target_max=0.40,

prior_tox_a1=prior_a1, prior_tox_a2=prior_a2, n_cohort=10,

cohort=3, tite=FALSE, nsim=1000, c_e=0.85, c_d=0.45, c_stop=1,

n_min=30, seed = 14061991)

True toxicities:

24

2

Dose Finding for a Combination of Two Agents

Agent 1

Agent 2

1

2

3

3 0.3 0.4 0.5

2 0.2 0.3 0.4

1 0.1 0.2 0.3

Percentage of Selection:

Agent 1

Agent 2

1

2

3

3 10.0 12.3

3.4

2 12.9 27.8 11.0

1

1.5 11.3

9.8

Number of patients:

Agent 1

Agent 2

1

2

3

3 1.99 2.38 2.14

2 3.31 7.25 2.11

1 5.81 2.92 2.10

Number of toxicities:

Agent 1

Agent 2

1

2

3

3 0.60 0.94 1.06

2 0.65 2.15 0.87

1 0.57 0.61 0.62

Percentage of inconclusive trials:

0

The minimum number of cohorts to stop the trial is:

10

Number of simulations:

1000

Cohort size:

3

Number of cohorts planned:

10

Total patients accrued:

30

Toxicity target:

0.3

Targeted toxicity interval:

[ 0.2 , 0.4 ]

Prior toxicity probabilities for agent 1:

[1] 0.1 0.2 0.3

Prior toxicity probabilities for agent 2:

[1] 0.1 0.2 0.3

Escalation threshold:

0.85

Deescalation threshold:

0.45

Stopping threshold:

1

Toxicity is not a time-to-event but binary

--------------------------------------------------





2.6 The Design Based on Order-Restricted Inference 25

2.6

The Design Based on Order-Restricted Inference

2.6.1

Order-Restricted Inference

The method proposed by Conaway et al. (2004) is based on the estimation procedure of Hwang and Peddada (1994). Parameter estimation subject to order restrictions is discussed by Hwang and Peddada (1994) and Dunbar et al. (2001). The method of Hwang and Peddada (1994) uses different estimation procedures for “nodal”

and “non-nodal” parameters. A nodal parameter is one whose ordering is known with respect to all the other parameters. For example, in a J × K matrix of drug combinations, the probability of toxicity, π 11, at combination ( A 1 , B 1) is a nodal parameter because it is known that π 11 ≤ π j+1 ,k and π 11 ≤ π j,k+1 for j, k ≥ 1.

For nodal parameters, estimation proceeds by establishing a simple order that is consistent with the partial order. This is done by guessing the unknown inequalities and by obtaining isotonic regression estimates of nodal parameters π jk based on the Pool Adjacent Violators Algorithm (PAVA). To estimate the non-nodal parameters, Hwang and Peddada (1994) eliminate the smallest number of parameters that make a non-nodal parameter into a nodal parameter. For instance, in a J × K

matrix of drug combinations, π 12 is a non-nodal parameter because it is unknown whether π 12 < π 21 or vice versa. Estimates of the non-nodal parameters can be obtained in a version of PAVA for simple orders that fixes the nodal parameters at their previously estimated values. Hwang and Peddada (1994) demonstrated that the resulting estimates satisfy the partial order. Conaway et al. (2004) computed estimates of the parameters for all possible guesses and averaged them to eliminate the dependence of the estimates on a single guess in the ordering among non-nodal parameters.

The approach of Conaway et al.(2004) is a two-stage design. The initial stage is intended to quickly escalate through treatment combinations that are nontoxic (in single-patient cohorts until the first toxicity is observed), and the second stage imple-ments the Hwang and Peddada (1994) approach. Throughout the second stage, the toxic response data for the i th treatment combination is of the form Y = { Y jk; j =

1 , . . . , J ; k = 1 , . . . , K } with Y jk equal to the number of observed toxicities among patients treated with combination (A j , Bk). Suppose A denotes the set of treatments that have been administered thus far in the trial such that A = { ( j, k) : n jk > 0}, where n jk represents the number of patients treated with each combination. With the Beta (α jk, β jk) prior for π jk, the toxicity probabilities are updated only for ( j, k) ∈ A.

ˆ πjk =

Y jk + α jk

(2.14)

n jk + α jk + β jk

The estimation procedure of Dunbar et al. (2001) is applied to the updated posterior means ˆ π jk for ( j, k) ∈ A.

If appropriate prior information is available to investigators, it is described via a prior distribution of the form π jk ∼ Beta (α jk, β jk). The investigators specify the





26

2

Dose Finding for a Combination of Two Agents

expected value of π jk and upper limit u jk such that they are 95% certain that the toxicity probability will not exceed u jk. The equations

αjk

E[ π jk] =

and

Pr[ π

α

j k ≤ u jk ] = 0 . 95

(2.15)

j k + β jk

are solved to obtain prior specifications for α jk and β jk. Another prior specification for the CDP method is to choose a subset of possible dose–toxicity orders based on ordering the combinations by rows, columns, and diagonals of the drug combination matrix. Following the guidance of Wages and Conaway (2013), we choose a subset of approximately 6–9 orderings. This approach provides an appropriate balance between choosing enough orderings so that we include adequate information to account for the uncertainty associated with partially ordered dose–toxicity curves, without increasing the dimensionality of the problem so much so that we dimin-ish performance. We arrange orderings according to movements across rows, up columns, and along diagonals. Because in a large matrix, there could be many ways to arrange combinations along a diagonal, we restrict movements to only moving across rows, up columns, and up or down any diagonal.

2.6.2

The Dose-Finding Algorithm

Stage 1: The first patient is entered at the starting treatment, usually combination (A 1 , B 1 ). The most appropriate treatment to which to escalate could possibly consist of more than one treatment combination. For example, in a matrix of combinations, the possible escalation treatment for ( 1 , 1 ) is ( 1 , 2 ) or ( 2 , 1 ). Therefore, if no toxicity is observed with ( 1 , 1 ), then the next patient is treated with a combination chosen from the “possible escalation treatments.” If no toxicity is observed in this patient, the next patient is assigned to a combination randomly chosen from the set of possible escalation treatments that have not yet been administered in the trial. Once a toxicity is observed, Stage 2 begins.

Stage 2: For all ( j, k) ∈ A, we compute the loss, L( ˆ π jk, φ), associated with each combination. As in Conaway et al. (2004), we implement a symmetric loss function so that L( ˆ π jk, φ) = | ˆ π jk − φ|.

1. Suppose lmin = min L jk( ˆ π jk, φ), and let C be the set of combinations with ( j,k)∈ A

losses equal to the minimum observed loss, C = { ( j, k) : L jk( ˆ π jk, φ) = lmin}.

2. If there is a single combination, c ∈ C, then the suggested combination is c, with an estimated toxicity probability of ˆ πc

3. If C contains more than one combination, then we randomly choose among them according to the following rules:

a. If ˆ πc > φ ∀ c ∈ C, then we randomly choose from the set C of candidate combinations.





2.6 The Design Based on Order-Restricted Inference 27

b. If ˆ πc ≤ φ for at least one c ∈ C, we choose randomly among the combinations in C that are expected to have the “highest” toxicity probability.

4. If the suggested combination has an estimated toxicity probability that is less than the target, a combination is chosen at random from the “possible escalation treatments” that have not yet been tested in the trial.

The averaged Hwang and Peddada (1994) estimates for each possible ordering pro-duce estimates ˆ π jk and the next patient is enrolled into the treatment with estimated toxicity probability closest to the target rate such that | ˆ π jk − φ| is minimized. Subsequent to a toxic or nontoxic response being observed for that patient, the toxicity probabilities are re-estimated and the trial proceeds.

2.7

The Partial-Ordering Continual Reassessment Method

2.7.1

The Model for Possible Orderings of Toxicity

Probability for a Dose Combination

The CRM for partial orders is based on utilizing a class of working models that correspond to possible orderings of the toxicity probabilities for the combinations. Specifically, suppose there are M possible orderings being considered that are indexed by m. For a particular ordering, we model the true probability of toxicity, π jk, corresponding to combination A j and Bk, via a power model π

βm

j k ≈ Fm (d jk , βm ) =

p jk(m)

;

m = 1 , . . . , M,

(2.16)

where p jk(m) represent the skeleton of the model at ordering m. We let the plausibility of each ordering under consideration be described by a set of prior probabilities τ = { τ( 1 ), . . . , τ(M)}, where τ(m) ≥ 0 and τ(m) = 1; m = 1 , . . . , M. From

accumulated data Ωi from i patients, the maximum likelihood estimate ˆ

βm of the

parameter βm can be calculated for each of the m orderings, along with the value of the log-likelihood, Lm( ˆ

βm | Ωi), at ˆ βm. Wages et al. (2011b) proposed an escalation method that first chooses the ordering that maximizes the updated probability ω(m) = exp{ Lm( ˆ βm | Ωi)} τ(m)

(2.17)

M

exp{ Lm( ˆ βm | Ωi)} τ(m)

m=1

before inclusion of each patient. If we denote this ordering as m∗, they use estimate ˆ βm∗ to evaluate the toxicity probabilities for each combination at ordering m∗ so that ˆ πjk ≈ Fm∗ (djk, ˆ βm∗ ).





28

2

Dose Finding for a Combination of Two Agents

A prior specification for the WCO method is to choose a subset of possible dose–

toxicity orders. We rely on the guidance of Wages and Conaway (2013) and choose approximately 6–9 orderings based on ordering the combinations by rows, columns, and diagonals of the drug combination matrix. Another specification that needs to be made prior to beginning the study is a set of skeleton values p jk(m). We can rely on the algorithm of Lee and Cheung (2009) to generate reasonable skeleton values using function getprior in R package dfcrm. We simply need to specify skeleton values at each combination that is adequately spaced (O’Quigley and Zohar 2010)

and to adjust them to correspond to each possible ordering, in order for the WCO

method to show good performance in terms of identifying an MTD combination.

The location of these skeleton values can be adjusted to correspond to each possible ordering using the getwm function in R package pocrm (Wages and Varhegyi 2013).

2.7.2

The Dose-Finding Algorithm

Within the framework of sequential likelihood estimation, an initial escalation scheme is needed, given that the likelihood fails to have a solution in the interior of the parameter space unless some heterogeneity (i.e., at least one toxic and one nontoxic) in the responses has been observed.

Stage 1: At the first stage, the WCO method makes use of “zoning” the matrix of combinations according to its diagonals. The trial begins in zone Z 1 = { (A 1 , B 1 )}, and the first cohort of patients is to be enrolled in this “lowest” combination. After the first detection of a toxicity in one of the patients, the first stage is closed, and the second (model-based) stage is opened. As long as no toxicities occur, cohorts of patients are examined at each dose within the currently occupied zone, before escalating to the next highest zone. If (A 1 , B 1 ) was tried and deemed “safe,” then the trial will escalate to zone Z 2 = { (A 1 , B 2 ), (A 2 , B 1 )}. If more than one dose is present within a zone, we can sample without replacement from the doses available within the zone. Therefore, the next cohort is enrolled into a dose that is chosen randomly from (A 1 , B 2 ) and (A 2 , B 1 ). The trial is not allowed to advance to zone Z 3 at the first stage until a cohort of patients has been observed at all combinations in Z 2. This procedure continues until a toxicity is observed or all available zones are exhausted.

Stage 2: Subsequent to a toxicity being observed, the second stage of the trial begins.

1. Based on accumulated data Ωi from i patients, the estimated toxicity probabilities ˆ πjk are obtained for all combinations being tested, by the procedure described above.

2. The next entering patient is then allocated to the dose combination with the estimated toxicity probability closest to the target toxicity rate so that | ˆ π jk − φ|

is minimized.





2.7 The Partial-Ordering Continual Reassessment Method 29

3. There is no skipping the restriction imposed on escalation to allow for adequate exploration of the drug combination space.

4. For trials subject to partial ordering, there may be more than one combination with toxicity probability closest to the target. If there is a “tie” between two or more combinations, the patient will be randomized to one of the combinations with the toxicity probability closest to the target. The trial stops once enough information accumulates about the MTD combination.

2.7.3

Software Implementation

Readers can apply the WCO method using R package pocrm. Given the true toxicity probabilities of agents A and B, the possible orderings, skeleton values, initial guesses of toxicity probabilities for each ordering based on function getprior in R package dfcrm, prior probability for each possible ordering, the size of patient cohorts, the number of patients for the stopping rule, maximum sample size, target toxicity rate, the number of simulations, and an acceptable toxicity range, function pocrm.sim provide the operating characteristics of the WCO method as follows:

--------------------------------------------------

#True toxicity rates .

r<-c(0.05,0.10,0.15,0.20,0.15,0.20,0.30,0.35,0.20

,0.30,0.60,0.70,0.60,0.65,0.70,0.80)

#Specify the possible orderings.

orders<-matrix(nrow=3,ncol=16)

orders[1,]<-c(1,2,5,3,6,9,4,7,10,13,8,11,14,12,15,16)

orders[2,]<-c(1,5,2,3,6,9,13,10,7,4,8,11,14,15,12,16)

orders[3,]<-c(1,5,2,9,6,3,13,10,7,4,14,11,8,15,12,16)

#Specify the skeleton values.

skeleton<-c(0.20,0.22,0.24,0.26,0.28,0.30,0.32,

0.34,0.36,0.38,0.40,0.42,0.44,0.46,0.48,0.50)

#Initial guesses of toxicity probabilities for each ordering.

alpha<-getwm(orders,skeleton)

#We consider all orders to be equally likely prior to the study.

prior.o<-rep(1/3,3)

#Initial escalation at Stage 1 proceeds according to the zones.

#Single patient cohorts are used.

x0<-c(rep(1,1),rep(2,1),rep(5,1),rep(3,1),rep(6,1),

rep(9,1),rep(4,1),rep(7,1),rep(10,1),rep(13,1),

rep(8,1),rep(11,1),rep(14,1),rep(12,1),rep(15,1),rep(16,1))

#Number of patients used to define stopping rule

stop<-31

#Maximum sample size.





30

2

Dose Finding for a Combination of Two Agents

n<-30

#The target toxicity rate

theta<-0.30

#Number of simulations

nsim<-100

#Definition of acceptable toxicity rates

tox.range<-0.05

fit<-pocrm.sim(r,alpha,prior.o,x0,stop,n,theta,nsim,tox.range)

fit

$true.prob

[1] 0.05 0.10 0.15 0.20 0.15 0.20 0.30 0.35 0.20

0.30 0.60 0.70 0.60 0.65 0.70 0.80

$MTD.selection

[1] 0.00 0.00 0.07 0.20 0.01 0.08 0.19 0.03 0.10

0.19 0.04 0.00 0.08 0.01 0.00 0.00

$patient.allocation

[1] 0.07 0.06 0.07 0.11 0.05 0.09 0.12 0.04 0.09

0.10 0.04 0.01 0.09 0.02 0.01 0.02

$percent.toxicity

[1] 0.3016667

$mean.n

[1] 30

$acceptable

[1] 0.41

--------------------------------------------------

2.8

Operating Characteristics

Little is known about the relative performance of competing model-based dose-finding methods for combination phase I trials. Some authors have compared their method with existing model-based methods (Wages et al. 2011a, b; Hirakawa et al. 2013). Wages et al. (2011b) reported that their method is competitive in comparison with the previously proposed method of Wages et al. (2011a), which has been demonstrated to have performance comparable to that of the methods of Conaway et al. (2004) and Yin and Yuan (2009a, b). Hirakawa et al. (2013) reported that their method is competitive relative to the methods of Yin and Yuan (2009a) and Wages et al. (2011b).

Riviere et al. (2014) compared two algorithm-based and four model-based dose-finding methods by means of three evaluation indices under 10 scenarios of a 3 × 5

dose combination matrix. Specifically, the two up-and-down designs using isotonic regression and the T -statistic proposed by Ivanova and Wang (2004) and Ivanova and Kim (2009), respectively, were selected as the algorithm-based methods; the loga-

2.8 Operating Characteristics

31

rithm, Clayton, and Gumbel model-based methods proposed by Wang and Ivanova

(2005) and Yin and Yuan (2009a, b), respectively, as well as the partial-ordering CRM proposed by Wages and Conaway (2011a) were selected as model-based methods. Among their conclusions was that the model-based methods performed better than the algorithm-based ones, as demonstrated in single-agent studies (Iasonos et al. 2008).

These comparisons have been made at limited and ideal settings with respect to the type of combination matrix, the position, and number of true MTD combinations, using few evaluation indices, and often for large sample sizes (i.e., ∼60). Nonetheless, in practice, we often encounter complex and various settings of phase I trials.

Specifically, (1) the dose combination matrices are not only of the square type (i.e., 3 × 3 and 4 × 4) but also of the rectangle type (2 × 4 and 3 × 5); (2) the underlying position and number of true MTD combinations possibly vary; and (3) the sample size is as small as 30 in practice. Furthermore, the operating characteristics of the dose-finding methods developed based on different principles should be compared via many evaluation indices. Hirakawa et al. (2015) and Hirakawa and Sato (2016)

examined performance of six methods based on six evaluation indices under 16 toxicity scenarios shown in Table 2.2. The target toxicity probability that is clinically allowed, φ, is set to 0.3. For each simulated trial, no stopping rule was specified to exhaust prespecified maximum sample size N max = 30. Each simulation study consisted of 1,000 trials. The other configurations of the methods are elaborated by Hirakawa et al. (2015) and Hirakawa and Sato (2016). The aim of simulation studies was to evaluate (1) how well each method identifies MTD combinations at and near the target rate, (2) how well each method allocates patients to combinations at and around the true MTD combination, and (3) how feasible it is to implement each method given its respective prior specifications and software capabilities.

Across the 16 scenarios, the YYC, CDP, BW, WCO, HHM, and RYDZ methods yielded average 34, 47, 40, 46, 42, and 48% recommendation rates for true MTD

combinations, respectively. The YYC, CDP, BW, WCO, HHM, and RYDZ methods showed average 41, 30, 33, 32, 25, and 31% recommendation rates for overly toxic dose combinations, respectively. The average number of patients allocated to true MTD combinations of the YYC, CDP, BW, WCO, HHM, and RYDZ methods averages 6, 11, 9, 10, 8, and 9, respectively. The overall percentages of observed toxicities of methods YYC, CDP, BW, WCO, HHM, and RYDZ were averaged 23, 32, 30, 28, 20, and 27%, respectively. The average number of patients allocated to a dose combination above the true MTD combinations of the YYC, CDP, BW, WCO, HHM, and RYDZ methods averages 8, 12, 11, 9, 5, and 8, respectively. In considering a benchmark for this summary measure, Cheung (2011) analyzed the ideal situation in which all patients are treated with the true MTD combination. In this case, we would expect a φ = 30% observed toxicity rate. Therefore, a design that results in roughly φ% toxicities on average per trial can be regarded as safe. The CDP, BW, and WCO methods yield the best performance with respect to an observed toxicity rate closest to the target toxicity rate. Cheung (2011) also consider that the recommendation rates for true MTD combinations are the most immediate index for accuracy, which can be used to compare different methods, while the entire distri-

32

2

Dose Finding for a Combination of Two Agents

eragevA

34

47

40

46

42

48

41

30

33

32

25

31

6

11

9

10

8

9

(continued)

16

2

22

20

26

20

24

54

32

35

34

32

47

0

5

4

5

3

3

15

37

34

33

41

42

35

49

47

43

34

24

40

8

8

6

9

7

5

14

18

39

33

44

44

57

41

37

37

32

31

29

4

8

8

10

7

12

13

30

51

38

39

30

34

25

26

28

19

15

26

6

11

8

8

5

6

12

2

38

29

36

22

40

47

25

32

36

29

21

1

8

5

8

5

7

11

72

92

83

86

70

84

n/a

n/a

n/a

n/a

n/a

n/a

10

24

23

21

15

20

10

49

41

38

48

46

35

40

34

39

29

19

35

10

10

8

12

9

7

9

39

53

39

49

47

35

26

10

26

20

12

18

6

12

10

11

8

8

8

5

23

24

23

29

42

55

39

41

46

32

42

1

5

6

5

5

8

7

33

46

28

37

31

33

42

20

25

29

22

22

5

11

6

7

3

5

(%)

6

44

43

37

40

49

50

32

41

39

36

22

36

9

9

8

10

8

10

(%)

combinations

5

59

80

58

77

64

82

combinations

27

10

17

13

12

11

MTD

12

17

12

16

9

14

dose

true

characteristics

combinations

to

4

6

29

36

31

38

50

70

36

37

44

36

35

1

6

9

7

6

10

toxic

MTD

erly

operating

3

v

true

26

25

24

32

28

30

o

54

54

48

55

48

57

allocated

6

5

5

7

6

4

the

for

for

of

atients

2

p

rates

70

81

66

73

66

85

rates

23

18

24

24

23

14

f

14

17

14

16

14

15

o

Summary

1

44

62

50

56

45

48

23

24

27

24

14

27

8

14

11

14

11

11

number

.22

ble

erage

a

YDZ

YDZ

v

YDZ

T

Scenarios

Methods

Recommendation

YYC

CDP

BW

WCO

HHM

R

Recommendation

YYC

CDP

BW

WCO

HHM

R

A

YYC

CDP

BW

WCO

HHM

R

2.8 Operating Characteristics

33

eragevA

23

32

30

28

20

27

8

12

11

9

5

8

0.45

0.59

0.48

0.57

0.52

0.59

16

22

30

30

24

13

29

9

12

12

8

2

13

0.34

0.53

0.47

0.53

0.40

0.45

15

24

31

30

26

17

26

9

15

14

9

3

10

0.58

0.55

0.48

0.58

0.50

0.51

14

26

35

32

28

20

28

10

14

13

9

5

8

0.42

0.56

0.45

0.57

0.56

0.66

13

22

31

31

26

18

26

4

10

10

6

1

7

0.50

0.67

0.50

0.61

0.48

0.57

12

26

35

33

32

29

28

9

12

12

11

9

7

0.36

0.60

0.54

0.64

0.56

0.67

11

20

27

27

26

21

24

n/a

n/a

n/a

n/a

n/a

n/a

0.37

0.56

0.40

0.47

0.37

0.44

10

24

31

31

29

24

27

9

12

12

9

6

10

0.54

0.53

0.39

0.59

0.52

0.49

combinations

9

18

25

27

25

17

24

3

4

8

5

2

4

0.43

0.60

0.42

0.55

0.54

0.56

TDM

8

25

34

31

28

19

26

true

10

15

12

12

6

8

0.30

0.53

0.51

0.51

0.58

0.66

theev

7

24

31

29

23

15

25

9

9

9

6

3

7

0.46

0.66

0.46

0.60

0.56

0.59

abo

6

24

34

31

27

18

26

5

15

12

9

3

7

0.45

0.56

0.49

0.53

0.62

0.61

combination

5

24

32

31

26

15

28

6

7

8

4

0

6

0.58

0.78

0.55

0.74

0.62

0.78

(%)

dosea

to

4

22

28

29

27

19

26

11

12

11

11

7

8

0.31

0.48

0.49

0.50

0.54

0.65

toxicities

3

ed

25

36

32

33

28

29

allocated

11

18

15

16

14

14

0.47

0.49

0.47

0.58

0.49

0.56

observ

atients

2

of

27

39

34

35

33

31

pf 6 11 10 9 11 8

0.72

0.82

0.71

0.76

0.69

0.86

o

x

(continued)

1

ercentage

22

31

30

28

22

27

3

10

9

7

3

7

inde

0.40

0.56

0.37

0.46

0.31

0.36

number

.2

p

y

2

ble

erall

erage

a

YDZ

v

YDZ

YDZ

T

Scenarios

Methods

Ov

YYC

CDP

BW

WCO

HHM

R

A

YYC

CDP

BW

WCO

HHM

R

Accurac

YYC

CDP

BW

WCO

HHM

R





34

2

Dose Finding for a Combination of Two Agents

bution of selected dose combinations does provide more detailed information than what the recommendation rates for true MTD combinations alone suggest. Cheung

(2011) proposed the accuracy index, after n patients, defined as J

K

| πjk − φ|× ρjk

j =1 k=1

Mn = 1 − J × K ×

,

(2.18)

J

K

| πjk − φ|

j =1 k=1

where π jk is the true toxicity probability of dose combination (A j , Bk), and ρ jk is the probability of selecting dose combination (A j , Bk). A large index indicates high accuracy, and the maximum value of the index is 1. Based on the accuracy index, the CDP and RYDZ methods showed the maximum value, 0.59, and the WCO method showed the second largest value: 0.57.

2.9

Effects of Design Properties

Many model-based methods include four design properties: patient cohort size, dose–

toxicity model, choice of the start-up rule, and whether or not to include a restriction on dose-level skipping. In the studies by Riviere et al. (2014) and Hirakawa et al. (2015), these design properties were kept as close as possible to those in published works, to be true to the original design intended by the authors because their goals were to compare the dose-finding designs implied by these published methods. Nevertheless, the rationale for choosing each design property, particularly the patient cohort size, dose–toxicity model, start-up rule, and whether or not to include a restriction on dose-level skipping, was not substantially investigated in these studies. When statisticians develop a new dose-finding method or modify an existing method, they are especially interested in the true effects of these properties. Thus, a fair comparison of these properties is necessary. Moreover, when planning phase I trials, investigators may need to change the four design properties of the model-based method for practical or ethical reasons. In such cases, understanding the true effects of these properties on the operating characteristics would be beneficial.

Hirakawa et al. (2016) analyzed the well-known four design properties and evaluated the impact of each independent effect on the operating characteristics of the dose-finding method at these properties. With respect to the properties of the design properties in the dose-finding methods for two-agent combination trials, Sweeting and Mander (2012) evaluated various dose escalation strategies in the six- and three-parameter dose–toxicity models for two-agent combination trials using a cohort size of two patients. Hirakawa et al. (2016) performed comprehensive simulation studies to primarily examine the effects of the four design properties on the identification of the true MTD combinations and exposure to unacceptable toxic dose combinations at the complex and various settings of two-agent combination trials.





2.9 Effects of Design Properties

35

In this section, we touch on the patient cohort size, the choice of a start-up rule, and whether or not to include a restriction on dose level skipping, along with the insights obtained from the results of the simulation studies (for examining the effects of these design properties) conducted by Hirakawa et al. (2016).

2.9.1

Size of Patient Cohorts

Dose-finding designs allocate a cohort of patients to each dose combination. The size of patient cohorts typically described in the statistical literature is conventionally in the range of 1–3 and may be related to the probability of identifying the true MTD

combination. This is because the total number of doses that can be tested during the trial depends on the number of patients and the size of the cohort. Notably, we supposed that the total sample size is fixed, and only the distribution into cohorts is the design element. For example, for a total sample size of 30, a cohort size of 1, 2, or 3 results in the use of up to 30, 15, or 10 doses, respectively. In this example, the cohort size of 3 enables toxicity data to be collected from more patients for a given dose combination. On the other hand, the opportunity to explore more dose combinations is lost. Selecting an appropriate cohort size is therefore an important consideration for investigators when designing a phase I trial.

According to the results of the simulation studies conducted by Hirakawa et al.

(2016), we observed that the selection rates for true MTD combinations decreased, and those for unacceptable toxicity dose combinations increased on average with the increasing patient cohort sizes. To have the best chance to identify the true MTD

combination and to avoid unacceptable toxicity of dose combinations, a cohort size of 1 may be favorable and unrelated to any of the other design properties. We expect that at a cohort size of 1, the selection rates for true MTD combinations are up to 5% higher than in studies that involve a cohort size of 2 or 3. Nonetheless, the use of a cohort size of 1 may be controversial in some trials, owing to concerns about the determination of dose escalation or de-escalation based on toxicity data from only one patient, especially at an early stage of a trial. Therefore, the development of a dose-finding method with variable patient cohort sizes during the trial is necessary, as stated by Kakurai et al. (2015). In addition, the smaller cohort size operationally requires more time to complete the trials. Depending on the circumstances of trial operation, one may prefer a cohort size of 2 (or 3) in practice.

2.9.2

The Choice of a Dose–Toxicity Model

To accommodate synergistic toxicity effects in two-agent combinations, several useful models have been proposed. For example, Thall et al. (2003) published a six-parameter model for determining the toxicity probabilities of dose combinations and a toxicity equivalence contour for two-agent combinations. Wang and Ivanova (2004)

proposed a logistic-type logarithm model. Yin and Yuan (2009a) introduced the use of the Clayton and Gumbel copula-type model. Hirakawa et al. (2013) developed

36

2

Dose Finding for a Combination of Two Agents

a shrinkage logistic model with an interaction term of two agents. When selecting a dose–toxicity model, one should pay attention to the number of parameters included in the model because this characteristic affects the results at limited sample sizes. In the present study, we focused on well-known three-parameter models for the following reasons: First, over the last decade, many authors tended to propose a three-parameter model rather than a one- or six-parameter model. To this end, authors of recent comparative studies on the rival dose-finding methods chose the methods based on the three-parameter models as competitors (Riviere et al. 2014; Hirakawa et al. 2015). Second, in addition to the specification of the four design properties chosen in this study, the specifications of the partial orderings are required for the one-parameter model (Wages et al. 2011a, b). With respect to the partial orderings, a key assumption for dose-finding methods for single-agent trials is the monotonicity of the dose–toxicity curve. In this case, the curve is said to follow a “complete order”

because the ordering of probabilities of toxicity for any pair of doses is known, and administration of greater doses of the agent can be expected to yield toxicity in an increasing proportion of patients. In studies testing combinations, the probabilities of toxicity often follow a partial order, in that there are pairs of combinations for which the ordering of the toxicity probabilities is not known. Such an assumption would make the comparison between the one-parameter and three-parameter models unsubstantial. Specifically, although we can compare the performance between the composite of one-parameter models and partial orderings and three-parameter models, we cannot fairly compare the independent (or crude) effects between the one-parameter and three-parameter models. Third, a fair comparison between the operating characteristics of the three-parameter and six-parameter models is also difficult because the six-parameter model described by Thall et al. (2003) also requires the inherent specifications of prior distributions for the model parameters. In the study by Hirakawa et al. (2016), the following logistic-type logarithm model introduced by Wang and Ivanova (2005) and modified by Gasparini (2013)—in addition to the Clayton and Gumbel Archimedean copula models proposed by Yin and Yuan

(2009a)—were compared.

Logarithm model π jk = 1 − ( 1 − p j )α( 1 − qk)β− αβγ log ( 1− pj), (2.19)

where π jk is the joint toxicity probability when combining agent A j ( j = 1 , . . . , J ) and Bk ( k = 1 , . . . , K ); p j and qk are the prespecified toxicity probabilities corresponding to agents A j and Bk, respectively.

Simulation studies revealed that the results generated by the dose–toxicity model are independent of whether the dose combination matrix is square or rectangular and of the position of MTD combinations in the dose combination matrix. All three dose–toxicity models evaluated were similar on average. Although we thoroughly examined the operating characteristics of the three dose–toxicity models, there may be frequently encountered situations that we did not consider. For instance, our simulations implied that the two agents are already approved because the prior toxicity probabilities for the highest dose level of both agents were commonly set to 0.30.

The highest dose level for each agent is assumed to be the MTD that has been deter-





2.9 Effects of Design Properties

37

mined in a single-agent trial. Thus, we assumed that the lowest and highest doses are both fixed in our simulation studies. In practice, however, phase I trials can involve combinations of new and approved agents or two new agents. Further simulation studies are necessary to optimize the dose-finding design for such trials. In addition to the specifications of prior toxicity probability, the operating characteristics of the dose–toxicity models vary depending on the prior distributions of model parameters in the dose combination matrix. Therefore, the reasonable choice of a dose–toxicity model may be the most difficult issue in planning dose-finding trials.

2.9.3

The Start-Up Rule

The start-up dose allocation rule is a rule-based algorithm that is applied until a certain amount of data is obtained. This rule is generally introduced to stabilize the Bayesian estimation of parameters in a chosen dose–toxicity model. For example, the start-up rule is often applied until toxicity is first observed. Here, we introduced the two popular start-up rules: those proposed by Yin and Yuan (2009a) and by Wages et al. (2011b). The start-up rule proposed by Yin and Yuan (2009a) involves treating patients along the vertical dose escalation in the order (A 1 , B 1 ), (A 1 , B 2 ), · · ·

until the first dose-limiting toxicity (toxicity) is observed. Patients are then treated along the horizontal dose escalation in the order (A 2 , B 1 ), (A 3 , B 1 ), · · · until the first toxicity is observed. We refer to this as the vertical and horizontal (VH) rule. A model-based dose-finding method is then designed. The rule of Wages et al. (2011b)

begins with dividing the dose combination matrix into several groups along the diagonals of the combination matrix. For example, in a 4 × 4 dose combination matrix, seven groups are generated. The trial begins at the lowest combination (A 1 , B 1 ) (the first group) and, in the absence of toxicity, escalates to the second group, (A 1 , B 2 ) and (A 2 , B 1 ). At this step, if the second cohort is allocated to (A 1 , B 2 ), we then automatically allocate the third cohort to (A 2 , B 1 ) and vice versa. That is, we sample without replacement from the dose combinations available until all the available dose combinations in that group are tested as long as no toxicity occurs. We refer to this principle as the diagonal rule.

In simulation studies, the VH and diagonal start-up rules may result in similar average selection rates for true MTD combinations and unacceptable toxicity dose combinations, irrespective of the dose combination matrix and MTD combination position. In addition, the VH rule is operationally easier to apply than the diagonal rule because it does not include a random sampling procedure.

2.9.4

Restrictions on Skipping Dose Levels

Any restrictions imposed on the skipping of dose levels during model-based dose finding may be a controversial issue in many phase I trials because of safety concerns.





38

2

Dose Finding for a Combination of Two Agents

The original CRM proposed by O’Quigley et al. (1990) allows us to skip dose levels during dose escalation or de-escalation in single-agent phase I trials. Partial-ordering CRM for identifying MTD combinations in two-agent combination phase I trials also imposes no restriction on dose-level skipping. Nevertheless, several authors argued that moving from a given dose, (A j , Bk), to dose (A j+1 , Bk+1 ) (i.e., increasing the doses of both agents) may expose patients to a higher risk of toxicity (Yin and Yuan,

2009a; Wages et al. 2011b). Therefore, it has been proposed that dose escalation or de-escalation should be restricted such that doses change only by one level at a time, and that the doses of both drugs are never simultaneously increased or simultaneously decreased (Restriction 1). The allowed dose combinations of Restriction 1 are defined as the following set:

S 1 = { ( j −1 , k), ( j +1 , k), ( j, k), ( j, k +1 ), ( j, k −1 ), ( j +1 , k −1 ), ( j −1 , k +1 )} .

(2.20)

Although Braun and Wang (2010) also limit dose adjustment to one level of change only, they allow simultaneous escalation or de-escalation of both agents (Restriction 2). Restriction 2 is defined by the following set:

S 2 = { ( j − 1 , k), ( j + 1 , k), ( j, k), ( j, k + 1 ), ( j, k − 1 ), ( j + 1 , k − 1 ), (2.21)

( j − 1 , k + 1 ), ( j − 1 , k − 1 ), ( j + 1 , k + 1 )}

Investigators should decide which type of restriction to use based on historical toxicity data of combinations of the two agents. Ultimately, for two drugs that are already approved, there will be more toxicity data available, and dose skipping can likely be less restricted.

In simulation studies, restricting dose-level skipping may improve the selection rates of true MTD combinations by up to 10% and could reduce the selection rates of dose combinations with unacceptable toxicity by up to 4% in our simulation studies.

Nonetheless, the effect of restriction on skipping a dose level varied depending on the patient cohort size. We recommend including a restriction on skipping dose levels when the cohort size is greater than or equal to 2. The choice of Restriction 1 or Restriction 2 makes no difference and, therefore, the choice can be conveniently made in many cases. To alleviate concerns regarding simultaneous escalation of the two agents during the trial, Restriction 1 may be appealing in practice.

References

Barlow, R.E., Bartholomew, D.J., Bremner, J.M., Brunk, H.D.: Statistical Inference under Order Restrictions: Theory and Application of Isotonic Regression. Wiley, London (1972) Braun, T.M., Wang, S.: A hierarchical Bayesian design for phase I trials of novel combinations of cancer therapeutic agents. Biometrics 66, 805–812 (2010)

Cheung, Y.K.: Dose Finding by the Continual Reassessment Method. Chapman and Hall, London (2011)

References

39

Conaway, M.R., Dunbar, S., Peddada, S.D.: Designs for single- or multiple-agent phase I trials.

Biometrics 60, 661–669 (2004)

Dancey, J.E., Chen, H.X.: Strategies for optimizing combinations of molecularly targeted anticancer agents. Nat. Rev. Drug Discov. 5, 649–659 (2006)

Dunbar, S., Conaway, M.R., Peddada, S.D.: On improved estimation of parameters subject to order restrictions. Stat. Appl. 3, 121–128 (2001)

Gasparini, M.: General classes of multiple binary regression models in dose finding problems for combination therapies. Appl. Stat. 62, 115–133 (2013)

Gasparini, M., Bailey, S., Neuenschwander, B.: Correspondence: Bayesian dose finding in oncology for drug combinations by copula regression. Appl. Stat. 59, 543–544 (2010) Harrington, J.A., Wheeler, G.M., Sweeting, M.J., Mander, A.P., Jodrell, D.I.: Adaptive designs for dual-agent phase I dose-escalation studies. Nat. Rev. Clin. Oncol. 10, 277–288 (2013) Hirakawa, A., Hamada, C., Matsui, S.: A dose-finding approach based on shrunken predictive probability for combinations of two agents in phase I trials. Stat. Med. 32, 4515–4525 (2013) Hirakawa, A., Sato, H., Gosho, M.: Effect of design specifications in dose-finding trials for combination therapies in oncology. Pharm. Stat. 15, 531–540 (2016) Hirakawa, A., Sato, H.: Authors’ reply. Stat. Med. 35, 479–480 (2016) Hirakawa, A., Wages, N.A., Sato, H., Matsui, S.: A comparative study of adaptive dose-finding designs for phase I oncology trials of combination therapies. Stat. Med. 34, 3194–3213 (2015) Hwang, J., Peddada, S.D.: Confidence interval estimation subject to order restrictions. Ann. Stat.

22, 67–93 (1994)

Iasonos, A., Wilton, A.S., Riedel, E.R., Seshan, V.E., Spriggs, D.R.: A comprehensive comparison of the continual reassessment method to the standard 3+3 dose escalation scheme in phase 1

dose-finding studies. Clin. Trials 5, 465–477 (2008)

Ivanova, A., Kim, S.H.: Dose finding for continuous and ordinal outcomes with a monotone objective function: a unified approach. Biometrics 65, 307–315 (2009) Ivanova, A., Wang, K.: A non-parametric approach to the design and analysis of two-dimensional dose-finding trials. Stat. Med. 23, 1861–1870 (2004)

Jones, D.R., Moskaluk, C.A., Gillenwater, H.H., Petroni, G.R., Burks, S.G., Philips, J., Rehm, P.K., Olazagasti, J., Kozower, B.D., Bao, Y.: Phase I trial of induction histone deacetylase and proteasome inhibition followed by surgery in non-small-cell lung cancer. J. Thorac. Oncol. 7, 1683–1690 (2012)

Kakurai, Y., Hirakawa, A., Hamada, C.: A dose-finding method based on multiple dosing in two-agent combination phase I trials. J. Biopharm. Stat. 25, 1065–1076 (2015) Kim, K.B., Alrwas, A.: Treatment of KIT-mutated metastatic mucosal melanoma. Chin. Clin. Oncol.

3, 35 (2014)

Lee, S.M., Cheung, Y.K.: Model calibration in the continual reassessment method. Clin. Trials 6, 227–238 (2009)

Mander, A.P., Sweeting, M.J.: A product of independent beta probabilities dose escalation design for dual-agent phase I trials. Stat. Med. 34, 1261–1276 (2015) Marusyk, A., Almendro, V., Polyak, K.: Intra-tumour heterogeneity: a looking glass for cancer?

Nat. Rev. Cancer 12, 323–334 (2012)

O’Quigley, J., Pepe, M., Fisher, L.: Continual reassessment method: a practical design for phase I clinical trials in cancer. Biometrics 46, 33–48 (1990)

O’Quigley, J., Zohar, S.: Retrospective robustness of the continual reassessment method. J. Biopharm. Stat. 20, 1013–1025 (2010)

Riviere, M.K., Yuan, Y., Dubois, F., Zohar, S.: A Bayesian dose-finding design for drug combination clinical trials based on the logistic model. Pharm. Stat. 13, 247–257 (2014) Sweeting, M.J., Mander, A.P.: Escalation strategies for combination therapy phase I trials. Pharm.

Stat. 11, 258–266 (2012)

Thall, P.F., Millikan, R.E., Mueller, P., Lee, S.J.: Dose-finding with two agents in phase I oncology trials. Biometrics 59, 487–496 (2003)

40

2

Dose Finding for a Combination of Two Agents

Wages, N.A., Conaway, M.R.: Specifications of a continual reassessment method design for phase I trials of combined drugs. Pharm. Stat. 12, 217–224 (2013) Wages, N.A., Conaway, M.R., O’Quigley, J.: Continual reassessment method for partial ordering.

Biometrics 67, 1555–1563 (2011a)

Wages, N.A., Conaway, M.R., O’Quigley, J.: Dose-finding design for multi-drug combinations.

Clin. Trials 8, 380–389 (2011b)

Wages, N.A., Varhegyi, N.: POCRM: an R-package for phase I trials of combinations of agents.

Comput. Methods Programs Biomed. 112, 211–218 (2013)

Wang, K., Ivanova, A.: Two-dimensional dose finding in discrete dose space. Biometrics 61, 217–

222 (2005)

Yin, G., Yuan, Y.: A latent contingency table approach to dose finding for combinations of two agents. Biometrics 65, 866–875 (2009a)

Yin, G., Yuan, Y.: Bayesian dose finding for drug combinations by copula regression. Appl. Stat.

58, 211–224 (2009b)





Chapter 3

Dose Finding for Joint Assessment of Both

Efficacy and Toxicity

Abstract Traditionally, phase I trials are designed to determine the MTD of a new agent based solely on toxicity, regardless of the efficacy. The determination of an optimal dose based on the joint assessment of toxicity and efficacy of the drug in phase I dose-finding trials may be reasonable in some cases. The various types of incorporation of toxicity and efficacy outcomes into dose-finding methods have been developed. Among them, in this chapter, we overview four methods: (i) the bivariate continual reassessment method, (ii) Bayesian method based on the efficacy–toxicity trade-off, (iii) Bayesian method for evaluating binary toxicity and continuous efficacy outcomes, and (iv) the method based on the Bayesian Model Averaging (BMA).

Keywords Bivariate · Correlation · Efficacy and toxicity · Joint assessment 3.1

Introduction

For cytotoxic agents, increased exposure to a drug augments tumor cell killing in preclinical models. This dose–response relationship in preclinical models is extrap-olated to humans, as a consequence of which “the more the better” approach (i.e., the more toxic the treatment, the stronger effect we anticipate seeing) has become one of the most popular in oncology (Postel-Vinay et al. 2009; Sleijfer and Wiemer

2008). Thus, safety is first examined in a phase I trial, in which dose-finding methods are aimed at estimating the MTD of a new drug, fulfilling ethical constraints by minimizing the number of patients treated at too toxic levels. Then, efficacy of the MTD is typically examined in a subsequent phase II trial.

Nonetheless, some cancer therapies, such as cancer vaccines, are generally much safer than cytotoxic agents, and the dose that yields a sufficient biological activity is unlikely to confer significant toxicity. Hence, for these therapies, ethical concerns have been extended to the additional constraint that the proportion of patients who receive an ineffective dose can be minimized. In addition, due to statistical and resource insufficiency of the traditional two-phase approach (i.e., the safety and efficacy of a new agent is studied sequentially in phases I and II, respectively), various

© The Author(s), under exclusive licence to Springer Japan KK, part of Springer Nature 2018

41

A. Hirakawa et al., Modern Dose-Finding Designs for Cancer Phase I Trials: Drug Combinations and Molecularly Targeted Agents, JSS Research Series in Statistics, https://doi.org/10.1007/978-4-431-55573-5_3

42

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

dose-finding methods taking into account toxicity and efficacy simultaneously have been developed for clinical trials.

Gooley et al. (1994) were perhaps the first to consider two dose–outcome curves using a simulation as a design tool. They discussed the design and analysis of a proposed phase I/II clinical trial for a bone marrow transplant. That design sought a dose that balanced the risks of two immunological complications. Thall and Rus-

sell (1998) proposed a phase I/II design to find a dose that would satisfy both safety and efficacy requirements based on a trinary outcome. They used a proportional odds model (McCullagh 1989) to model the dose–outcome relationship. Thall and Cook (2004) developed a Bayesian phase I/II trial design based on trade-offs between efficacy and toxicity probabilities. They proposed to use the Gumbel model (Murtaugh and Fisher 1990) to capture the relation between the bivariate binary toxicity and efficacy outcomes. They employed the quadratic model for the dose–efficacy relationship to consider a nonmonotonic pattern.

As an extension of the CRM, Braun (2002) proposed the bivariate CRM that accounts for both toxicity and efficacy outcomes. Their work was motivated by research into allogeneic stem cell transplantation for older and advanced leukemia patients. Asakawa et al. (2014) devised a way to incorporate the BMA into the bivariate CRM to accommodate the misspecification of the true dose–toxicity and dose–efficacy relationships of the drug.

The above methods have been developed for binary toxicity and efficacy outcomes, but we often encounter a situation where the efficacy is measured as a continuous variable such as pharmacodynamic markers in practice. Bekele and Shen (2005)

utilized bivariate probit models, in which a patient’s toxicity and efficacy outcomes correlate with each other to develop the dose-finding method to explain binary toxicity and continuous efficacy outcomes. A continuous latent variable was introduced for the joint modeling of the continuous efficacy and the binary toxicity outcomes in a bivariate model, at each given dose level. Similarly, Hirakawa (2012) proposed a dose-finding method for analysis of correlating bivariate binary toxicity and continuous efficacy outcomes by means of the factorization models in single-agent and two-agent combination trials.

In this chapter, we overview the four methods: (i) the bivariate CRM (Brawn, 2002), (ii) Bayesian method based on the efficacy–toxicity trade-off (Thall and Cook

2004), (iii) Bayesian method for evaluating binary toxicity and continuous efficacy outcomes (Hirakawa 2012), and (iv) the CRM-based method derived from BMA (Asakawa et al. 2014).

Hereafter, we mainly introduce both the statistical model for capturing the dose–

efficacy and dose–toxicity relationships along with the dose-finding algorithm for exploring the optimal dose because almost all the dose-finding methods have often been developed by improving or devising these components. The notations of each method are independently defined because the models and dose-finding algorithm of each method are greatly different.





3.2 The Bivariate Continual Reassessment Method

43

3.2

The Bivariate Continual Reassessment Method

Braun (2002) attempted to find a regimen that is optimal, in the sense that acute graft-versus-host disease and disease progression rates are both kept near desired thresholds.

3.2.1

Modeling Toxicity and Efficacy Outcomes

For each subject i (i = 1 , · · · , N ), let Yi and Zi be the indicators of toxicity and progression (that is no efficacy). Yi (or Zi ) = 1 indicates that toxicity (or progression) is observed, and Yi (or Zi ) = 0 indicates otherwise.

The respective probabilities of toxicity and progression, πY (dl) and πZ (dl), are associated with each dose dl (l = 1 , · · · , L) via the equations πY (dl) = exp (−3 + β 1 dl) ,

(3.1)

1 + exp (−3 + β 1 dl)

πZ (dl) = exp ( 3 − β 2 dl) .

(3.2)

1 + exp ( 3 − β 2 dl)

Braun (2002) assumed that each pair (Yi , Zi ) has a bivariate distribution; f (y, z | d) = Cπ y ( 1 − π

( 1 − π

Y

Y )( 1− y) π zZ

Z )( 1− z) ψ yz ( 1 − ψ )( 1− yz)

(3.3)

where ψ denotes the association between Y and Z, and C is a normalizing constant.

Thus, the parameter vector is given by θ = (β 1 , β 2 , ψ) in this dose-finding method.

After we observe the results for a cohort of n subjects, Dn, the likelihood is given by

n



L (θ | Dn) =

f (yi , zi ) .

(3.4)

i =1

Braun (2002) presumed a noninformative prior for θ, p (θ ), specifically, p (θ ) = 6 ψ ( 1 − ψ) exp {− (β 1 + β 2 )} , β 1 > 0 , β 2 > 0 , 0 < ψ < 1

(3.5)

which applies an exponential distribution with a mean of 1 to each regression parameter β 1, β 2, and a beta distribution with the mean 0.5 to association parameter ψ.

Note that β 1, β 2, and ψ are assumed to be marginally independent.

The posteriors of θ are expressed as

p(θ | Dn) ∝ L(θ | Dn) p(θ ).

(3.6)

Braun (2002) estimated the posterior mean of θ by the integral approximation method proposed by Tierney and Kadane (1986).





44

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

3.2.2

The Dose-Finding Algorithm

Definition of the Optimal Dose:

Braun (2002) defined the optimal dose as the dose that minimized the Euclidean distance ul of the posterior probabilities ˆ πY (dl) , ˆ πZ (dl) to the target rates of toxicity and progression π∗ , π∗ at the end of the study: Y

Z





2

2

ul =

ˆ πY (dl) − π∗ + ˆ π

.

(3.7)

Y

Z (dl ) − π ∗

Z

Acceptable Dose Criteria:

To control the risk of treating subjects at a dose with either unacceptably high toxicity or unacceptably low efficacy, Braun (2002) placed a limit on the dose escalation/de-escalation based on the lower bound of a one-sided 95% confidence interval for the overall rate of toxicity L BY and for the overall rate of disease progression L BZ . L BY

and L BZ are estimated from the total toxic events eY and total progression events eZ

among n subjects. The specific dose escalation/de-escalation rules will be described later.

Dose- Fi ndi ng Algor i t hm:

In their dose-finding method, a first cohort with c subjects is treated at the starting dose that the investigator considers the optimal dose. After n subjects have been enrolled, using the posterior mean of θ, we calculate the posterior probabilities of toxicity and progression outcomes for each dose, ˆ πY (dl) and ˆ πZ (dl). The dose allocated to the next cohort of patients is determined as follows:

1. If L BY ≤ π∗ and L B

, the dose corresponding to the smallest value of u

Y

Z ≤ π ∗

Z

l

is selected, and a new cohort of c subjects enters on that dose.

2. If L BY > π∗ and L B

, then patients of the next cohort will be treated

Y

Z ≤ π ∗

Z

at the dose that minimized ul only if that dose is lower than the current dose.

Otherwise, the dose will be decreased to the next lowest dose from the current dose.

3. If L BY ≤ π∗ and L B

, then patients of the next cohort will be treated at

Y

Z > π ∗

Z

the dose that minimized ul only if it is higher than the current dose. Otherwise, the dose will be escalated to the next highest dose.

This procedure is repeated until the maximum number of patients N have been enrolled, and then we determine the optimal dose. If both confidence intervals L BY

and L BZ lie above the target rates or their dose-finding method recommends increasing above dose dL or decreasing below dose d 1, then the study will be terminated early.





3.2 The Bivariate Continual Reassessment Method

45

3.2.3

Operating Characteristics

Braun (2002) compared the performance of the bivariate CRM with that of the designs proposed by Gooley et al. (1994) in simulation studies under three scenarios. Gooley et al. (1994) proposed three rule-based dose-finding designs, denoted as designs A–

C, based on the number of patients without efficacy (rejection after a transplant) or with toxicity. The dose-finding algorithms of the three designs are quite similar. The major differences among the three designs are the criteria for increasing or decreasing the dose level. For further details, see the original paper. According to the simulation results published by Gooley et al. (1994), the operating characteristics of design A were deemed inferior to those of designs B and C. Therefore, we focused on designs B and C, and compared the operating characteristics among the bivariate CRM and designs B and C.

Braun (2002) assumed 18 dose levels and 60 patients in total. The first cohort of patients was allocated to dose level 14. The outcomes of each subject were simulated to be negatively associated with ψ = 1 / 2. Each simulation consisted of 1,000 trials.

In the two scenarios, which include more than two true optimal doses, the means of the recommended rates for the true optimal dose of the bivariate CRM, design B, and design C were 67.0%, 61.6%, and 77.1%, and the mean termination rates of the study on the bivariate CRM, design B, and design C were 23.9%, 24.7%, and 13.7%, respectively. In the scenarios in which no optimal dose exists, the bivariate CRM, design B, and design C revealed termination rates of the trial, 92.3%, 85.3%, and 76.7%, and average numbers of subjects per trial of the bivariate CRM, design B, and design C were 19.6, 25.6, and 27.9, respectively.

Judging by these simulation results, the average performance of the bivariate CRM was slightly higher than that of design B but lower than that of design C by approximately 10% of the recommended rates for a true optimal dose. On the other hand, the bivariate CRM terminated the study earlier than design B and design C

when no optimal dose exists. Thus, the bivariate CRM can be considered a more conservative method than design C.

3.2.4

Software Implementation

A software package for implementing the bivariate CRM can be downloaded from https://biostatistics.mdanderson.org/softwaredownload/SingleSoftware.aspx?-

Software_Id=15.

When applying the bivariate CRM, we input (i) monitoring outcomes (Toxicity/Efficacy/Toxicity and Efficacy), (ii) a definition of a true optimal dose (the target rates of toxicity; the target rates of efficacy; the closest dose to the target/the dose above the target/the dose below the target), (iii) the value of the intercept parameter in the toxicity–efficacy model [−3 in Eq. (3.1) and 3 in Eq. (3.2)], (iv) the number of dose levels, (v) initial dose level, (vi) maximum dose-level increment, (vii) the





46

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

range of toxicity and efficacy probability (minimum and maximum probabilities of toxicity and efficacy), (viii) cohort size, and (ix) minimum and maximum sample sizes. Note that it is necessary to use the reciprocal of disease progression rates in Eq. (3.2) when we input (iii), the value of the intercept parameter, into the efficacy model (i.e., input the value of −3 instead of 3).

After we run simulations, the main program window can show the summary data for the different scenarios and design variants simulated.

3.3

Dose Finding Based on Efficacy–Toxicity Trade-Offs

Thall and Cook (2004) developed a Bayesian phase I/II trial design based on the efficacy–toxicity trade-offs that a physician would consider desirable. The models for bivariate binary and trinary outcomes are considered in this dose-finding method.

Here, we introduce only the model for bivariate binary outcomes.

3.3.1

Modeling Toxicity and Efficacy Outcomes

Let YEi and YT i be the indicators of efficacy and toxicity for the i th patient (i = 1 , · · · , N). YEi (or YTi) = 1 indicates that efficacy (or toxicity) is observed, and YEi (or YT i ) = 0 indicates otherwise. Given the actual L doses d 1 , · · · , dL , standardized dose d = log (d

L

d

l

l ) − L −1

m=1 m , ( l = 1 , · · · , L ) is used for the models underlying the dose-finding method.



Thall and Cook (2004) formulated the marginal probability of toxicity πT d l and efficacy πE d as follows:

l





exp α

π

T + βT d l





T

d =

,

(3.8)

l

1 + exp αT + βT d l





exp α

2

E + βE, 1 d + βE, 2 d

π

l

l





E

d =

.

(3.9)

l

1 + exp α

2

E + βE, 1 d + β

l

E , 2 d l

The joint probability function for YEi and YT i is modeled by the Gumbel model: πa,b (xi, θ ) = Pr (YEi = a, YTi = b| xi, θ )

= (πE)a ( 1 − πE) 1− a (πT )b ( 1 − πT ) 1− b



+

eψ −

(−

1

1 )a+ b πE ( 1 − πE ) πT ( 1 − πT )

(3.10)

eψ + 1

for a, b ∈ {0 , 1}, where xi and ψ denote the actual dose administered to patient i and the association parameter, respectively. Thus, the parameter vector is given by θ = αT , βT , αE, βE, 1 , βE, 2 , ψ in this dose-finding method.





3.3 Dose Finding Based on Efficacy–Toxicity Trade-Offs 47

If we denote the data for the first n patients in the trial as Dn, then the likelihood is given by

n

1

1





L

I { Y i = (a,b)}

n (θ | Dn ) =

πa,b (xi, θ )

.

(3.11)

i =1 a=0 b=0

Thall and Cook (2004) assumed that each component of θ has a normal distri-





bution, i.e., αT ∼ N ˜

μα , ˜ σ

, β

˜ μ , ˜ σ

, α

˜ μ , ˜ σ

, β

T

αT

T ∼ N

βT

βT

E ∼ N

αE

αE

E , 1 ∼





N ˜

μβ , ˜ σ

, β

˜ μ , ˜ σ

, ψ ∼ N ˜ μ

, respectively. Suppose

E , 1

βE, 1

E , 2 ∼ N

βE, 2

βE, 2

ψ , ˜

σψ





ξ = ˜ μα , ˜ σ , · · · , ˜ μ

denotes the vector of hyperparameters with all prior

T

αT

ψ , ˜

σψ

covariance sets equal to 0, and let φ (θ | ξ) denote the normal prior of θ.

The posteriors of θ are given by

φ(θ | ξ, Dn) ∝ Ln (θ | Dn) φ(θ | ξ).

(3.12)

By the method of Monahan and Genz (1997), Thall and Cook (2004) numerically integrated Ln (Dn| θ ) φ(θ | ξ) with respect to θ for computing the posteriors.

To establish the value of hyperparameters, for each dose d, Thall and Cook

l



(2004) considered the prior mean of πE d , denoted as m l

E ,l (ξ ) and m T,l (ξ ), and





the prior standard deviations of πE d and π d , denoted as s l

T

l

E ,l (ξ ) and sT,l (ξ ).

Additionally, Thall and Cook (2004) proposed to specify the values of the target means m∗

and m∗ based on the physician’s opinion, and the values of the target E ,l

T ,l

standard deviations s∗ and s∗ in the range 0.29–0.50. Then, by the Nelder–Mead E ,l

T ,l

algorithm (Nelder and Mead 1965), we numerically solved for the value of ξ that best fits the target means and variances by minimizing the objective function 2

2

h(ξ ) =

m y,l(ξ ) − m∗

+ s

+ c

( ˜ σ

y,l

y,l (ξ ) − s∗

y,l

l − ˜

σk) 2 .

y= E,T 1≤ l≤ L

1≤ l≤ k≤ L

(3.13)

The second term in h(ξ ) is included so that the solution will distribute the prior variance more evenly among the components of θ, with c being a small positive constant.

3.3.2

The Dose-Finding Algorithm

The Definition of the Optimal Dose:

Thall and Cook (2004) considered the situation where the dose-finding method based on the Euclidean distance from the point of interest to the most desirable point, (πE, πT ) = ( 1 , 0 ) may not reflect clinical desirable outcomes in practice because this method puts equal weight on efficacy and toxicity. Instead of using the Euclidean distance, Thall and Cook (2004) developed a new indicator, which is designated as

“desirability,” to identify the optimal dose based on the efficacy–toxicity trade-offs that a physician would consider desirable.

At first, to calculate the desirability, we have to establish the target efficacy–

toxicity trade-off contour, C, such that all the points on C are equally desirable.





48

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

The way to construct C is introduced in the next subsection. Once the trade-off contour C is established, for each given dose level, we obtain an intersection point Z = πEz d , π

d

of the trade-off contour and a straight line that cuts across

l

T z

l





the points of the posterior efficacy and toxicity probabilities ˆ πE d , ˆ π

d

and

l

T

l

the ideal efficacy and toxicity probability pair (1, 0). Thus, the desirability value for d, δ d , is defined as follows:

l

l





π

2

2

d − 1 + π

d − 0

δ

E z

l

T z

l

d =





− 1

(3.14)

ˆ π

2

2

E

d − 1 + ˆ π

d − 0

l

T

l





If ˆ πE d , ˆ π

d

is on the trade-off contour, then the desirability value is 0. The l

T

l

larger positive desirability value indicates a more desirable dose level.

Acceptable Dose Criteria:

Thall and Cook (2004) defined the minimum efficacy and maximum toxicity criteria as follows:





Pr πE d , θ > π E| Dn > pE,

(3.15)





Pr πT d , θ < π | D

> p

T

n

T ,

(3.16)

where π E and π are fixed lower and upper limits specified by the physician, and T

pE and pT are fixed probability cutoffs. The probability cutoffs pE and pT may be determined, from preliminary computer simulation results, to obtain a design with desirable operating characteristics. If d satisfies both Eqs. (3.15) and (3.16), or if d is the lowest untried dose above the starting dose and satisfies Eq. (3.16), then d is an acceptable dose.

The Dose-Finding Algorithm:

We treat the first cohort at the starting dose specified by the physician. During the trial, after the most recent cohort’s data have been incorporated into Dn, the desirability for each d, δ d , is calculated, and the dose—that maximizes δ d among the l

l

l

doses with acceptable efficacy and toxicity—is to be administered to the next cohort of patients. This procedure is repeated until the maximum number of patients N

is reached. At this point, there is at least one acceptable dose, then dose d among acceptable doses maximizing δ d is selected as the optimal dose. If there are no l

acceptable doses, then the trial is terminated early and no dose is selected.

3.3.3

Constructing a Trade-Off Contour





To construct C, three target values, π∗ , π∗ , π∗ , that the physician considers equally 1

2

3





desirable, are elicited. First, we elicit a desirable trade-off target, π∗ = π∗ , π∗

=

1

1 ,E

1 ,T





3.3 Dose Finding Based on Efficacy–Toxicity Trade-Offs 49

1.0

0.8

toxicity 0.6

z

of

Contour

0.4

A

B

Probability 0.2

0.0 .00

.

0 2

.

0 4

.

0 6

0.8

1.0

Probability of efficacy

Fig. 3.1 The efficacy–toxicity trade-off contour is represented by the dotted curve. This contour is generated from the three equally desirable elicited target points π∗ , 0 , 1 , π∗

, π∗ , π∗ ,

E 1

T 2

E 3

T 3

which are represented by filled circles. Z represented by a filled square is the intersection point of the trade-off contour and a straight line that cuts across the points of the posterior efficacy and toxicity probabilities ˆ πE d , ˆ π

d

(represented by a filled triangle), and the ideal efficacy

l

T

l





and toxicity probability pair (1, 0). “A” is Euclidean distance from the point of ˆ πE d , ˆ π

d

l

T

l

to optimal point (1, 0), and “B” is Euclidean distance from the intersection point z to optimal point (1, 0). The desirability value is defined as B / A − 1





π∗ , 0 , in the case where toxicity has probability 0. Next, we elicit π∗ having the 1 ,E

2

same desirability as π∗ by asking the physician what the maximum value of π

1

T may

be if in the bivariate binary outcome case πE = 1. Given these two equally desirable extremes, we elicit a third pair, π∗, that is equally desirable but is intermediate 3

between π∗ and π∗. We plot each target as it is elicited and draw the target efficacy–

1

2





toxicity trade-off contour, C, determined by π∗ , π∗ , π∗ (Fig. 3.1).

1

2

3

Thall and Cook (2004) used the convenient form πT = f (πE ) = a+ b/πE + c/π 2 E

in their work, fitted to the three elicited target pairs subject to the constraint that f be nondecreasing for πE such that { πE , f (πE )} ∈ C.

3.3.4

Operating Characteristics

Thall and Cook (2004) illustrated their dose-finding method’s behavior in a simulation study under six scenarios. The number of dose levels was four, and the maximum sample size was set to 36. The starting dose was dose level 1, and the number of





50

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

patients allocated to each dose level was set to 3. In each scenario, the efficacy and toxicity occurred independently (i.e., φ = 0).

In addition, we set π E = 0 . 20, π = 0 . 40, and p T

E = pT = 0 . 10. The means





and standard deviations of the prior parameters were ˜

μα , ˜ s

= (−0 . 619 , 0 . 941 ),

T

αT





˜ μβ , ˜ s

= ( 0 . 587 , 1 . 659 ), ˜ μ , ˜ s

= (−1 . 496 , 1 . 113 ), ˜ μ , ˜ s

=

T

βT

αE

αE

βE, 1

βE, 1





( 1 . 180 , 0 . 869 ), ˜ μβ , ˜ s

= ( 0 . 149 , 1 . 192 ) and ˜ μ

= ( 0 , 1 . 00 ), respec-

E , 2

βE, 2

ψ , ˜ sψ





tively. To construct C, the three target values π∗ , 0 , 1 , π∗ , π∗ , π∗

=

E 1

T 2

E 3

T 3

( 0 . 15 , 0 ) , ( 1 , 0 . 60 ) , ( 0 . 25 , 0 . 30 ) were selected.

As a result, in five scenarios, which include a true optimal dose, the mean of the recommended rates for the true optimal dose was 82.6%. In the scenario where no dose was acceptable, the trial was correctly stopped early with no dose selected 94.5% of the time. Thus, Thall and Cook (2004) demonstrated that their dose-finding method may be able to make a correct decision, namely, select the optimal dose or stop early when no doses are acceptable.

3.3.5

Software Implementation

Readers can use publicly released software EffTox (version 4.0.12), which can be downloaded from https://biostatistics.mdanderson.org/softwaredownload/-

SingleSoftware.aspx?Software_Id=2.

To run EffTox, the essential inputs—(i) prior efficacy and toxicity probabilities for doses, (ii) effective sample size, (iii) equally desirable target efficacy–toxicity probability pairs, (iv) true efficacy and toxicity probabilities for each dose level, and (v) the conditional probability of efficacy given no toxicity outcome—are required but are not limited to these values.

Depending on prior efficacy and toxicity probabilities and effective sample size, the hyperparameters of the prior distribution with respect to the model parameters were automatically calculated. The prespecified efficacy–toxicity trade-off contour is also automatically constructed based on three determined efficacy and toxicity probability pairs that are considered by the physician to be equally desirable targets, that is, π∗ , π∗ , π∗ .

1

2

3

3.4

A Bayesian Approach to Modeling Binary Toxicity

and Continuous Efficacy Outcomes

Hirakawa (2012) developed a dose-finding method for evaluating continuous efficacy and binary toxicity outcomes in monotherapy and combination therapy. Here, we introduce only the model for monotherapy.





3.4 A Bayesian Approach to Modeling Binary Toxicity …

51

3.4.1

Modeling Toxicity and Efficacy Outcomes

Let YT i and Y ∗ be a binary toxicity outcome and a raw continuous efficacy outcome Ei

for the i th of N patients. YT i = 1 indicates that toxicity is observed, and YTi = 0

indicates otherwise. A lower value of continuous efficacy outcome Y ∗ is regarded Ei

as superior to higher values.

Hirakawa (2012) assumed the probability of the toxicity outcome as follows: πT (dl)

logit (πT (dl)) = log

= α 0 + α 1 dl,

(3.17)

1 − πT (dl)

where πT (dl) is the probability of toxicity for dose dl, l = 1 , · · · , L, and (α 0 , α 1 ) are unknown parameters. Then, the distribution of YT i matches the Bernoulli distribution, such that,





f yT i | dl,i = exp yTi ψi − log {1 + exp (ψi )} , (3.18)

where ψi equals logit (πTi ), and dl,i denotes the actual dose for patient i.

For the continuous efficacy outcome, Hirakawa (2012) used the model previously described by O’Connell et al. (1993). A raw continuous efficacy outcome Y ∗ is Ei





transformed by YEi = h Y ∗ , then the distribution of Y

Ei

Ei is normal with the mean

μEi and variance σ 2,

i





(yEi − μEi) 2

f yEi | dl,i =

1



exp −

,

(3.19)

2 πσ 2

2 σ 2 i

i

where

β

μ

1 − β 2

Ei = β 2 +



.

β

(3.20)

1 + d

4

l,i /β 3

In this equation, (β 1 , β 2 , β 3 , β 4 ) are unknown parameters. Furthermore, as discussed by Harvey (1976), Hirakawa (2012) assumed variance σ 2 to be the multiplicative i

heteroscedasticity as follows:

σ 2 = σ 2 dλ ,

(3.21)

i

l,i

where σ 2 and λ are unknown parameters. The value of λ determines the degree of heteroscedasticity, particularly, homoscedasticity is held as the dose level increases when λ = 0.

Considering the correlation between binary toxicity and continuous efficacy outcomes, Hirakawa (2012) analyzed a model based on the factorization of the joint distribution of (YTi , YEi ), which was previously introduced by Olkin and Tate (1961):

f (yTi , yEi ) = f (yTi ) f (yEi | yTi ) .

(3.22)

The conditional distribution of yEi given yT i is normal,





52

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity





{ yEi − μEi − τ (yTi − πTi)}2

f (yEi | yTi ) =

1



exp −

,

(3.23)

2 πσ 2

2 σ 2 i

i

where τ is the parameter for the regression of yEi on yTi . Large absolute values of τ indicate a strong correlation between the two outcomes. When τ = 0, the two outcomes are independent given the dose level in the model. In this dose-finding method, parameter vector θ = α 0 , α 1 , β 1 , β 2 , β 3 , β 4 , τ, σ 2 , λ

Given the current data Dn, the log-likelihood function is given by n





n





L(θ | Dn) = log

f ybi , yci | dl,i = log

f yci | ybi , dl,i f ybi | dl,i . (3.24)

i =1

i =1

Hirakawa (2012) employed a Bayesian procedure to update the estimates of parameter vectors θ. In their work, the prior joint distributions for the parameter vectors of θ, f (θ ), are an independent uniform distribution for each parameter.

In accordance with the Bayes theorem, the joint posterior distribution is f (θ | Dn) ∝ f (θ ) L (θ | Dn) .

(3.25)

Hirakawa (2012) estimated the posterior means of θ by the random-walk Metropolis algorithm to generate a sequence of draws from the joint posterior distribution of parameters using the PROC MCMC in the SAS software, version 9.2 (SAS Institute Inc., Cary, NC, USA).

3.4.2

The Dose-Finding Algorithm

The Definition of the Optimal Dose:

Hirakawa (2012) defined the optimal dose as a dose level that has the minimum weighted Mahalanobis distance between the point of efficacy and toxicity outcomes and the optimal point (y min , 0 ) among the dose levels whose efficacy and toxicity are acceptable. Specifically, to determine the optimal dose, Hirakawa (2012) used the posterior mean of the weighted Mahalanobis distance given by averaging the posterior samples. The k th posterior samples of the weighted Mahalanobis distance (k = 1 , · · · , K ) of the outcome μE (dl)(k) , πT (dl)(k) to the optimal point (y min , 0 ) are given by





(

A 2 + c 2 B 2 − 2 ρ (dl)(k) c 1 c 2 AB

m k) = c 21

2

,

(3.26)

l



2

1 − ρ (dl)(k)

where





3.4 A Bayesian Approach to Modeling Binary Toxicity …

53

A =

y min − μE (dl)(k)





,

(3.27)

τ 2 (k)ρ (dl)(k) 1 − ρ (dl)(k) + σ 2 (k)dλ (k) l

B =

0 − πT (dl)(k)





,

(3.28)

p (dl)(k) 1 − p (dl)(k)

and ρ (dl) is the correlation between efficacy and toxicity, c 1 and c 2 are the prespecified weight parameters for adjusting the trade-off between efficacy and toxicity, respectively. The posterior mean of the weighted Mahalanobis distance is calculated based on the posterior samples, that is,

K



¯

(

m

k)

l = 1

m

.

(3.29)

K

l

k=1

When employing the Markov chain Monte Carlo method in the simulation studies, Hirakawa (2012) used a burn-in of 5,000 iterations with a chain of length 5,000, retaining every fifth sample. Therefore, the value of K is set to 1,000 throughout.

Acceptable Dose Criteria:

Hirakawa (2012) defined the acceptable dose levels as T (dl) = { dl| I [ μE (dl) < μ 0

and πT (dl) < π 0] = 1}, where I [·] is an indicator function, μE (dl) and πT (dl) are the posterior mean of the continuous efficacy and the posterior probability of a toxicity outcome for dose level dl (l = 1 , · · · , L), respectively. μ 0 and π 0 are critical values for the posterior estimates of μE (dl) and πT (dl), respectively.

The Dose-Finding Algorithm:

In this algorithm, c patients are allocated to a single dose level at a time, starting from the lowest dose level. If T (dl) = 0, then the dose with the minimum value of

¯ ml among T (dl) is allocated to the next patient until reaching the maximum number of patients N . At the end of the trial, we choose a dose level that has the minimum weighted Mahalanobis distance among T (dl) as an optimal dose. The trial is stopped early when T (dl) = 0 for all dose levels and/or any of the following criteria is met: Pr ˆ πT (d 1 ) > π 0| Data > δ 1 ,

(3.30)





Pr ˆ

μE (dL) > μ 0| Data > δ 2 ,

(3.31)

where δ 1 and δ 2 are the prespecified threshold probabilities.

3.4.3

Operating Characteristics

Hirakawa (2012) compared the operating characteristics of the proposed method with those of the method published by Bekele and Shen (2005), through simulation





54

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

studies under six scenarios. In this study, four dose levels were considered, and the maximum sample size N was set to 36. The starting dose was the lowest dose, and the number of patients allocated to the single dose c was set to 3. Hirakawa (2012)

introduced a correlation between toxicity and efficacy into the simulations via a copula function. Here, we introduce the case of correlation coefficient r = 0 . 2, each simulation consisted of 1,000 trials.

The toxicity probability that is clinically allowed, π 0, was set to 0.3. The efficacy threshold that is clinically allowed, μ 0, was set to 1.1. In addition, the weight parameters c 1 and c 2 were both set to 1.0, and the probabilities δ 1 and δ 2 were both set to 0.7. Hirakawa (2012) used α 0 ∼ U ni f orm (−10 , 0 ), α 1 ∼ U ni f orm ( 0 , 5 ), β 1 ∼ Uni f orm ( 0 , 10 ), β 2 ∼ Uni f orm (−10 , 0 ), β 3 ∼ Uni f orm ( 0 , 10 ), β 4 ∼ Uni f orm ( 0 , 10 ), τ ∼ Uni f orm (−10 , 10 ), σ 2 ∼ Uni f orm ( 0 , 10 ), and λ ∼ Uni f orm (−10 , 10 ) for all the scenarios.

Under the four scenarios that include a true optimal dose, the mean of the recommended rates for the true optimal dose of Hirakawa’s method and of Bekele and Shen’s method were 85.3% and 82.0%, respectively. Under scenarios in which all four doses were unacceptable or had no efficacy, both methods did not select any of the four doses in more than 90% of the cases, but the average number of patients in the Hirakawa’s method was 6.8, which was approximately a half of that of Bekele and Shen’s method (13.9 patients).

3.5

The BMA Bivariate CRM

Asakawa et al. (2014) proposed to incorporate BMA into the bivariate CRM to mitigate the risk of the misspecification of the true dose–efficacy and dose–toxicity relationships of a drug.

3.5.1

Modeling Toxicity and Efficacy Outcomes

Suppose YEi and YT i are binary efficacy and toxicity outcomes for patient i (i = 1 , · · · , N). YEi ( or YTi) = 1 indicates that efficacy (or toxicity) is observed, and YEi ( or YTi ) = 0 indicates otherwise.

Asakawa et al. (2014) presumed a power model for dose–efficacy and dose–toxicity relationships, which consist of the skeletons for efficacy and toxicity probability and unknown model parameters. To address misspecification of the true dose–efficacy and/or toxicity relationships, Asakawa et al. (2014) proposed to apply BMA, which estimates the posterior probability for toxicity and efficacy by averaging posterior probabilities. Thus, K working models, denoted as W Mk (πEk (dl) , πT k (dl)) , (k = 1 , · · · , K ), are prespecified for dose dl (l = 1 , · · · , L). Working model W Mk is given by





3.5 The BMA Bivariate CRM

55

πEk (dl) = p exp (βEk),

(3.32)

E kl

πTk (dl) = p exp (βTk),

(3.33)

T kl

where pEkl and pT kl are the k th skeletons for efficacy and toxicity probabilities at dose dl , and βEk and βT k are unknown model parameters for the k th working model, respectively.

Suppose that nl patients have been treated at dose dl and zEl (or zTl) defined as the number of patients whose response is YE = 1 (or YT = 1) at dose dl, respectively.

In addition, zl is defined as the number of patients whose response is YE = 1 and YT = 1 at dose dl. For the observed data D, the likelihood function for W Mk is expressed as

L



L(βEk, βTk, ψk, W Mk| D) ∝

πzEl ( 1 − π

E kl

E kl )(nl − zEl ) π zTl

T kl

l=1

( 1 − πTkl)(nl− zTl) ψzl ( 1 − ψ

k

k )(nl − zl ) ,

(3.34)

where ψk is the association parameter.

The estimates of the parameter are updated by means of the Bayesian theorem.





Asakawa et al. (2014) assumed the normal prior distribution N 0 , 42 for gradient parameters βEk and βT k and presumed beta distribution Beta ( 2 , 2 ) for association parameter ψk to have a prior mean value of 0.5 with sufficiently vague information.

Given the prior distribution, the joint posterior distribution is expressed as f (βEk, βT k, ψk| D) ∝ L(βEk, βT k, ψk, W Mk| D) f (βEk) f (βT k) f (ψk) . (3.35) Asakawa et al. (2014) estimated the posterior distribution of model parameters using a random-walk Metropolis algorithm to generate the sample for generating recursive draws from a particular Markov chain, whose stationary distribution is the same as the posterior joint distribution of parameters using PROC MCMC in SAS, version 9.2 (SAS Institute Inc., Cary, NC).

3.5.2

BMA Estimates

Let Pr (W Mk) be the prior probability that represents the prior relative certainty (or importance) for the k th working model with the restriction Pr (W M

k

k ) = 1. In

their work, each working model has equal prior probability. These probabilities for each working model are adaptively updated as posterior probabilities. The posterior model probability (PMP) is given by





56

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

L(βEk, βTk, ψk, W Mk| D) Pr (W Mk)

PMP (W Mk) = Pr (W Mk| D) =

.

K

L(β

m=1

E m , βT m , ψm , W M m | D) Pr (W Mm )

(3.36)

With PMP (W Mk) as a weight for the k th working model, the BMA estimates for efficacy and toxicity probabilities at the l th dose level are obtained simply as a weighted average of the posterior means of the efficacy and toxicity probability, ˆ πEk (dl) and ˆ πTk (dl), across K working models: K



¯ πE (dl) =

ˆ πEk (dl) PMP (W Mk) ,

(3.37)

k=1

K



¯ πT (dl) =

ˆ πTk (dl) PMP (W Mk) .

(3.38)

k=1

3.5.3

The Dose-Finding Algorithm

The Definition of the Optimal Dose:

Asakawa et al. (2014) defined an optimal dose as a dose level that minimizes the weighted Euclidean distance from the target efficacy and toxicity probabilities, (φE, φT ), via BMA estimates of efficacy and toxicity probabilities, such that E Dl = w(φE − ¯ πEl) 2 + ( 1 − w) (φT − ¯ πTl) 2 .

(3.39)

Asakawa et al. (2014) assumed φE = 1 and φT = 0 and w = 0 . 5, respectively.

Acceptable Dose Criteria:

To ensure at least minimal efficacy and maximal allowable toxicity with high probability, Asakawa et al. (2014) defined the minimum requirement criteria as follows: K





Pr ˆ πEkl ≥ cE PMP (W Mk) ≥ 0 . 9 , (3.40)

k=1

K





Pr ˆ πT kl ≤ cT PMP (W Mk) ≥ 0 . 9 , (3.41)

k=1

where cE and cT are the critical values. Asakawa et al. (2014) set cE and cT to 0.2

and 0.3, respectively.

The Dose-Finding Algorithm:

In this dose-finding method, patients are allocated to a specific dose level in a cohort that consists of three patients. Among dose levels satisfying the above criteria, the





3.5 The BMA Bivariate CRM

57

dose level that minimizes E Dl is assigned to the next cohort of patients. It should be noted that the skipping a dose level during the escalation or de-escalation is not allowed. The trial is terminated when no dose levels satisfy these criteria. When the planned maximum number of patients is reached, then the optimal dose is determined by the BMA estimates of efficacy and toxicity probability based on all the accumulated outcomes.

3.5.4

Operating Characteristics

Asakawa et al. (2014) compared the operating characteristics of the proposed method with those of the ordinal bivariate CRM by means of each working model under eight scenarios. Asakawa et al. (2014) assumed five dose levels, and the maximum number of patients was set to 45. The patients were allocated to a specific dose level in a cohort that consists of three patients. The true correlation coefficient between these outcomes was assumed to be 0.5 on the scale of bivariate normal outcomes. Next, 1,000 simulations were conducted for each scenario. cE and cT were set to 0.2 and 0.3, φE = 1 and φT = 0, and w = 0 . 5, respectively. The prior distributions of parameters βEk and βTk were N 0 , 42 , and the beta distribution Beta ( 2 , 2 ) was assumed to be the prior distribution of association parameter ψk. In that simulation study, four sets of working models for efficacy and toxicity probabilities were considered.

In six scenarios, which include a true optimal dose, the means of the recommended rates for the true optimal dose of the proposed and bivariate CRM involving the best-fitting working model were 61.9% and 75.3%, respectively. The probability of correct optimal-dose selection with the proposed method was the second best among the candidate designs in most of the cases. The differences in the correct optimal dose selection probabilities between the best-fitting working model and the proposed method were 7.4–39.1%. Under the scenarios where no dose was acceptable, the proposed method was correctly stopped early with no dose selected more than 90%

of the time.

According to the simulations, if true dose–efficacy and dose–toxicity relationships for an investigational drug can be speculated based on prior information, then the ordinal bivariate CRM involving the working model corresponding to true dose–

efficacy/toxicity relationships should be used. Nonetheless, in the cases without prior information about dose–efficacy and dose–toxicity relationships, the proposed method may be a useful alternative.

3.5.5

Software Implementation

Readers can use the BMA-based bivariate CRM method in SAS version 9.2. The SAS code to run this method (BMA-bCRM.sas) and estimate model parameters





58

3

Dose Finding for Joint Assessment of Both Efficacy and Toxicity

(MCMC.sas) are available on the website http://www.rs.kagu.tus.ac.jp/hamada/lab.

html.

To execute BMA-bCRM.sas, it is necessary to use MCMC.sas in BMA-bCRM.sas.

Given the skeletons for efficacy probability and toxicity probability of each working model, a prior probability of each working model, and the minimum efficacy or maximum allowable toxicity criteria, BMA-bCRM.sas applies the BMA-based bivariate CRM to the input SAS dataset and outputs the dose level assigned to the next cohort of patients. The input SAS dataset must contain each patient’s data on outcomes: an indicator of the toxicity outcome, indicator of the efficacy outcome, and the dose level used for the treatment.

References

Asakawa, T., Hirakawa, A., Hamada, C.: Bayesian model averaging continual reassessment method for bivariate binary efficacy and toxicity outcomes in phase I oncology trials. J. Biopharm. Stat.

24, 310–325 (2014)

Bekele, B.N., Shen, Y.: A Bayesian approach to jointly modeling toxicity and biomarker expression in a phase I/II dose-finding trial. Biometrics 61, 344–354 (2005) Braun, T.M.: The bivariate continual reassessment method: extending the CRM to phase I trials of two competing outcomes. Control. Clin. Trials 23, 240–256 (2002) Gooley, T.A., Martin, P.J., Fisher, L.D., Pettinger, M.: Simulation as a design tool for phase I/II clinical trials: an example from bone marrow transplantation. Control. Clin. Trials 15, 450–462

(1994)

Harvey, A.C.: Estimating regression models with multiplicative heteroscedasticity. Econometrica 44, 461–465 (1976)

Hirakawa, A.: An adaptive dose-finding approach for correlated bivariate binary and continuous outcomes in phase I oncology trials. Stat. Med. 31, 516–532 (2012) McCullagh, P.: Models for discrete multivariate responses. Bull. Int. Stat. Inst. 53, 407–418 (1989) Monahan, J., Genz, A.: Spherical-radial integration rules for Bayesian computation. J. Am. Stat.

Assoc. 92, 664–674 (1997)

Murtaugh, P.A., Fisher, L.D.: Bivariate binary models of efficacy and toxicity in dose-ranging trials.

Commun. Stat. Theory Methods 19, 2003–2020 (1990)

Nelder, J.A., Mead, R.: A simplex method for function minimization. Comput. J. 7, 308–313 (1965) O’Connell, M.A., Belanger, B.A., Haaland, P.D.: Calibration and assay development using the four parameter logistic model. Chemom. Intell. Lab. Syst. 20, 97–114 (1993) Olkin, I., Tate, R.F.: Multivariate correlation models with mixed discrete and continuous variables.

Ann. Math. Stat. 32, 448–465 (1961)

Postel-Vinay, S., Arkenau, H.T., Olmos, D., Ang, J., Barriuso, J., Ashley, S., Banerji, U., De-Bono, J., Judson, I., Kaye, S.: Clinical benefit in Phase-I trials of novel molecularly targeted agents: does dose matter? Br. J. Cancer 100, 1373–1378 (2009)

Sleijfer, S., Wiemer, E.: Dose selection in phase I studies: why we should always go for the top. J.

Clin. Oncol. 26, 1576–1578 (2008)

Thall, P.F., Cook, J.D.: Dose-finding based on efficacy-toxicity trade-offs. Biometrics 60, 684–693

(2004)

Thall, P.F., Russell, K.E.: A strategy for dose-finding and safety monitoring based on efficacy and adverse outcomes in phase I/II clinical trials. Biometrics 54, 251–264 (1998) Tierney, L., Kadane, J.B.: Accurate approximations for posterior moments and marginal densities.

J. Am. Stat. Assoc. 81, 82–86 (1986)





Chapter 4

Dose Finding for Molecularly Targeted

Agents (MTAs)

Abstract In the last 20 years, breakthroughs in the understanding of cancer cell biology resulted in the development of MTAs that are targeted to the unique genetics of each tumor and each patient. MTAs modulate specific aberrant pathways in cancer cells while sparing normal tissues, so that some MTAs do not necessarily need to be administered at their MTD to have maximal efficacy. Therefore, dose-finding methods that take into account the bivariate-correlating outcomes of both efficacy and toxicity are required for the clinical development of MTAs. In addition, the dose–efficacy model for MTAs is necessary to capture the specific relation between efficacy and the dose level. The efficacy may increase initially with the dose level but then reaches a plateau; however, this situation may not always be the case. Several powerful methods taking into account such a dose–efficacy relationship inherent in MTAs were devised recently. In this chapter, we overview the existing dose-finding methods intended to determine the optimal dose in singe-agent trials of MTAs.

Keywords Bivariate efficacy and toxicity · MTA · Optimal dose · Plateau 4.1

Introduction

MTAs modulate specific aberrant pathways in cancer cells while sparing normal tissues, and therefore most MTAs are expected to be more selective and less toxic than conventional cytotoxic drugs. Thus, the maximum therapeutic effect may be achieved at doses that are well below the MTD. This supposition comes from the results on clinical responses at different dose levels in clinical trials evaluating MTAs (Le Tourneau et al. 2015). In addition, the toxic effects of MTAs may manifest themselves through different mechanisms of action relative to the therapeutic effect, in which case, the toxic effects may not be predictive of the therapeutic effect (Fox et al.

2002). Therefore, dose-finding methods that evaluate efficacy and toxicity outcomes simultaneously are required for the clinical development of MTAs. In addition, the dose–efficacy model for MTAs should be able to capture the specific relation between efficacy and the dose level. In the dose–efficacy relationships of MTAs in most cases, the efficacy may increase initially with the dose level but then reaches a plateau;

© The Author(s), under exclusive licence to Springer Japan KK, part of Springer Nature 2018

59

A. Hirakawa et al., Modern Dose-Finding Designs for Cancer Phase I Trials: Drug Combinations and Molecularly Targeted Agents, JSS Research Series in Statistics, https://doi.org/10.1007/978-4-431-55573-5_4





60

4

Dose Finding for Molecularly Targeted Agents (MTAs)

however, this situation may not always be the case. Several dose-finding methods that take into account toxicity and efficacy simultaneously for determining the optimal dose in singe-agent trials were introduced in the previous chapter. Nevertheless, the efficacy model in these methods does not necessarily consider the dose–efficacy relationship inherent in MTAs.

To accommodate the dose–efficacy relationship of MTAs, Cai et al. (2014) proposed a logistic model with quadratic terms to capture the dose–efficacy relationship in the trials of combinations of biological agents. They regarded the shape of the dose–toxicity surface as initially monotonic with the dose escalation but changing to flat once it passes the threshold, and therefore, they selected a logistic model that reflects the fact that the dose–toxicity surface of combinations of biological agents may plateau. Riviere et al. (2015) incorporated a plateau parameter into a proportional hazards model for time to efficacy in a trial of a combination of a cytotoxic agent and an MTA. This approach also implies that after a certain dose level, the efficacy curve will plateau, even if toxicity is increasing. Wages and Tait (2015)

proposed a power model for the binary efficacy outcome taking into account the notion that efficacy may decrease or reach a plateau after a certain dose level in a dose-finding trial of a single MTA. Sato et al. (2016) proposed a change point logistic model where the parameters change in the vicinity of the change point of the dose level. The change point is defined as the dose level at which the dose–efficacy pattern changes. Consequently, their method can capture various dose–efficacy patterns with an increase in the dose level. Riviere et al. (2016) selected the weighted likelihood approach to accommodate the possibility that efficacy has a late onset in the sense that efficacy takes a relatively long time to be assessed compared to toxicity (with respect to the accrual rate), such that when the next new patient arrives, patients who have enrolled into the trial have not completed their efficacy assessment yet. Those authors assumed that toxicity monotonically increases with the dose and modeled it via a logistic model.

In this chapter, we focus on three dose-finding methods, that is, those developed by Wages and Tait (2015), Sato et al. (2016), and Riviere et al. (2016). As described in the previous chapter, we first introduce the statistical models for capturing the dose–efficacy and dose–toxicity relationships as well as the dose-finding algorithm for analyzing the optimal dose. We also discuss the operating characteristics of each method. The symbols are independently defined by the dose-finding methods we introduce here because the models and dose-finding algorithm of each method are quite different.

4.2

The Model-Selecting Dose-Finding Method

Wages and Tait (2015) made use of some class of working models corresponding to unimodal or plateau dose–efficacy relationships for MTAs and continuously selected the model based on the posterior model probability through the trial.





4.2 The Model-Selecting Dose-Finding Method

61

4.2.1

Modeling Toxicity and Efficacy Outcomes

Let Yi and Zi denote binary toxicity and efficacy outcomes for the i th entering patient (i = 1 , . . . , N ), respectively. Yi (or Zi ) = 1 indicates that toxicity (or efficacy) is observed, and Yi (or Zi ) = 0 indicates otherwise. The dose for the i th entering patient, Xi , can be thought of as random, taking values xi ∈ { d 1 , . . . , dL }.

Wages and Tait (2015) formulated the toxicity probability as πT (dl) = q exp (β),

(4.1)

l

where ql are skeletons representing discrete dose levels dl . Wages and Tait (2015)

assumed that toxicity monotonically increases with the dose; therefore, 0 < q 1 <

· · · < qL < 1. On the other hand, some class of working models for the efficacy probability is used to allow for more flexibility in modeling the dose–efficacy relationship.

In this method, K = 2 × L − 1 working models are prespecified; there are L unimodal skeletons and L − 1 plateau skeletons, which correspond to the dose–efficacy relationships where efficacy is increasing at low dose levels and either decreasing or plateauing at higher dose levels. For a particular skeleton, k, k = 1 , . . . , K , the true efficacy probability at dl is modeled by

πEk (dl) = p exp (θk),

(4.2)

kl

where pkl is the skeleton of model k.

Wages and Tait (2015) estimated parameters β and θk based on the Bayesian framework. For the current data on n patients, Dn, to estimate parameters β and θ, the likelihood is given by

n



L (β| Dn) =

{ πT } yi {1 − πT } ( 1− yi) and (4.3)

i =1

n



Lk (θk| Dn) =

{ πEk} zi {1 − πEk} ( 1− zi) , respectively .

(4.4)

i =1

Wages and Tait (2015) utilized normal priors with mean 0 and variance 1.34 for β

and θk as well as g (β) and h (θk), respectively.

For L (β| Dn) and Lk (θk| Dn), the posterior distributions of β and θk are given by g (β| Dn) ∝ g (β) L (β| Dn) and

(4.5)

h (θk| Dn) ∝ h (θk) Lk (θk| Dn) , respectively .

(4.6)

Wages and Tait (2015) proposed to select the model based on the posterior model probability. Suppose Pr (Modelk) is a prior model probability for each possible skeleton. Based on the set Dn and the likelihood, posterior model probabilities





62

4

Dose Finding for Molecularly Targeted Agents (MTAs)

PMP (Modelk) are as follows:



Pr (Modelk) Lk (θk| Dn) h (θk) dθk

PMP (Modelk) =Pr (Modelk| Dn) =



.

K

Pr (Model

L

m=1

m )

m (θm | Dn ) h (θm ) d θm

(4.7)

Each time a new patient is to be enrolled, Wages and Tait (2015) chose a single skeleton, k∗, with the largest posterior probability such that k∗ = arg max k PMP (Modelk) .

(4.8)

4.2.2

The Dose-Finding Algorithm

The Definition of the Optimal Dose:

Wages and Tait (2015) regarded an optimal dose as a dose level that has the maximum efficacy probability among the dose levels whose toxicity is acceptable.

Acceptable Dose Criteria:

Wages and Tait (2015) defined the acceptable set as follows: T (dl) = dl : ˆ πT (dl) ≤ φT

(4.9)

where πT (dl) is the toxicity probability estimates for each dose, and φT is the critical value. It should be noted that Wages and Tait (2015) substituted the toxicity skeleton ql for πT (dl) to calculate T (dl) at the beginning of the trial.

The Dose-Finding Algorithm:

To accurately assign patients to the most efficacious dose with acceptable toxicity, early in the trial, Wages and Tait (2015) introduced an adaptive randomization phase.

In this phase, the next cohort of patients is randomized to dose dl with probability Rl, which is calculated from the estimated efficacy probabilities, ˆ πE (dl), for doses in T (dl), that is,

ˆ πE (dl)

R



l =

.

(4.10)

dl ∈ T (dl ) ˆ

πE (dl)

It should be noted that the first patient or cohort of patients is allocated to dose x 1 = dl with probability Rl based on the efficacy skeleton p∗ instead of ˆ π

kl

E (dl ).

This adaptive randomization phase is continued until a subset of n R patients has been enrolled to allow information on untried doses to accumulate.

After the adaptive randomization phase, Wages and Tait (2015) initiated the maximization phase. The next cohort of patients is assigned to the dose level with the highest estimated efficacy probabilities, ˆ πE (dl) among the doses contained in T (dl).

If we continue this way, then the optimal dose is the recommended dose after the inclusion of the maximum sample size of N patients.





4.2 The Model-Selecting Dose-Finding Method

63

In their dose-finding method, there are two stopping rules. Let π− (d T

1 ) and φT be

a lower bound of the 95% confidence interval for the probability of toxicity at d 1 and the maximum acceptable toxicity rate, respectively. In terms of safety, at any point in the trial, if π− (d

T

1 ) > φT , then we stop the trial for safety, and no treatment is identified as the optimal dose. In addition to the safety stopping rule, Wages and Tait

(2015) set a futility stopping rule in the maximization phase. Suppose π+ (x E

n ) and

φE are an upper bound of the 95% confidence interval for the probability of efficacy at the current dose xn and the futility threshold, respectively. If π+ (x E

n ) < φE , then

we stop the trial for futility, and no treatment is identified as the optimal dose.

4.2.3

Operating Characteristics

Wages and Tait (2015) compared the performance of the proposed method with that of the Hoering et al. method (2013) for identifying the optimal dose in simulations under 12 scenarios. The number of dose levels was six. The maximum sample size was set to 64, and the size of the adaptive randomization phase was set equal to one quarter of the total sample size. The first cohort of patients is allocated to dose x 1 with probability Rl calculated from the efficacy skeletons p∗ for each dose. In kl

the proposed dose-finding method, toxicity and efficacy probabilities are estimated independently, but to provide a justifiable comparison to Hoering’s method, Wages and Tait (2015) generated correlating binary outcomes using function ranBin2 in R

package binarySimCLF, that is, the log odds ratio specification used to generate the data was set to ψ = 4 . 6 to match that used by Hoering et al. (2013). Each simulation analyzed 1,000 trials.

To define the acceptable set, the maximum acceptable toxicity rate was specified to be φT = 0 . 33, and the minimum efficacy threshold to be φE = 0 . 05. The toxicity probabilities were modeled via the power model with skeleton values, which is robust and effective at carrying out the CRM designs. For efficacy, probabilities were modeled via the class of power models using 11 skeletons that correspond to the possible dose–efficacy relationship; six sets of values used for the unimodal relations, and five sets of values for plateau relations.

In all the scenarios, the mean of the recommended rates for true optimal dose of the proposed and Hoering’s method were 73.9% and 57.7%, respectively. Under the scenarios that include one true optimal dose and where the dose–efficacy curves increase until the middle dose and remain constant after that dose—that is, the dose–efficacy curve nonmonotonically increases with the dose—the recommendation rates of the true optimal dose of the proposed method were higher than those of the Hoering’s method by approximately 20–40%. In addition, the proposed method outperformed Hoering’s method under the scenarios that include one true optimal dose and where the efficacy monotonically increases with the dose, by selection rates of approximately 10–40%.





64

4

Dose Finding for Molecularly Targeted Agents (MTAs)

Based on the results of simulation studies, regardless of whether the dose–response relationship of an investigational MTA is monotonic/nonmonotonic, the proposed method may show superior performance relative to Hoering’s method.

4.2.4

Software Implementation

Readers can employ the dose-finding method proposed by Wages and Tait (2015)

using the R code released at

http://faculty.virginia.edu/model-based_dose-finding/Wages%20and%20Tait%

202015.R.

Wages and Tait (2015) provided two function pieces of code: bpocrm and bpocrm.sim. If we input the total number of doses, a set of toxicity skeleton values, the number of possible efficacy orderings, the possible efficacy orderings of the doses, the toxicity upper limit, efficacy lower limit, cohort size, the number of cohorts, starting dose, size of the adaptive randomization phase, the number of simulated trials, true toxicity probabilities, and true efficacy probabilities, then function bpocrm.sim outputs the operating characteristics of the method proposed by Wages and Tait (2015) as follows:

--------------------------------------------------------------------

#####Specify the total number of doses

d<-5

###Specify a set of toxicity skeleton values

p.skel<-c(0.01,0.08,0.15,0.22,0.29)

#####Specify the number of possible efficacy orderings

g<-9

#efficacy

###Specify the possible efficacy orderings of the doses

q.skel<-matrix(nrow=g,ncol=d)

q.skel[1,]<-c(0.60,0.70,0.60,0.50,0.40)

q.skel[2,]<-c(0.70,0.60,0.50,0.40,0.30)

q.skel[3,]<-c(0.50,0.60,0.70,0.60,0.50)

q.skel[4,]<-c(0.40,0.50,0.60,0.70,0.60)

q.skel[5,]<-c(0.30,0.40,0.50,0.60,0.70)

q.skel[6,]<-c(0.70,0.70,0.70,0.70,0.70)

q.skel[7,]<-c(0.60,0.70,0.70,0.70,0.70)

q.skel[8,]<-c(0.50,0.60,0.70,0.70,0.70)

q.skel[9,]<-c(0.40,0.50,0.60,0.70,0.70)

tul<-0.33

##toxicity upper limit

ell<-0.20

##efficacy lower limit

cohortsize=1 ##cohort size for each inclusion

ncohort=48

##number of cohorts

start.comb=1 ##starting dose

n.adaptive randomization=24

##size of adaptive randomization phase

ntrial=1000

##number of simulated trials





4.2 The Model-Selecting Dose-Finding Method

65

p0<-c(0.02,0.05,0.07,0.09,0.11)

q0<-c(0.68,0.56,0.49,0.40,0.33)

set.seed(580)

##random seed

##simulate many trials

bpocrm.sim(p0,q0,p.skel,q.skel,tul,ell,cohortsize,ncohort,ntrial,

start.comb)

True tox probability:

0.02

0.05

0.07

0.09

0.11

True eff probability:

0.68

0.56

0.49

0.4

0.33

selection percentage:

69.7

21.0

8.4

0.7

0.2

number of toxicities:

0.4

0.5

0.5

0.4

0.3

number of responses:

15.4

5.9

3.5

1.8

1.0

number of patients treated:

22.6

10.5

7.0

4.6

3.2

percentage of stop (safety):

0

percentage of stop (futility):

0

--------------------------------------------------------------------

4.3

The Dose-Finding Method Using the Change Point

Model

Sato et al. (2016) developed an adaptive dose-finding method involving a change point logistic model to allow for more flexibility in modeling various dose–efficacy patterns (including the nonmonotonic pattern) for MTAs.

4.3.1

Modeling Toxicity and Efficacy Outcomes

Let YEi and YT i be binary efficacy and toxicity outcomes for the i th entering patient (i = 1 , . . . , N), respectively. YEi ( or YTi) = 1 indicates that efficacy (or toxicity) is observed, and YEi ( or YTi ) = 0 indicates otherwise.

To consider the correlation between the toxicity and efficacy outcomes, Sato et al.

(2016) selected the model proposed by Islam et al. (2012). The joint probabilities for YT i and YEi are given in Table 4.1.

The bivariate joint probability function for YEi and YT i is expressed as Table 4.1 The joint

YT i

probabilities for YEi and YT i

0

1

YEi

0

π 00

π 01

1 − πE

1

π 10

π 11

πE

1 − πT

πT

1

66

4

Dose Finding for Molecularly Targeted Agents (MTAs)

1

1



Pr (yEi , yTi ) = π( 1− yEi)( 1− yTi)π( 1− yEi)yTi π yEi( 1− yTi)π yEi yTi =

π yijk , (4.11)

00

01

10

11

j k

j =0 k=0

where

yi 00 = ( 1 − yEi ) ( 1 − yTi ) , j = 0 , k = 0 , yi 01 = ( 1 − yEi ) yTi , j = 0 , k = 1 , yi 10 = yEi ( 1 − yTi ) , j = 1 , k = 0 , and yi 11 = yEi yTi , j = 1 , k = 1 .

To model the probability of efficacy and toxicity outcomes, Eq. (4.11) is factorized into the conditional probability of toxicity given an efficacy outcome Pr (YTi =

k| YEi = j; k, j = 0 , 1 ) and the marginal probability of efficacy Pr (YEi = j; j = 0 , 1 ) as follows:

1

1



1

1



Pr (yEi , yTi ) =

π yijk =

{Pr (Y

j k

T i = k| YEi = j ) Pr (YEi = j )} yi jk .

j =0 k=0

j =0 k=0

(4.12)

Sato et al. (2016) modeled the conditional probability functions of toxicity given each efficacy outcome using an ordinary logistic model, that is,

Pr (YTi = 1| YEi = 0 ) = πT | Y

and (4.13)

E =0 (xi ; θ0 ) =

exp (α 0 + β 0 xi )

1 + exp (α 0 + β 0 xi )

Pr (YTi = 1| YEi = 1 ) = πT| Y

,

(4.14)

E =1 (xi ; θ1 ) =

exp (α 1 + β 1 xi )

1 + exp (α 1 + β 1 xi )

where xi = { d 1 , . . . , dL } is the actual dose of the agent administered to the i th patient, θ0 = { α 0 , β 0} and θ1 = { α 1 , β 1} are unknown parameters for the model of Eqs. (4.13) and (4.14), respectively. Given actual dose dl (l = 1 , . . . , L), the standardized dose is defined as d = log (d

L

log (d

l

l ) − L −1

m=1

m ). It should be

noted that these conditional models are equal ( i . e ., θ0 = θ1 ) at the independence of efficacy and toxicity (Islam et al. 2012).

Next, Sato et al. (2016) proposed the change point logistic model for marginal probability of efficacy as follows:

⎧

⎪

⎪

⎪

⎪ π

,

⎨ E(xi; θE ) = exp (αE + βE xi)

xi ≤ d∗

1 + exp (αE + βE xi )

Pr (YEi = 1 ) = πE (xi ) = ⎪⎪⎪⎪

+ β x

⎩ π

E i )

E (xi ; θ ) =

exp (α E

, x

E

i > d ∗

1 + exp (α + β x

E

E i )

(4.15)

where d∗ is the change point of a dose between d , . . . , d and θ

1

L−1

E = { αE , βE } and

θ = { α , β } are unknown parameters.

E

E

E

4.3 The Dose-Finding Method Using the Change Point Model 67

For the current data on n patients, Dn, Sato et al. (2016) calculated the probabilities under the assumptions of d∗ = d , . . . , d

, respectively, that is,

1

L−1





n

1

1



Ln,l θ l| Dn, d∗ = d =

{Pr (Y

l

T i = k| YEi = j ) Pr (YEi = j )} yi jk i =1 j=0 k=0

n





=

π

yi 01

yi 00

T | Y

1 − π

E =0 (xi ; θ0 l )

T | YE =0 (xi ; θ0 l )

i =1

{ πT| YE=1 (xi; θ1 l)} yi 11{1 − πT| YE=1 (xi; θ1 l)} yi 10



×

{ πE (xi; θE l)} (yi 11+ yi 10 ) {1 − πE (xi; θE l)} (yi 00+ yi 01 ) i ∈ Ω





×

π

(yi 11+ yi 10 )

(yi 00+ yi 01 )

E

xi ; θ

1 − π

x

,

E l

E

i ; θE l

i /

∈ Ω

(4.16)





where θ l = θ0 l, θ1 l, θE l, θ

and Ω = { i| x

E l

i ≤ d ∗ , i = 1 , . . . , n} is the set of patients who received a dose lower than the assumed change point of d∗. In the Bayesian inference for θ l, Sato et al. (2016) assumed that the prior distribution for each parameter f (θ l) is an independent normal distribution although other distributions can be used. The method for the specification of hyperparameters for a prior normal distribution will be described later.

For each Ln,l (l = 1 , . . . , L − 1 ), the posterior distribution of θ l is given by f θ l| Dn, d∗ = d ∝ f (

.

(4.17)

l

θ l) Ln,l θ l| Dn, d∗ = d l After calculating the posterior distributions of θ l (for example, by Markov chain Monte Carlo methods), we can obtain the posterior mean ˆθ l for each θ l. The method for the specification of hyperparameters for a prior normal distribution is described in the next section.

Sato et al. (2016) devised a method for estimating change point (d∗ ) according to the method of Rukhin (1995). Given the posterior mean ˆθ l, we determine estimated change point ˜

d∗ that provides the maximum value among log L

ˆ

n,l θ l | Dn , d∗ = d ,

l

that is,

˜





d∗ = arg max

ˆ

d ≤ d∗≤ d

log Ln,l θ l| Dn, d∗ = d .

(4.18)

1

L−1

l

Sato et al. (2016) proposed to estimate the value of the mean parameter via the prior probabilities of efficacy and toxicity outcomes for each dose that are often elicited from investigators. Let pl be the prior probabilities of efficacy corresponding to dose d. Given prior expected change point d#, the doses are categorized into two groups: l

{ d| d ≤ d# , l = 1 , . . . , L} and { d| d > d# , l = 1 , . . . , L}. For the former and latter l

l

l

l





group, Sato et al. (2016) assumed pl = exp ηE + ξE d / 1 + exp η

l

E + ξE d l





and pl = exp η + ξ d / 1 + exp η + ξ d respectively, and then esti-E

E l

E

E l





mated θE = { ηE, ξE} and θ = η , ξ

by the least-squares method. Thus,

E

E

E





68

4

Dose Finding for Molecularly Targeted Agents (MTAs)

the least-squares estimates of θE and θ serve as the hyperparameter of prior nor-E





mal distribution i . e ., α

ˆ

E ∼ N or mal

ˆ ηE, σ 2 , βE ∼ Normal ξE, σ 2 , α ∼

E





N or mal ˆ η , σ 2 , and β ∼ N ormal ˆ ξ , σ 2

.

E

E

E

To determine the mean parameter for each of the prior normal distributions for θ0 and θ1, Sato et al. (2016) first supposed that ql are the prior probabilities of toxicity corresponding to dose d. Sato et al. (2016) then introduced the conditional l

probabilities of toxicity given each efficacy outcome, qT | YE=0 ,l and qT| YE=1 ,l, that can be written as pl, ql , and the prior correlation coefficient ψl, which is provided by Islam et al. (2012). For bivariate Bernoulli variables, the correlation coefficient is expressed as





Pr YE = 1 , YT = 1 , d Pr YE = 0 , YT = 0 , d − Pr YE = 1 , YT = 0 , d Pr YE = 0 , YT = 1 , d ψ

l

l

l

l

l =





,

pl 1 − pl ql 1 − ql

(4.19)

where





Pr YE = 1 , YT = 1 , d =

l

ql − qT | YE =0 ,l ( 1 − pl ) = qT | YE=1 ,l pl , Pr YE = 0 , YT = 0 , d =

(

l

1 − qT | Y

1 − p

1 − q

p

E =0 , l

l ) = 1 − ql −

T | YE =1 , l

l ,





Pr YE = 1 , YT = 0 , d =

(

l

1 − ql − 1 − qT | Y

1 − p

1 − q

p

E =0 , l

l ) =

T | YE =1 , l

l , and





Pr YE = 0 , YT = 1 , d =

l

qT | YE =0 ,l ( 1 − pl ) = ql − qT | YE =1 ,l pl .

According to these equations, qT | YE=0 ,l and qT| YE=1 ,l can be expressed as

√

ψl pl ( 1 − pl) ql ( 1 − ql) − ql ( 1 − pl) qT | Y

,

(4.20)

E =0 , l =

pl − 1

√

ψl pl ( 1 − pl) ql ( 1 − ql) + plql

qT | Y

.

(4.21)

E =1 , l =

pl





Thus, if we assume that qT | Y

η

/ 1 + exp η

and

E =0 , l

= exp 0 + ξ 0 d l

0 + ξ 0 d l





qT | Y

η

/ 1 + exp η

, θ

E =1 , l

= exp 1 + ξ 1 d l

1 + ξ 1 d l

0

= { η 0 , ξ 0} and θ1 =





{ η 1 , ξ 1} are estimated by the least-squares method ( i . e ., α 0 ∼ Normal ˆ η 0 , σ 2 , β

ˆ

ˆ

0 ∼ N or mal

ξ 0 , σ 2 , α 1 ∼ Normal ˆ η 1 , σ 2 , and β 1 ∼ Normal ξ 1 , σ 2 ).

In addition, the standard deviation ( σ ) is set to a common value for all the prior normal distributions in this study; however, it should be fine-tuned in a simulation study before the trial is conducted.

4.3.2

The Dose-Finding Algorithm

The Definition of the Optimal Dose:

Sato et al. (2016) defined an optimal dose as a dose level that has the minimum weighted Mahalanobis distance proposed by Hirakawa (2012). Sato et al. (2016)

obtained the k th posterior samples of the weighted Mahalanobis distance of outcome

4.3 The Dose-Finding Method Using the Change Point Model 69





π(k) d , π(k) d to optimal point ( 1 , 0 ): E

l

T

l





2

2

u E d

− 2 ρ d wEwT uE d uT d + w 2 uT d m(k) d = w 2 E

l

l

l

l

T

l

, (4.22)

l

2

1 − ρ d l

where





1 − π(k) d

u

E

l

E

d =

l



,

(4.23)

π(k) d 1 − π(k) d

E

l

E

l





0 − π(k) d

u

T

l

T

d =

l



,

(4.24)

π(k) d 1 − π(k) d

T

l

T

l

and wE and wT are the prespecified weight parameters for adjusting the trade-off between efficacy and toxicity, respectively. Suppose ρ d denotes the correlation l

coefficient (Islam et al. 2012):





π(k) d π(k) d − π(k) d π(k) d

ρ d =

11

l

00

l

10

l

01

l



l





,

(4.25)

π(k) d 1 − π(k) d π(k) d 1 − π(k) d

E

l

E

l

T

l

T

l

where





π(k) d = π(k) d − π(k)

d

1 − π(k) d

= π(k)

d π(k) d ,

11

l

T

l

T | YE =0

l

E

l

T | YE =1

l

E

l





π(k) d = 1 − π(k)

d

1 − π(k) d

00

l

T | YE =0

l

E

l





= 1 − π(k) d − 1 − π(k)

d

π(k) d ,

T

l

T | YE =1

l

E

l





π(k) d = 1 − π(k) d − 1 − π(k)

d

1 − π(k) d

10

l

T

l

T | YE =0

l

E

l





= 1 − π(k)

d

π(k) d , and

T | YE =1

l

E

l





π(k) d = π(k)

d

1 − π(k) d

= π(k) d − π(k)

d π(k) d .

01

l

T | YE =0

l

E

l

T

l

T | YE =1

l

E

l

The posterior mean of the weighted Mahalanobis distance is expressed as the average of the posterior samples, that is,



K





¯ m d = 1

m(k) d .

(4.26)

l

K

l

k=1





70

4

Dose Finding for Molecularly Targeted Agents (MTAs)

In the simulation studies, Sato et al. (2016) ran 500 burn-in iterations and then recorded every 10th subsequent sample out of 10,000 Gibbs samples to reduce the autocorrelation in the Markov chain; accordingly, the value of K was set to 1,000

throughout.

Acceptable Dose Criteria:

To avoid allocating patients to ineffective or severely toxic doses, Sato et al.

(2016) determined the set of acceptable doses (T ) based on the posterior probabilities of efficacy and toxicity outcomes for each dose d, ˆ π

d and ˆ π

d

l

E

l

T

l





= ˆ πE d × ˆ π

d

+ 1 − ˆ π d × ˆ π

d , as follows (Thall and

l

T | YE =1

l

E

l

T | YE =0

l

Cook 2004):





T d = d|Pr ˆ π

d > c

> δ

ˆ π d < c

> δ

,

l

l

E

l

E

E and Pr

T

l

T

T , l = 1 , . . . , L

(4.27)

where cE and cT are critical values for the posterior probabilities of efficacy and toxicity outcomes, and δE and δT are fixed probability cutoffs, respectively. That is, Sato et al. (2016) extracted the doses that are expected to be effective and not very toxic at a certain level.

The Dose-Finding Algorithm:

To stabilize the parameter estimates for θ l and d∗ at an early stage of the trial, Sato et al. (2016) incorporated a run-in period wherein the first cohort of patients is treated with the lowest dose, and the dose is escalated unless two or more of three patients in that cohort experience toxicity, although other dose escalation rules, such as the well-known 3 + 3 rule, can be applied. In this study, the cohort consisted of three patients.

Upon completion of the run-in period, the trial design switches to the model-based dose-finding stage. Using the estimated change point of ˜

d∗ and the corresponding

posterior means of ˆθ l, Sato et al. (2016) calculated the posterior probabilities of efficacy and toxicity outcomes for each dose d. The dose with the minimum value l





of ¯

m d among T d is administered to the next cohort of patients. Sato et al.

l

l

(2016) applied this algorithm until the maximum sample size was reached and then selected the dose administered to the next cohort of patients as the optimal dose. If there is no acceptable dose at an interim time point, then the trial is terminated at this time point, and no dose is selected as the optimal dose.

4.3.3

Operating Characteristics

Sato et al. (2016) compared the operating characteristics of the proposed method with the method proposed by Thall and Cook (2004) via simulations under 12 scenarios.

In this simulation study, six actual doses were considered, and the maximum sample size was set to 36. The starting dose was set to the lowest dose, and the number of patients allocated to each dose level was set to 3. Sato et al. (2016) introduced

4.3 The Dose-Finding Method Using the Change Point Model 71

a correlation between toxicity and efficacy into simulations by conditional proba-





bilities Pr YE = 1| YT = 0 , d and Pr Y

, which were calculated

l

E = 1| YT = 1 , d l





by substituting true πT d , π

d , and ρ d = ρ = 0 . 20 into the following l

E

l

l

equations:





ρ πE d 1 − π d π d 1 − π d − π d 1 − π d l

E

l

T

l

T

l

E

l

T

l

Pr YE = 1| YT = 0 , d =



,

l

πT d − 1

l

(4.28)





ρ πE d 1 − π d π d 1 − π d + π d π d l

E

l

T

l

T

l

E

l

T

l

Pr YE = 1| YT = 1 , d =



.

l

πT d l

(4.29)

Each simulation consisted of 1,000 trials.

The critical values for the posterior probabilities of efficacy and toxicity cE and cT were set to 0.20 and 0.40, respectively, and fixed probability cutoffs δE and δT were both set to 0.10. To determine the mean of the prior normal distribution in the proposed method, Sato et al. (2016) specified the prior efficacy and toxicity probabilities as ( p 1 , p 2 , p 3 , p 4 , p 5 , p 6 ) = ( 0 . 05 , 0 . 20 , 0 . 35 , 0 . 50 , 0 . 55 , 0 . 60 ) and (q 1 , q 2 , q 3 , q 4 , q 5 , q 6 ) = ( 0 . 05 , 0 . 10 , 0 . 15 , 0 . 20 , 0 . 25 , 0 . 30 ), respectively. The expected change point was set to d# = d , the correlation coefficient of ψ

4

l = ψ =

0 . 20, and the standard deviation of σ = 3 . 0. The weight parameters wE and wT for the weighted Mahalanobis distance were set to 1.0.

Throughout the 11 scenarios, which include a true optimal dose, the means of the recommended rates for the true optimal dose of the proposed method and of Thall and Cook’s method were 44.1% and 26.8%, respectively. In the scenarios where the dose–efficacy curve nonmonotonically increases with the dose, the recommendation rates for the optimal dose and the average number of patients allocated to the optimal dose in the proposed method were up to 40% higher as compared with Thall and Cook’s method. This index of the proposed method was not worse than that of Thall and Cook’s method under the scenarios where the dose–efficacy curve monotonically increases with the dose level. Under the scenarios where the optimal dose was located at the lowest (or highest) dose level, the two methods were comparable. In the case where all dose levels had unacceptable toxicity, the two methods yielded an approximately 100% termination rate of the trial.

The simulation studies indicated that the operating characteristics in the proposed method were more favorable than those of the Thall and Cook method, especially when the optimal dose levels were in the lower or middle range, and the dose–efficacy curves nonmonotonically increased with the dose escalation. Thus, the proposed method may be useful for determining the optimal dose in the cases where the MTAs under study have a nonmonotonic dose–efficacy relationship according to prior information, such as preclinical data.





72

4

Dose Finding for Molecularly Targeted Agents (MTAs)

4.3.4

Software Implementation

The estimation of model parameters under the assumptions of change point d∗ =

d , . . . , d

is carried out by means of PROC MCMC in SAS, version 9.3 (SAS Insti-1

L−1

tute Inc., Cary, NC). Given the prior distribution for each parameter and the assumed change point d∗ = d, the following programs apply the random-walk Metropolis l

algorithm for input SAS dataset “assign” and output posterior mean ˆθ l at the assumed change point. Dataset “assign” contains a dose for patient i , yi 00 , yi 01 , yi 10, and yi 11.

--------------------------------------------------

/************************************************/

D: actual dose

X: standardized dose calculated based on actual dose

Y00: no efficacy and no toxicity outcome

Y01: no efficacy and toxicity outcome

Y10: efficacy and no toxicity outcome

Y11: efficacy and toxicity outcome

CHANGEPOINT: assumptive change-point

/************************************************/

PROC MCMC DATA=assign NTU=&NTU. NBI=&NBI. NMC=&NMC.

NTHIN=&NTHIN. PROPCOV=QUANEW SEED=&SEED.

OUTPOST=OUT;

ODS OUTPUT POSTSUMMARIES=OUT_SUMMARIES;

***** Parameter definition *****;

PARMS ALPHACT0;

PARMS ALPHACT1;

ARRAY ALPHAE[2];

PARMS (ALPHAE1 ALPHAE2);

PARMS BETACT0;

PARMS BETACT1;

ARRAY BETAE[2];

PARMS (BETAE1 BETAE2);

********************************;

***** Prior distribution *****************;

PRIOR ALPHACT1 ˜ NORMAL(-0.951,SD=3);

PRIOR ALPHACT0 ˜ NORMAL(-2.191,SD=3);

PRIOR ALPHAE1 ˜ NORMAL(-0.599,SD=3);

PRIOR ALPHAE2 ˜ NORMAL(-0.375,SD=3);

PRIOR BETACT1 ˜ NORMAL(0.353, SD=3);

PRIOR BETACT0 ˜ NORMAL(0.936, SD=3);

PRIOR BETAE1 ˜ NORMAL(2.114, SD=3);

PRIOR BETAE2 ˜ NORMAL(1.123, SD=3);

******************************************;



*****

Conditional toxicity probability *****;

PCT0=LOGISTIC(ALPHACT0+BETACT0*X);

PCT1=LOGISTIC(ALPHACT1+BETACT1*X);

*********************************************;





4.3 The Dose-Finding Method Using the Change Point Model 73

***** Change-point Model **************;

J = 1 + (D > &CHANGEPOINT.);

PE=LOGISTIC(ALPHAE[J] + BETAE[J]*X);

***************************************;

LLIKE=Y01*LOG(PCT0)+Y00*LOG(1-PCT0)

+Y11*LOG(PCT1)+Y10*LOG(1-PCT1)

+(Y11+Y10)*LOG(PE)+(Y00+Y01)*LOG(1-PE);

MODEL DGENERAL(LLIKE);

RUN;

--------------------------------------------------

4.4

The Dose-Finding Method with Late-Onset Efficacy

Riviere et al. (2016) proposed a dose-finding method for MTAs with efficacy delayed so often that the efficacy practically takes more follow-up time to assess as compared with toxicity. Riviere et al. (2016) employed a logistic model with a plateau parameter to consider the plateau dose–efficacy relationship for MTAs.

4.4.1

Modeling Toxicity and Efficacy Outcomes

Let us assume that Yi is the binary toxicity outcome for patient i (i = 1 , . . . , N ).

Yi = 1 indicates that toxicity is observed, and Yi = 0 indicates otherwise. To consider late-onset efficacy, let T be a fixed time window required to evaluate efficacy, and tEi denotes time to efficacy of the i th patient. Suppose CEi is the follow-up time for patient i prior to the entry of the next patient. The efficacy indicator of patient i prior to the entry of the next patient is denoted by zi = I [ tEi < CEi ], where I [·]

represents the indicator function.

Riviere et al. (2016) modeled the toxicity probability of dose dl (l = 1 , . . . , L), designated as πT (dl) = πTl, via a logistic model: logit (πTl) = β 0 + β 1 ul,

(4.30)

where β 0, β 1 (> 0 ) are unknown parameters, and ul is the effective dose associated with dose dl , which typically differs from the actual dose. To make ul identifiable, we require the prior estimates of ˜

β 0, ˜ β 1, and ˜ πTl. Then, effective dose ul is determined by back-solving the dose–toxicity model as follows,





˜ πTl

ul = log

− ˜ β 0 / ˜ β 1 .

1 − ˜ πTl

74

4

Dose Finding for Molecularly Targeted Agents (MTAs)

Next, let πE (dl) = πEl be the efficacy probability for dose dl. Riviere et al. (2016)

employed a logistic model with plateau parameter τ to capture the increasing-then-plateauing feature of the dose–efficacy relationship:

logit (πEl) = γ 0 + γ 1 (vl I [ dl < τ ] + vτ I [ dl ≥ τ ] ) (4.31)

where γ 0 and γ 1 are unknown parameters, and vl is the effective dose associated with dose dl . Plateau parameter τ is an integer between 1 and L that indicates at which dose level the dose–efficacy curve reaches the plateau. Like effective dose ul , vl is determined by back-solving the dose–efficacy model as follows:





˜ πEl

vl = log

− ˜ γ 0 / ˜ γ 1 ,

1 − ˜ πEl

where ˜ πEl, ˜

γ 0 , ˜ γ 1 and ˜ τ are prior estimates of parameters.

After the first n patients are enrolled into the trial, the likelihood of toxicity data Dtox is

n





L (β

1− yi

0 , β 1| Dtox ) =

π yi 1 − π

,

(4.32)

T x

T x

i

i

i =1

where xi denotes the effective dose corresponding to the actual dose administered to the i th patient.

If we assume that f (β 0 , β 1 ) represents the prior distribution of β 0 and β 1, the posterior is then given by

f (β 0 , β 1| Dtox ) L (β 0 , β 1| Dtox ) f (β 0 , β 1 ) .

(4.33)

Riviere et al. (2016) assumed that prior distributions are independent and take a vague normal prior N ( 0 , 100 ) for the intercept β 0, and we assigned slope β 1 to an exponential distribution with a rate parameter of 1, i.e., β 1 ≈ E x p ( 1 ). After we specify the prior distributions, the posterior distribution is sampled using the Gibbs sampler.

For efficacy, Riviere et al. (2016) followed the approach of Cheung and Chappell

(2000) by weighting the observed data likelihood with the follow-up time. Given efficacy data Def f , the weighted likelihood function of the efficacy data is expressed as





n





L γ

zi

1− zi

0 , γ 1 , τ | De f f

=

wiπEx

1 − w

(4.34)

i

i πE xi

i =1

where wi is the weight function.

Riviere et al. (2016) selected the form of adaptive weights proposed by Cheung and Thall (2002), formulated as





4.4 The Dose-Finding Method with Late-Onset Efficacy 75

1

if tEi ≤ CEi

wi = #{ j : t

(4.35)

E j ≤ C Ei and C E j = T }+ CEi /T otherwise

#{ j : tEj ≤ T and CEj = T }+1





where # j : tE j ≤ T and CE j = T is the number of patients who experienced efficacy (i.e., tE j ≤ T ) and completed the follow-up (i.e., CE j = T ) before the entry of the next patient; and CEi /T is the proportion of the time that patient i was followed compared to the full follow-up time T before the entry of the next patient.

If we assume that f (γ 0 , γ 1 , τ ) represents the prior distribution of γ 0, γ 1, and τ , then the posterior is given by





f γ 0 , γ 1 , τ | Def f ∝ L γ 0 , γ 1 , τ | Def f f (γ 0 , γ 1 , τ ) .

(4.36)

Riviere et al. (2016) assumed that prior distributions are independent and took vague normal prior N ( 0 , 100 ) for the intercept γ 0 and an exponential distribution with a rate parameter of 1 for γ 1, i.e., γ 1 ≈ E x p ( 1 ). To the plateau parameter, τ , Riviere et al.



(2016) assigned a discrete prior distribution Pr (τ = l) = p L

l and

p

m=1

m = 1 and

∀ m, pm ≥ 0. When no information is available on the plateau location, the uniform prior is recommended with p 1 = · · · = pL = 1 /L. After we specified the prior distributions, the posterior distribution is sampled by the Gibbs sampler.

4.4.2

Plateau Estimation

With the Gibbs sampler, the posterior probability of the l th dose being the plateau point, ql = Pr τ = dl| Def f , is given by pl

L γ 0 , γ 1| dl, Def f f (γ 0 , γ 1 ) dγ 1 dγ 0

ql =





.

(4.37)

L

p

L γ

f (γ

m=1

m

0 , γ 1| dm , De f f

0 , γ 1 ) d γ 1 d γ 0

Riviere et al. (2016) proposed two approaches to plateau estimation: MTA-RA (Adaptive Randomization):

Let us assume that R is the set of doses whose posterior probabilities of being the plateau point were close to the largest one with a difference less than a positive threshold s 1, i.e.,





R = k : max (q



l ) − qk ≤ s 1 , 1 ≤ k ≤ L , (4.38)

1≤ l≤ L

where s 1 is the cutoff value. Riviere et al. (2016) found that what generally works well





in their simulation study is s 1 = 0 . 20 1 − n , where n is the current sample size. The N



plateau estimate, ˆ τ, is sampled from R with renormalized probability ql/

q

k∈ R

k .





76

4

Dose Finding for Molecularly Targeted Agents (MTAs)

MTA-PM (Posterior Efficacy Probabilities):

Given the plateau location at each possible dose level and estimated posterior efficacy probabilities, we then perform BMA on the estimated posterior efficacy probabilities L



¯ πEl =

ˆ πE (dl, γ 0 , γ 1| τ = k) qk

(4.39)

k=1

where ˆ πE (dl, γ 0 , γ 1| τ = k) is the posterior mean of the efficacy probability under the assumption that τ = k. After that, the plateau is determined at dose ˆ τ = max k : 1 ≤ k ≤ L, ¯ πEk − ¯ πE(k−1 ) ≥ s 2

(4.40)

where s 2 is a cutoff value. The value of s 2, which is a constant, should be calibrated in a simulation to ensure good operating characteristics of the design.

4.4.3

The Dose-Finding Algorithm

Definition of the Optimal Dose:

Riviere et al. (2016) defined the optimal dose as the dose level that has the maximum efficacy probability among the admissible dose levels.

Acceptable Dose Criteria:

Riviere et al. (2016) regarded the dose that satisfies the following safety and efficacy requirements as admissible:

Pr (πTl > θ) < LT

(4.41)

Pr (πEl > ξ ) ≥ L E I [ nk > max (c, 3 )]

(4.42)

where θ and ξ are the prespecified toxicity upper bound and efficacy lower bound, L T and L E are the respective probability thresholds for toxicity and efficacy, and nk denotes the number of patients treated with dose dl , respectively. Here, the set of admissible doses that met the two above-mentioned criteria is designated as A (dl).

The Dose-Finding Algorithm:

At the beginning of the trial, the following start-up phase is implemented to gather enough information for estimating model parameters. The first cohort of patients is at the lowest dose level 1, and the dose is escalated to the next dose level unless more than one out of three patients in that cohort experiences toxicity.

Once a toxicity is observed or the highest dose level is reached, the start-up phase ends, and the trial design switches to the model-based dose-finding phase, where





4.4 The Dose-Finding Method with Late-Onset Efficacy 77

patients are treated at a cohort size of c. The next incoming cohort of patients is basically assigned to the dose level with the highest efficacy in the set of admissible doses A (dl):





dnext = min arg max

ˆ π

(4.43)

l∈ A(d

El

l )

If dnext is the dose that has never been administered up to that time point, increasing the dose by only one level, Riviere et al. (2016) continued the above dose assignment processes until the maximum sample size was reached, and selected the optimal dose as the lowest dose level that is admissible and has the highest estimate of efficacy among all the doses tested during the trial. At any time during the model-based dose-finding phase, if all doses were not admissible, those authors terminated the trial to protect patients from overly toxic or futile doses.

4.4.4

Operating Characteristics

Riviere et al. (2016) compared the proposed MTA-RA and MTA-PM designs with the method proposed by Hunsberger et al. (2005) (abbreviated as the HRDK method) and the method proposed by Thall and Cook (2004) (abbreviated as the TC method) under 10 scenarios. Because the HRDK and TC designs assume that the efficacy endpoint is binary, it is quickly ascertainable when these two designs are implemented. Riviere et al. (2016) assumed six dose levels, and the maximum sample size was N = 60.

The trial started at the lowest dose d 1, and the cohort size was c = 3 patients. They considered toxicity and efficacy independent. Each simulation was conducted 2,000

times.

Riviere et al. (2016) set the prespecified toxicity upper bound as θ = 0 . 35, the toxicity threshold as L T = 0 . 90, the efficacy lower bound as ξ = 0 . 20, and the efficacy threshold as L E = 0 . 40. To identify effective doses uk and vk used in the toxicity and efficacy models, Riviere et al. (2016) took the initial guesses of toxicity and efficacy probabilities as (0.02, 0.06, 0.12, 0.20, 0.30, 0.40) and (0.12, 0.20, 0.30, 0.40, 0.50, 0.59), respectively. The patient accrual followed a Poisson process at the rate of 0.28 patients per week. The evaluation of efficacy required 7 weeks. Riviere et al. (2016) assumed that the time to efficacy followed an exponential distribution whose parameter was chosen based on the efficacy rate of each dose under each scenario. It should be noted that when implementing the HRDK and TC method, Riviere et al. (2016) waited for the efficacy response of the treated patients to become completely observable before enrolling a new cohort of patients.

In the scenarios that include a true optimal dose, the means of the recommended rates for the true optimal dose of MTA-RA, MTA-PM, HRDK, and TC methods were 52.2%, 52.7%, 28.0%, and 34.7%, respectively. Although the TC method performed the best under the scenario where the plateau was reached at the lowest dose level (the differences in the probabilities of correct optimal dose selection between their proposed method and TC method were approximately 10%), their proposed method outperformed the HRDK design and performed as well as or better than TC in terms





78

4

Dose Finding for Molecularly Targeted Agents (MTAs)

of the selection of the optimal dose under most scenarios. In the scenario in which none of the doses was admissible and the trial had to be terminated, their proposed method terminated the trial early approximately 90% of the time.

In this simulation study, their method was based on partial information, while all patients’ outcomes were fully determined in the other methods. Considering these simulation results, their proposed methods may outperform other dose-finding methods even in the case where efficacy takes a relatively long time to assess as compared to toxicity.

4.4.5

Software Implementation

Readers can employ the dose-finding method proposed by Riviere et al. (2016) using the R package dfmta.

Given the number of dose levels, the true toxicity probabilities, the true efficacy probabilities, toxicity upper bound, efficacy lower bound, initial guesses of toxicity probabilities, initial guesses of efficacy probabilities, the rate for the Poisson process used to simulate patient arrival, the total number of patients, cohort size for the start-up phase, cohort size for the model phase, the type of outcome for efficacy (time to event or binary), the method for plateau determination, s 1 (or s 2), the number of simulations, an toxicity threshold, and an efficacy threshold, function mtaBin_sim provides the operating characteristics of the method proposed by Riviere et al. (2016)

as follows:

--------------------------------------------------------------------

p_tox_sc1 = c(0.005, 0.01, 0.02, 0.05, 0.10, 0.15)

p_eff_sc1_g1 = c(0.01, 0.10, 0.30, 0.50, 0.80, 0.80)

p_tox_sc2 = c(0.01, 0.05, 0.10, 0.25, 0.50, 0.70)

p_eff_sc2_g2 = matrix(c(0.40, 0.01, 0.40, 0.02, 0.40, 0.05, 0.40,

0.10, 0.40, 0.35, 0.40, 0.55), nrow=2)

prior_tox = c(0.02, 0.06, 0.12, 0.20, 0.30, 0.40)

prior_eff = c(0.12, 0.20, 0.30, 0.40, 0.50, 0.59)

prior_eff2 = rbind(prior_eff, prior_eff)

s_1=function(n_cur){0.2}

n=60

sim = mtaBin_sim(ndose=6, p_tox= p_tox_sc1, p_eff= p_eff_sc1_g1,

tox_max=0.35, eff_min=0.20, prior_tox=prior_tox, prior_eff= prior_eff, poisson_rate=0.28, n=60, cohort_start=3, cohort=3, tite=FALSE,

method="MTA-RA", s_1= function(n_cur){0.2*(1-n_cur/n)}, nsim=1, c_tox=0.90, c_eff=0.40)

|----|----|----|----|----|----|----|----|----|----|

**************************************************|

> sim

Call:

mtaBin_sim(ngroups = 1, ndose = 6, p_tox = p_tox_sc1,

p_eff = p_eff_sc1_g1, tox_max = 0.35, eff_min = 0.2,





References

79

prior_tox = prior_tox, prior_eff = prior_eff, n = n,

cohort_start = 3, cohort = 3, tite = FALSE, method = "MTA-RA", s_1 = function(n_cur) {0.2 * (1 - n_cur/n)}, nsim = 1)

doses

1 2 3 4 5 6

True toxicities 0.00 0.01 0.02 0.05 0.1 0.15

True efficacies for group 1 0.01 0.10 0.30 0.50 0.8 0.80

Prior toxicities 0.02 0.06 0.12 0.20 0.3 0.40

Prior efficacies for group 1 0.12 0.20 0.30 0.40 0.5 0.59

Percentage of Selection for group 1 0.00 0.00 0.00 0.00 0.0 100.00

Number of patients for group 1 3.00 3.00 3.00 6.00 6.0 39.00

Number of toxicities for group 1 0.00 0.00 0.00 0.00 0.0 10.00

Number of efficacies for group 1 0.00 1.00 1.00 2.00 5.0 33.00

Percentage of inconclusive trials for group 1: 0

Allocation method: MTA-RA

Number of simulations: 1

Total patients accrued: 60

Toxicity upper bound: 0.35

Efficacy lower bound: 0.2

Patient arrival for group 1 is modeled as a Poisson process with rate: 1 that is in mean 1 patients during a full follow-up time

Toxicity threshold: 0.9

Efficacy threshold: 0.4

Cohort size start-up phase: 3

Cohort size model phase: 3

Efficiency is not a time-to-event but binary

--------------------------------------------------------------------

References

Cai, C., Yuan, Y., Ji, Y.: A Bayesian dose finding design for oncology clinical trials of combinational biological agents. Appl. Stat. 63, 159–173 (2014)

Cheung, Y.K., Chappell, R.: Sequential designs for phase I clinical trials with late-onset toxicities.

Biometrics 56, 1177–1182 (2000)

Cheung, Y.K., Thall, P.F.: Monitoring the rates of composite events with censored data in phase II clinical trials. Biometrics 58, 89–97 (2002)

Fox, E., Curt, G., Balis, F.: Clinical trial design for target-based therapy. Oncologist 7, 401–409

(2002)

Hirakawa, A.: An adaptive dose-finding approach for correlated bivariate binary and continuous outcomes in phase I oncology trials. Stat. Med. 31, 516–532 (2012) Hoering, A., Mitchell, A., LeBlanc, M., Crowley, J.: Early phase trial design for assessing several dose levels for toxicity and efficacy for targeted agents. Clin. Trials 10, 422–429 (2013) Hunsberger, S., Rubinstein, L.V., Dancey, J., Korn, E.L.: Dose escalation trial designs based on a molecularly targeted endpoint. Stat. Med. 24, 2171–2181 (2005) Islam, M.A., Chowdhury, R.I., Briollais, L.: A bivariate binary model for testing dependence in outcomes. Bull. Malays. Math. Sci. Soc. 35, 845–858 (2012)

Le Tourneau, C., Dieras, V., Tresca, P., Cacheux, W., Paoletti, X.: Current challenges for the early clinical development of anticancer drugs in the era of molecularly targeted agents. Target Oncol.

5, 65–72 (2015)

Riviere, M.K., Yuan, Y., Dubois, F., Zohar, S.: A Bayesian dose finding design for clinical trials combining a cytotoxic agent with a molecularly targeted agent. Appl. Stat. 64, 215–229 (2015)

80

4

Dose Finding for Molecularly Targeted Agents (MTAs)

Riviere, M.K., Yuan, Y., Jourdan, J.H., Dubois, F., Zohar, S.: Phase I/II dose-finding design for molecularly targeted agent: plateau determination using adaptive randomization. Stat. Methods Med. Res. (2016). https://doi.org/10.1177/0962280216631763

Rukhin, A.L.: Asymptotic behavior of estimators of the change-point in a binomial probability. J.

Appl. Stat. Sci. 1, 1–12 (1995)

Sato, H., Hirakawa, A., Hamada, C.: An adaptive dose-finding method using a change-point model for molecularly targeted agents in phase I trials. Stat. Med. 35, 4093–4109 (2016) Thall, P.F., Cook, J.D.: Dose-finding based on efficacy-toxicity trade-offs. Biometrics 60, 684–693

(2004)

Wages, N.A., Tait, C.: Seamless phase I/II adaptive design for oncology trials of molecularly targeted agents. J. Biopharm. Stat. 25, 903–920 (2015)





Chapter 5

Advanced Topics on Dose-Finding Designs

Abstract Recently, many types of dose-finding methods were proposed to address the issues that we often encounter in practice. For instance, a seamless phase I/II trial that combines phase I and phase II trials has some advantages: the data on both toxicity and efficacy can be used more efficiently for identifying an RP2D, and the duration of drug development can be reduced. For some MTAs, toxicity and efficacy outcomes sometimes require a longer follow-up period for their final assessments in practice. Moreover, there are patients who experience chronic low-grade toxicities from MTAs during the evaluation period of phase I trials. Such events eventually warrant a dose reduction or treatment interruption owing to intolerance. The relative dose intensity, which is generally defined as the ratio of the effectively delivered dose to the theoretically administered cumulative dose, draws the attention as a potential new endpoint of phase I trials. Cancer immunotherapy and dose individualization for phase I trials that analyze the mutations in several genes are also discussed.

Keywords Dose individualization · Immunotherapy · Phase I/II Relative dose intensity

5.1

Leveraging Phase I/II Trials

The standard approach to early exploratory clinical trials for developing new drugs in oncology is to conduct phase I and phase II trials separately, where an MTD is determined in phase I trials, and the efficacy at the MTD is assessed in phase II trials.

This approach has also been applied to the development of drug combinations. An alternative approach is to combine these trials, so that the data on both toxicity and efficacy can be used more efficiently for identifying an optimal dose, and the duration of drug development can be reduced. For example, Hoering et al. (2011) proposed a two-step dose-finding trial for assessing both toxicity and efficacy of a target agent.

A traditional dose-finding design is employed at the first step. At this step, only toxicity is assessed, and the MTD is determined. For the second step, Hoering et al.

(2011) proposed a modified phase II selection design for two or three dose levels at

© The Author(s), under exclusive licence to Springer Japan KK, part of Springer Nature 2018

81

A. Hirakawa et al., Modern Dose-Finding Designs for Cancer Phase I Trials: Drug Combinations and Molecularly Targeted Agents, JSS Research Series in Statistics, https://doi.org/10.1007/978-4-431-55573-5_5





82

5

Advanced Topics on Dose-Finding Designs

and below the MTD to determine efficacy and to evaluate the efficacy and toxicity of each dose level.

In two-agent combination trials, it may also be reasonable to determine the RP2D

on the basis of efficacy and toxicity outcomes by conducting a seamless phase I/II trial. Such trials generally involve determination of a single MTD combination based solely on toxicity data as a phase I part, followed by evaluation of efficacy data (such as response rates) at the MTD of the combination as a phase II part. Some dose-finding methods have been developed for determining an optimal-dose combination of two agents more efficiently based on toxicity and efficacy data in phase I/II trials (Table 5.1).

Huang et al. (2007) proposed to select a set of dose combinations with admissible toxicity using the 3 + 3 design as the phase I part and to determine an optimal-dose combination based on efficacy data among the selected dose combinations via adaptive randomization as the phase II part. Yuan and Yin (2011a) proposed to employ a Bayesian copula-type model to select admissible toxicity dose combinations in the phase I part. In these methods, the evaluation of efficacy in the phase II part is restricted to a few selected dose combinations from the phase I part, but they do not necessarily include the true optimal-dose combination because of being based only on toxicity profiles from small numbers of patients in the phase I part. Wages and Conaway (2014) proposed adaptive randomization based on efficacy data among admissible toxicity dose combinations for patient allocation in the phase I part and then to determine an optimal-dose combination judging by the maximum estimated efficacy probability in the phase II part. Shimamura et al. (in press) proposed a zone-finding stage that determines the most admissible toxicity zone in the dose combination matrix and subsequently to select the dose combination allocated to the next patient from that zone in phase I.

5.2

Late-Onset Toxicity and Efficacy Outcomes

In practice, toxicity and efficacy outcomes sometimes require a longer follow-up period for their final assessments. According to Muler et al. (2004), it took 9 weeks to conduct follow-up for final evaluation of toxicities in the phase I trials of combined cisplatin and gemcitabine in patients with pancreatic cancer. Such late-onset outcomes cause logistical issues for implementation of the dose-finding method because it is undesirable to delay a new patient’s treatment until the final evaluations of toxicity and/or efficacy outcomes of the previously enrolled patients in the trial are obtained. The issue of late-onset toxicity should be adequately addressed in the emerging era of MTAs. A review paper that examined the time-to-toxicity onset of MTAs revealed that 57% of grade 3 and 4 toxicities have a late onset (Postel-Vinay et al. 2011). To address the issue of late-onset toxicity, Cheung and Chappell

(2000) proposed the time-to-event CRM that assigns weights to the responses of patients whose final response status has not been determined in single-agent trials.

Mauguen et al. (2011) extended this weighting approach to the escalation with

5.2 Late-Onset Toxicity and Efficacy Outcomes

83

no

the

ore

of

com-

out-

mod-

dose

m

proba-

orized

point,

dose-

closest

to

atients

findings

g

toxicity

is

r

based

p

o

selected

dose

west

f

estimated,

o

number

this

trials

cate

lo

time

o

dose

true

toxicity

is

prespecified

is

the

zone

tw

(continued)

I/II

toxicity

of

the

this

toxicity

selected

allocated

met,

and

of

the

is

umber

the

each

at

zone

as

are

estimated

is

h

n

randomly

matrix

with

and

minimum

is

are

ntil

zone

phase

include

for

each

u

n

and

that

least

there

o

rdering

ordering

patient

the

ress)

o

hich

zone

for

patients

the

If

p

w

wn

odel

treated

zone

probability

criteria

is

each

zone

of

with

based

(in

m

with

partial

probability

first

for

zone.

continued

combination

al.

combination

zones

unkno

wer

combination

is

reached

et

the

atient

in

allocated

single

toxicity

cohort

is

design

po

p

probability

n

dose

eral

et

stopping

model

model

o

v

with

theorem

xt

rst

the

the

g

dose

-agent

se

toxicity

the

ne

selected

step

size

o

the

fi

en

,

obtained

tar

them

the

by

v

then

combination

combinations

o-stage

tw

The

The

Gi

toxicity

the

The

the

Unless

w

Based

T

for

Shimamura

Logistic

Logistic

1.

bility

into

bination

probability

2.

eled

Bayesian

3.

combination

4.

come

the

and

to

5.

dose

in

dose

patients,

from

6.

finding

sample

rel-

are

the

ased

sin-

dose

cal-

partial

b

mean

roba-p

is

to

and

the

selected

chosen

of

posterior

y

are

prespecified

est

for

combinations

g

ficac

the

class

robabilities

enrolled,

this

posterior

ef

ely

represent

are

p

lar

admissible

v

be

probabilities

the

probabilities

probability

randomized

met,

until

the

is

-agent

some

that

to

the

o

dose–toxicity

)

generated

reached

y,

These

is

ork,

in

are

tw

ordering

with

w

combinations

is

cac

respecti

are

toxicity

estimated

atients

probability

for

(2014

posterior

y

p

size

ordered

f

continued

ay

effi

each

as

the

criteria

patient

frame

cac

dose

o

this

w

is

of

randomization

esign

and

probabilities

for

selected

effi

d

relationships

information.

ew

a

y

theorem

is

estimated

with

step

sample

Cona

n

considered,

combinations

cohort

partially

updated

a

and

basis

t

cac

rior

odel

odel

is

p

probability

the

stopping

fi

Bayesian

and

m

m

ex

toxicity

rderingo

n

ely

admissible

n

the

for

n

r

certainty

o

v

o

the

o

e

ordering

ages

wer

wer

F

The

v

Bayesian

When

In

toxicity

The

On

The

Unless

Dose-finding

assuming

dose–ef

W

Po

Po

1.

ordering

2.

ati

based

adapti

on

3.

gle

ordering

4.

of

ordering

5.

based

6.

bilities

combinations,

culated

7.

combination

8.

dose-finding

prespecified

trials

is

a

fo

are

is

e

of

el

design

v

wing

Bayesian

or

atients

v

step

)

model

are

p

le

allo

agents

the

f

toxicity

toxicity

adapti

criteria

prespecified

n

o

estimates

o

ose

et

d

g

dose

not

both

the

combination

ving

combinations

(2011a

reached

model

ha

tar

ne

escalation

of

in

cohort

the

O

and

is

dose-finding

Y

hierarchical

based

t

.

to

the

stopping

until

dose-finding

-agent

probabilities

ex

to

only

size

-agent

I/II

o

Bayesian

posterior

n

and

o

this

tw

ving-reference

an

tw

u

The

The

Unless

Phase

for

using

mo

randomization

Y

Copula-type

Bayesian

1.

toxicity

estimated

theorem

2.

allocated

combination

closest

probability

change

simultaneous

de-escalation

3.

met,

continued

sample

for

;

n

e

o

v

ab

ws

dose

are

the

ed

d

so

then

based

used

the

the

design

design

a

=

is

and

starts

follo

each

adapti

,

and

and

in

block

D

)

single

11

o

12

and

n

design

for

along

a

d

d

o

tw

3

control

dose

zone,

so

using

combinations

+

outcome

tested

to

(2007

matrix

has

dose

has

dose

zone,

3

ose-finding

combinations

zone

the

escalation

‘

atients

d

f

and

are

p

ed-reference

al.

model

o

first

second

escalation

f

dose-finding

ose

into

zone

combinations

o

I/II

-agent

et

zone

o

fix

d

zone

toxicity

the

the

zone,

zone

I/II

tw

first

The

the

zone

vided

The

Modified

Dose

Phase

for

using

randomization

Huang

n/a

Logistic

1.

di

diagonal

combination

the

combination

second

combination

2.

with

with

third

3.

on

for

4.

same

simultaneously

randomization

number

combination

Phase

.15

for

for

y

I

blea

ficac

T

Method

Reference

Model

toxicity

Model

ef

Stage

dose-finding

algorithm

84

5

Advanced Topics on Dose-Finding Designs

to

rob-

cal-

the

p

roba-

dose

sam-

p

is

dose-

findings

chosen

y

y

cac

among

the

trials

are

dose

effi

ficac

I/II

ef

randomized

met,

maximum

and

admissible

and

probability

is

the

are

the

zone

phase

probability

n

in

o

until

estimated

atients

II)

ress)

combinations

toxicity

p

this

p

f

criteria

II)

the

o

and

ith

I

based

(in

dose

of

randomization

w

combinations

stage

combination

al.

a

continued

et

estimated

cohort

is

design

basis

combinations

t

dose

stopping

reached

(stages

(only

the

ex

-agent

n

for

n

step

is

o

the

admissible

o

o-stage

tw

On

The

combination

Unless

size

oxicityT Futility

wT for

Shimamura

The

based

abilities

2.

bilities

combinations,

culated

3.

the

admissible

4.

finding

ple

1.

2.

simi-

atients

and

is

p

highest

f

admissi-

o

ash

stage

the

combinations

the

the

that

this

cohort

at

xt

among

met,

until

-agento dose–toxicity

)

ne

are

tw

reached

the

II)

t

is

II)

for

(2014

u

combination

and

ordered

algorithm

b

estimates

continued

ay

I,

criteria

size

I

w

is

stage

esign

dose

d

relationshipsy

step

Cona

stage

the

(stages

partially

f

sample

(only

cac

o

robability

combinations

stopping

fi

p

and

dose-finding

that

y

dose

oxicity

ages

The

to

allocated

ficac

Unless

T

Futility

Dose-finding

assuming

dose–ef

W

1.

lar

is

ef

ble

2.

dose-finding

maximum

1.

2.

anu

are

e

are

e

e

Y

n

the

v

y

II)

design

v

v

utions

by

o

to

fif

cac

is

)

atients

II)

p

o

effi

and

adapti

adapti

,

istrib

criteria

maximum

I

based

d

step

))

combinations

and

the

stage

combinations

(2011a

(named

cohort

updated

reached

in

prior

are

is

dose-finding

dose

(stages

Y

randomized

ery

until

(only

Bayesian

robability

stopping

(2011a

p

ev

the

size

I/II

-agent

ely

toxicity

o

Bayesian

and

in

y

v

dose-finding

tw

ving-reference

Y

an

ving-reference

the

oxicity

u

Using

ficac

After

Unless

T

Futility

Phase

for

using

mo

randomization

Y

1.

mo

randomization

and

ef

adapti

admissible

2.

patients,

for

parameters

3.

met,

continued

sample

1.

2.

e

the

v

based

to

e

y

are

is

atients

v

II)

design

(named

))

p

fi

utions

cac

adapti

,

fo

step

aximum

II)

and

II)

)

effi

criteria

m

I

(2011a

distrib

combinations

and

the

stage

combinations

in

randomized

cohort

updated

reached

stage

(2007

Y

robability

prior

ose-finding

ed-reference

p

are

ntil

is

d

ely

dose

ery

(stages

stopping

u

(only

ed-reference

al.

fix

randomization

and

y

v

ev

the

dose-finding

(only

size

I/II

-agent

et

e

toxicity

o

fix

v

an

y

ficac

the

xicity

tw

u

adapti

o

Using

Y

ef

After

the

Unless

T

Futility

ficac

Phase

for

using

randomization

Huang

1.

adapti

by

on

are

admissible

2.

patients,

for

parameters

3.

met,

continued

sample

1.

2.

Ef

(continued)

.15

II

stopping

bleaT Method

Reference

Stage

dose-finding

algorithm

Early

criteria





5.2 Late-Onset Toxicity and Efficacy Outcomes

85

overdose control design. Yuan and Yin (2011b) regarded late-onset toxicities as missing data and proposed an expectation maximization algorithm to account for the unobserved toxicity outcomes in single-agent trials. Liu and Ning (2013) proposed a Bayesian dose-finding design for two-agent combination trials with late-onset toxicities. More recently, some Bayesian phase I/II designs that can address late-onset efficacy and/or toxicity outcomes have been devised (Riviere et al. 2016; Lin and

Johnson 2016).

5.3

Accounting for Relative Dose Intensity for MTAs

The conventionally defined RP2D of a cytotoxic agent corresponds to the MTD, which is determined from toxicity data obtained during the first, and rarely, the second cycle of treatment. Toxicity data from later cycles are not used to determine the RP2D; furthermore, treatment changes (e.g., dose reduction or treatment interruption) are recorded but not used to determine the RP2D. Although such a conventional approach has been successful for evaluating cytotoxic agents, it may not be optimal to determine the RP2D of MTAs (Le Tourneau et al. 2010). In this regard, Le Tourneau et al. (2011) recommended that a treatment delay and/or reduction of relative dose intensity be included in the definition of dose limiting toxicity. Relative dose intensity is generally defined as the ratio of the effectively delivered dose to the theoretically administered cumulative dose. Moreover, there are patients who develop chronic low-grade toxicities from MTAs during the evaluation period of phase I trials. Such events eventually warrant a dose reduction or treatment interruption owing to intolerance.

The conventional method for determining RP2D relies on the traditional definition of the MTD during cycle 1, wherein low-grade toxicities are not considered and excluded from MTD determination. These toxicities eventually become intolerable and are major factors leading to a dose reduction or interruption after the cycle 1 evaluation period, resulting in insufficient drug exposure. Development of a methodology to predict an appropriate RP2D, instead of basing it on a simple MTD determination, has been advocated. A recent workshop examined Food and Drug Administration (FDA)-approved agents for oncological indications requiring dose reductions and interruptions in initial registration trials for small-molecule kinase inhibitors (Jänne et al. 2016). Among 31 approved inhibitors, at least eight necessitated postmarketing requirements or commitments. There is a significant gap in the development of these agents because of a failure to predict an appropriate administration dose, potentially leading to late-onset and/or cumulative toxicity (Nie et al. 2016). Consequently, there is a need to assess the frequency of cases requiring a dose reduction after cycle 1 and to evaluate the duration and degree of dose lowering (i.e., relative dose intensity).

Apart from the MTD, a study on toxicity information in phase I trials revealed that moderate and severe toxicities occur regularly after cycle 1, and attention to RP2D

determination may be warranted (Postel-Vinay et al. 2014; Hirakawa et al. 2017). It has been suggested that RP2D assessment should incorporate all available information from any cycle, including lower grade toxicities leading to decreased relative dose intensity.





86

5

Advanced Topics on Dose-Finding Designs

5.4

Cancer Immunotherapy

The effect of cancer immunotherapies is not directly based on the tumor but rather on the immune system. The mechanism of action of immunotherapy is characterized by a cellular immune response followed by potential changes in the tumor burden or patient survival (Hoos 2012). To adequately evaluate the optimal dose of immunotherapies in phase I trials, a new dose-finding method that accounts for these mechanisms is required. To this end, as in the dose-finding methods for MTAs, this new method would benefit from new trial designs that allow for incorporation of low-grade toxicities, late-onset toxicities, and addition of an efficacy endpoint.

Chiou and Burotto (2015) discussed the pseudo-progression of immunotherapy.

Delayed clinical responses have also been observed in studies of immunotherapeu-tic agents, namely, an increase in the total tumor burden is later followed by tumor regression. These findings of pseudo-progression would have been classified prema-turely as progressive disease according to historic WHO or RECIST criteria and have prompted the development of immunotherapy-related response criteria (Wolchok et al. 2009). Therefore, when an efficacy endpoint is evaluated in the dose-finding trials for immunotherapy, we may need to consider pseudo-progression when determining the optimal dose. In this regard, Postel-Vinay et al. (2016) reviewed the phase I designs for immunostimulatory monoclonal antibodies targeting immune checkpoint molecules, including pharmacokinetic and pharmacodynamic evaluations.

5.5

Dose Individualization

An emerging approach among treatments targeted to the needs of individual patients on the basis of genetic, biomarker, phenotypic, or other clinical (or clinicopathologi-cal) characteristics is given a great deal of attention (Collins and Varmus 2015). This growing trend is also recognized in early-phase dose-finding trials that determine the RP2D that often corresponds to the MTD defined as the highest clinically safe dose.

Several recent dose-finding trials have enrolled two or three heterogeneous groups of patients categorized based on clinical or genomic characteristics (e.g., Innocenti et al. 2014). Such trials were aimed at determining the individualized RP2D for each patient group. To accommodate this growing trend, several dose-finding methods have been developed to identify each RP2D in two or three groups of patients (e.g., O’Quigley et al. 1999; Ivanova and Wang 2006). Nevertheless, a common limitation of these methods is that they can accommodate only a couple of patients’ characteristics in the dose–toxicity and/or dose–efficacy models because of the difficulty with estimating model parameters at a limited sample size of early-phase trials; therefore, these methods do not include an interaction term of the dose and patient covariate in their models.

In recent years, phase I/II trials analyzing the mutations in multiple genes (e.g., mutant or wild type) simultaneously are increasing in number (Amatu et al. 2016). For





5.5 Dose Individualization

87

instance, we have 32 (=25) patterns of gene mutations when a trial tests five genes; therefore, the parameter estimation for dose–toxicity and/or dose–efficacy models including interaction terms of the dose and gene mutation at a limited sample size can be challenging due to the large number of parameters requiring estimation. Ideally, for each gene mutation pattern, the individualized optimal dose that is defined as the most efficacious dose among the doses with acceptable toxicity should be determined if the toxicity (and/or efficacy) outcome and a gene mutation interact.

Recently, Guo and Yuan (2016) struggled with this issue and developed a new dose-finding method for identifying an individualized optimal dose for each gene mutation pattern. They proposed the canonical partial least-square method, which is widely used in high-dimensional data analyses, to extract a small number of components from the covariate matrix consisting of the dose, covariates (i.e., genomic markers), and dose-by-covariate interactions. Nonetheless, their method cannot identify the gene(s) influencing toxicity and/or efficacy responses because of its methodological nature: the toxicity and efficacy outcomes are modeled based on a latent variable approach involving the canonical partial least-square components. A dose-finding method that determines the individualized optimal dose for each pattern of multiple patient covariates of interest and then identifies the covariates associated with toxicity and/or efficacy outcomes is needed in practice. This is because the associated covariates are useful for enriching the study population that can be expected to offer a reasonable benefit/risk balance for an investigational drug in subsequent trials.

To accommodate this growing trend, we need to develop a new method for dose individualization and simultaneous covariate selection in early-phase trials evaluating multiple patient covariates of interest. We possibly can create such methods by means of the Bayesian least absolute shrinkage and a selection operator (lasso) (Park and Casella 2008). The Bayesian lasso enables simultaneous parameter estimation and covariate selection in the data with a large number of covariates by shrinking the coefficients of covariates toward zero. For both binary efficacy and toxicity outcomes, the method assumes the logistic model including the dose, binary patient covariates, and interaction of the dose and patient covariates. The logistic model for the efficacy outcome also includes a quadratic term of the dose to enable capturing the nonmonotonic dose–efficacy relationship. The dose assignment during the trial is performed via the posterior distribution of parameters obtained from the Bayesian Lasso. Upon completion of patient enrollment, the proposed method determines the individualized optimal dose according to the patterns of patient covariates and selects the covariates associated with efficacy and toxicity outcomes.

References

Amatu, A., Sartore-Bianchi, A., Siena, S.: NTRK gene fusions as novel targets of cancer therapy across multiple tumour types. ESMO Open 1, e000023 (2016)

Cheung, Y.K., Chappell, R.: Sequential designs for phase I clinical trials with late-onset toxicities.

Biometrics 56, 1177–1182 (2000)

88

5

Advanced Topics on Dose-Finding Designs

Chiou, V.L., Burotto, M.: Pseudoprogression and immune-related response in solid tumors. J. Clin.

Oncol. 33, 3541–3543 (2015)

Collins, F., Varmus, H.: A new initiative on precision medicine. New Engl. J. Med. 372, 793–795

(2015)

Guo, B., Yuan, Y: Bayesian phase I/II biomarker-based dose finding for precision medicine with molecularly targeted agents. J. Am. Stat. Assoc. (2016). https://doi.org/10.1080/01621459.2016.

1228534

Hirakawa, A., Yonemori, K., Kinoshita, F., Kobayashi, Y., Ohkuma, H.S., Kawachi, A., Tamura, K., Fujiwara, Y., Rubinstein, L., Harris, P.J., Takebe, N.: Potential utility of a longitudinal relative dose intensity of molecularly targeted agents in phase 1 dose-finding trials. Cancer Sci. (2017).

https://doi.org/10.1111/cas.13436

Hoering, A., LeBlanc, M., Crowley, J.: Seamless phase I-II trial design for assessing toxicity and efficacy for targeted agents. Clin. Cancer Res. 17, 640–646 (2011) Hoos, A.: Evolution of end points for cancer immunotherapy trials. Ann. Oncol. 23, 47–52 (2012) Huang, X., Biswas, S., Oki, Y., Issa, J.-P., Berry, D.A.: A parallel phase I/II clinical trial design for combination therapies. Biometrics 63, 429–436 (2007)

Innocenti, F., Schilsky, R.L., Ramirez, J., Janisch, L., Undevia, S., House, L.K., Das, S., Wu, K., Turcich, M., Marsh, R., Karrison, T.: Dose finding and pharmacokinetic study to optimize the dosing of irinotecan according to the UGT1A1 genotype of patients with cancer. J. Clin. Oncol.

32, 2328–2334 (2014)

Ivanova, A., Wang, K.: Bivariate isotonic design for dose-finding with ordered groups. Stat. Med.

25, 2018–2026 (2006)

Jänne, P.A., Kim, G., Shaw, A.T., Sridhara, R., Pazdur, R., McKee, A.E.: Dose finding of small-molecule oncology drugs: optimization throughout the development life cycle. Clin. Cancer Res.

22, 2613–2617 (2016)

Le Tourneau, C., Diéras, V., Tresca, P., Cacheux, W., Paoletti, X.: Current challenges for the early clinical development of anticancer drugs in the era of molecularly targeted agents. Target Oncol.

5, 65–72 (2010)

Le Tourneau, C., Razak, A.R., Gan, H.K., Pop, S., Diéras, V., Tresca, P., Paoletti, X.: Heterogeneity in the definition of dose-limiting toxicity in phase 1 cancer clinical trials of molecularly targeted agents: a review of the literature. Eur. J. Cancer 47, 1468–1475 (2011) Lin, S., Johnson, V.E.: A robust Bayesian dose-finding design for phase I/II clinical trials. Biostatistics 17, 249–263 (2016)

Liu, S., Ning, J.: A Bayesian dose-finding design for drug combination trials with delayed toxicities.

Bayesian Anal. 8, 703–722 (2013)

Mauguen, A., Le Deley, M.C., Zohar, S.: Dose-finding approach for dose escalation with overdose control considering incomplete observations. Stat. Med. 30, 1584–1594 (2011) Muler, J.H., McGinn, C.J., Normolle, D., Lawrence, T., Brown, D., Hejna, G., Zalupski, M.M.: Phase I trial using a time-to-event continual reassessment strategy for dose escalation of cisplatin combined with gemcitabine and radiation therapy in pancreatic cancer. J. Clin. Oncol. 22, 238–

243 (2004)

Nie, L., Rubin, E.H., Mehrotra, N., Pinheiro, J., Fernandes, L.L., Roy, A., Bailey, S., de Alwis, D.P.: Rendering the 3 + 3 design to rest: more efficient approaches to oncology dose-finding trials in the era of targeted therapy. Clin. Cancer Res. 22, 2623–2639 (2016) O’Quigley, J., Shen, L.Z., Gamst, A.: Two-sample continual reassessment method. J. Biopharm.

Stat. 9, 17–44 (1999)

Park, T., Casella, G.: The Bayesian lasso. J. Am. Stat. Assoc. 103, 681–686 (2008) Postel-Vinay, S., Aspeslagh, S., Lanoy, E., Robert, C., Soria, J.C., Marabelle, A.: Challenges of phase 1 clinical trials evaluating immune checkpoint-targeted antibodies. Ann. Oncol. 27, 214–

224 (2016)

Postel-Vinay, S., Collette, L., Paoletti, X., Rizzo, E., Massard, C., Olmos, D., Fowst, C., Levy, B., Mancini, P., Lacombe, D., Ivy, P., Seymour, L., Le Tourneau, C., Siu, L.L., Kaye, S.B., Verweij, J., Soria, J.C.: Towards new methods for the determination of dose limiting toxicities and the

References

89

assessment of the recommended dose for further studies of molecularly targeted agents-dose-Limiting Toxicity and Toxicity Assessment Recommendation Group for Early Trials of Targeted therapies, an European Organisation for Research and Treatment of Cancer-led study. Eur. J.

Cancer 50, 2040–2049 (2014)

Postel-Vinay, S., Gomez-Roca, C., Molife, L.R., Anghan, B., Levy, A., Judson, I., De Bono, J., Soria, J.C., Kaye, S., Paoletti, X.: Phase 1 trials of molecularly targeted agents: should we pay more attention to late toxicities? J. Clin. Oncol. 29, 1728–1735 (2011) Riviere, M.K., Yuan, Y., Jourdan, J.H., Dubois, F., Zohar, S.: Phase I/II dose-finding design for molecularly targeted agent: plateau determination using adaptive randomization. Stat. Methods Med. Res. (2016). https://doi.org/10.1177/0962280216631763

Shimamura, F., Hamada, C., Matsui, S., Hirakawa, A.: Two-stage approach based on zone and dose findings for two-agent combination phase I/II trials. J. Biopharm. Stat. (in press) Wages, N.A., Conaway, M.R.: Phase I/II adaptive design for drug combination oncology trials. Stat.

Med. 33, 1990–2003 (2014)

Wolchok, J.D., Hoos, A., O’Day, S., Weber, J.S., Hamid, O., Lebbé, C., Maio, M., Binder, M., Bohnsack, O., Nichol, G., Humphrey, R., Hodi, F.S.: Guidelines for the evaluation of immune therapy activity in solid tumors: immune-related response criteria. Clin. Cancer Res. 15, 7412–

7420 (2009)

Yuan, Y., Yin, G.: Bayesian phase I/II adaptive randomized oncology trials with combined drugs.

Ann. Appl. Stat. 5, 924–942 (2011a)

Yuan, Y., Yin, G.: Robust EM continual reassessment method in oncology dose finding. J. Am. Stat.

Assoc. 106, 818–831 (2011b)





Document Outline


Preface

Contents

Acronyms

1 Dose Finding in Phase I Cancer Trials 1.1 Cytotoxic Agents and MTAs

1.2 Classification of Phase I Cancer Trials

1.3 Rule-Based Methods 1.3.1 3+3 Design

1.3.2 Other Relevant Methods





1.4 Model-Based Methods 1.4.1 Bayesian CRM

1.4.2 Other Relevant Designs





References





2 Dose Finding for a Combination of Two Agents 2.1 Introduction 2.1.1 Two-Agent Combination Trials

2.1.2 An Overview of Model-Based Dose-Finding Methods

2.1.3 Methodological Characteristics





2.2 The Bayesian Approach Based on Copula Regression 2.2.1 Copula-Type Models

2.2.2 The Dose-Finding Algorithm

2.2.3 Software Implementation





2.3 Hierarchical Bayesian Design 2.3.1 Hierarchical Models

2.3.2 The Dose-Finding Algorithm

2.3.3 Software Implementation





2.4 An Approach Using a Shrinkage Logistic Model 2.4.1 The Shrinkage Logistic Model

2.4.2 The Dose-Finding Algorithm

2.4.3 Software Implementation





2.5 An Approach Using a Logistic Model 2.5.1 The Logistic Model Involving Standardized Doses

2.5.2 The Dose-Finding Algorithm

2.5.3 Software Implementation





2.6 The Design Based on Order-Restricted Inference 2.6.1 Order-Restricted Inference

2.6.2 The Dose-Finding Algorithm





2.7 The Partial-Ordering Continual Reassessment Method 2.7.1 The Model for Possible Orderings of Toxicity Probability for a Dose Combination

2.7.2 The Dose-Finding Algorithm

2.7.3 Software Implementation





2.8 Operating Characteristics

2.9 Effects of Design Properties 2.9.1 Size of Patient Cohorts

2.9.2 The Choice of a Dose–Toxicity Model

2.9.3 The Start-Up Rule

2.9.4 Restrictions on Skipping Dose Levels





References





3 Dose Finding for Joint Assessment of Both Efficacy and Toxicity 3.1 Introduction

3.2 The Bivariate Continual Reassessment Method 3.2.1 Modeling Toxicity and Efficacy Outcomes

3.2.2 The Dose-Finding Algorithm

3.2.3 Operating Characteristics

3.2.4 Software Implementation





3.3 Dose Finding Based on Efficacy–Toxicity Trade-Offs 3.3.1 Modeling Toxicity and Efficacy Outcomes

3.3.2 The Dose-Finding Algorithm

3.3.3 Constructing a Trade-Off Contour

3.3.4 Operating Characteristics

3.3.5 Software Implementation





3.4 A Bayesian Approach to Modeling Binary Toxicity and Continuous Efficacy Outcomes 3.4.1 Modeling Toxicity and Efficacy Outcomes

3.4.2 The Dose-Finding Algorithm

3.4.3 Operating Characteristics





3.5 The BMA Bivariate CRM 3.5.1 Modeling Toxicity and Efficacy Outcomes

3.5.2 BMA Estimates

3.5.3 The Dose-Finding Algorithm

3.5.4 Operating Characteristics

3.5.5 Software Implementation





References





4 Dose Finding for Molecularly Targeted Agents (MTAs) 4.1 Introduction

4.2 The Model-Selecting Dose-Finding Method 4.2.1 Modeling Toxicity and Efficacy Outcomes

4.2.2 The Dose-Finding Algorithm

4.2.3 Operating Characteristics

4.2.4 Software Implementation





4.3 The Dose-Finding Method Using the Change Point Model 4.3.1 Modeling Toxicity and Efficacy Outcomes

4.3.2 The Dose-Finding Algorithm

4.3.3 Operating Characteristics

4.3.4 Software Implementation





4.4 The Dose-Finding Method with Late-Onset Efficacy 4.4.1 Modeling Toxicity and Efficacy Outcomes

4.4.2 Plateau Estimation

4.4.3 The Dose-Finding Algorithm

4.4.4 Operating Characteristics

4.4.5 Software Implementation





References





5 Advanced Topics on Dose-Finding Designs 5.1 Leveraging Phase I/II Trials

5.2 Late-Onset Toxicity and Efficacy Outcomes

5.3 Accounting for Relative Dose Intensity for MTAs

5.4 Cancer Immunotherapy

5.5 Dose Individualization

References





